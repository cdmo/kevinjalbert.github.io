<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kevin Jalbert</title>
  <link href="https://kevinjalbert.com"/>
  <updated>2018-12-29T18:53:20-05:00</updated>
  <author>
    <name>Kevin Jalbert</name>
  </author>
  <id>https://kevinjalbert.com</id>
  <entry>
    <title>Archive Unused Repositories</title>
    <link rel="alternate" href="https://kevinjalbert.com/archive-unused-repositories/"/>
    <id>https://kevinjalbert.com/archive-unused-repositories/</id>
    <updated>2018-12-29T20:35:42-05:00</updated>
    <published>2018-12-29T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Over time, an individual or organization will create a number of software projects. The purpose of these repositories is to facilitate libraries, micro-services, documentation, mono-repositories, etc. Every so often, the time comes when a repository is no longer used. This article will outline how to archive these repositories, and the benefits to be realized.</description>
    <content type="html">&lt;p&gt;At the time of writing this article, &lt;a href="http://company.thescore.com/"&gt;theScore&lt;/a&gt; has approximately 250 repositories hosted on &lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;. The majority of these are private, although some public ones do exist as well. I suspect that software companies of sufficient size eventually accumulate a large number of repositories due to new projects, libraries, experiments, etc. An employee being faced with these numbers can waste a lot of time searching through these repositories and determining whether a repository is actively used.&lt;/p&gt;

&lt;h1&gt;The Burden&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Note: We&amp;rsquo;ll be focused on GitHub as the platform of choice, although the same principals can be applied to other code hosting platforms.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Over time, a repository can fade in activity and end up in either a &lt;em&gt;finished and active&lt;/em&gt; or a &lt;em&gt;unused&lt;/em&gt; state. In the event that someone stumbles upon an unused repository, they can waste a lot of time if it&amp;rsquo;s not clear that the repository is in fact unused. These repositories faded over time and so it will still have a detailed README and possibly open issues and pull requests. In the worst case scenario, an individual might put time and effort into addressing these unresolved issues to no benefits.&lt;/p&gt;

&lt;p&gt;At theScore, we use &lt;a href="https://help.github.com/articles/about-teams/"&gt;GitHub Teams&lt;/a&gt; to help determine the ownership of repositories. As you can guess, when you have unused repositories, this leads to a cognitive burden on the team. Routine tasks might involve going over all the repositories that a team owns, which just eats up time if you are unsure a repository is used or not.&lt;/p&gt;

&lt;p&gt;In addition, theScore also uses services that periodically check for security violations or outdated dependencies. In a similar vein, these services are triggering for unused repositories, thus leading to more noise. In some instances, the services are priced by the number of repositories or invocations, and so unused repositories can lead to additional costs as well.&lt;/p&gt;

&lt;h1&gt;The Solution&lt;/h1&gt;

&lt;p&gt;So one option that might have crossed your mind is to just delete/remove the repository. While it does the job of reducing the burden of having unused repositories, I would argue that there is a wealth of knowledge in the history of the repository and the code hosting platform (i.e., GitHub via issues and pull requests). A perfect example of where archiving makes a lot of sense is in open source software (i.e., like in &lt;a href="https://github.com/rails/actioncable"&gt;rails/actioncable&lt;/a&gt;) &amp;ndash; you want to retain the open contributions and communications.&lt;/p&gt;

&lt;p&gt;To prevent future confusion and wasted effort/time/cost, we&amp;rsquo;ve made a conscious decision to &lt;em&gt;archive unused repositories&lt;/em&gt;. Fortunately, GitHub actually provides a mechanism for &lt;a href="https://help.github.com/articles/archiving-a-github-repository/"&gt;archiving repositories&lt;/a&gt;. I highly recommend giving &lt;a href="https://blog.github.com/2017-11-08-archiving-repositories/"&gt;GitHub&amp;rsquo;s blog post&lt;/a&gt; a read as it details how you use the feature and provides some recommendations for archiving.&lt;/p&gt;

&lt;p&gt;The main takeaways of archiving a repository on GitHub are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The repository becomes read-only to everyone.&lt;/li&gt;
&lt;li&gt;Forks can still happen in the event someone wants to take the repository in a new direction.&lt;/li&gt;
&lt;li&gt;Archived repositories have a different appearance and can be filtered in a search.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;The Final Change&lt;/h1&gt;

&lt;p&gt;The first thing we do is create our final pull request, which adds the following notice to the top of the README:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# This repository is ⚰️ ARCHIVED ⚰️

FancyProject as a product has been sunsetted and decommissioned as the adoption was not as great as we were hoping for. Resources and efforts were moved to other projects. The last day of operation was on September 18, 2018.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This pull request has at least 4 major tasks in it:&lt;/p&gt;

&lt;h3&gt;1. Close All Open Issues and Pull Requests&lt;/h3&gt;

&lt;p&gt;We close the issues with the following message so that people know the reason why it was closed:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Closing open issues and pull requests as the project is now archived (&amp;lt;pr_of_final_update&amp;gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A link to the pull request is also mentioned in the comment. We do this so the last pull request that GitHub includes all the issues and pull requests that were closed due to the archiving process. You can see an example of this in the image below:&lt;/p&gt;

&lt;p&gt;&lt;img alt="Closed issues and pull requests" width="708" height="612" src="/images/2018-12-29-archive-unused-repositories/closed-issues.jpg" /&gt;&lt;/p&gt;

&lt;h3&gt;2. Set &lt;em&gt;Contributors&lt;/em&gt; to All Developers&lt;/h3&gt;

&lt;p&gt;When a repository is archived you cannot change the contributors (i.e., adding/removing teams). In the event that a repository was only visible to a subset of developers (it sometimes happens), we ensure our &lt;em&gt;developers team&lt;/em&gt; is a contributor before archiving. This subtle change makes it so everyone in the organization can see the repository (in the event it was needed for something).&lt;/p&gt;

&lt;h3&gt;3. Delete Repository from External Services&lt;/h3&gt;

&lt;p&gt;As part of the archiving process, we want to disable/remove any external services that might be monitoring the repository. For example, &lt;a href="https://snyk.io/"&gt;Snyk&lt;/a&gt; checks for security vulnerabilities periodically, and would continue to do so unless disabled. As previously mentioned, some of these services are priced by invocations and/or the number of repositories, so it is important that this step is completed.&lt;/p&gt;

&lt;p&gt;In the event that the repository represents a deployable project, you want to make sure you&amp;rsquo;ve taken steps to &lt;em&gt;decommission&lt;/em&gt; all aspects. For example, there might be servers, databases, cloud storage, etc., that are linked to this repository and need to be taken care of.&lt;/p&gt;

&lt;h3&gt;4. Archive Repository&lt;/h3&gt;

&lt;p&gt;Finally, with everything resolved, we can archive the repository in GitHub. Enjoy the event, as it simplifies the surface area of repositories you have to maintain.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Tracking Production Disruptions</title>
    <link rel="alternate" href="https://kevinjalbert.com/tracking-production-disruptions/"/>
    <id>https://kevinjalbert.com/tracking-production-disruptions/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-11-30T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">When operating software in a production environment it is expected to have some unplanned disruptions over time. While the primary task is to resolve the disruption so that the impact is minimized, it is still very much important to track the disruption itself. Disruption reports provide transparency to others, accountability in the actionable tasks, a place for discussion, categorical data, and also a summary of the event.</description>
    <content type="html">&lt;p&gt;Let us first iron out what constitutes a &lt;em&gt;disruption&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Any unexpected degradation or interruption of a service that in any method affects users ability to the service.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When operating a production service, it is simply a matter of time till a disruptions &lt;em&gt;happens&lt;/em&gt;. No matter the safeguards you&amp;rsquo;ve put in place, there is always the expected scenarios. There are many ways to prepare and to ensure that your services are as robust as possible, but that is a task left to you the reader. In this post I&amp;rsquo;ll be talking about what to do &lt;em&gt;after&lt;/em&gt; you&amp;rsquo;ve handled a production disruption.&lt;/p&gt;

&lt;h1&gt;Why Track?&lt;/h1&gt;

&lt;p&gt;A disruption can be a chaotic event, lasting from a few minutes to multiple hours. The main purpose of tracking these disruptions is to have a better understanding of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;what led to the issue.&lt;/li&gt;
&lt;li&gt;what could have been done to prevent the issue from happening?&lt;/li&gt;
&lt;li&gt;flaws in monitoring in detecting when the issue started.&lt;/li&gt;
&lt;li&gt;learnings and processes when dealing with a similar issue in the future.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I highly encourage disseminating the learnings around all aspects of a disruption to the rest of the team and organization. A tracked disruption can be used in a post-mortem. The ultimate goal is by educating everyone it will lead to more resilient services and better processes during the inevitable future disruptions.&lt;/p&gt;

&lt;p&gt;In addition, with tracked disruptions, it becomes easy to perform basic analysis of the frequency and length of disruptions.&lt;/p&gt;

&lt;p&gt;Without any tracking, it becomes a huge failure if the same disruption happens again over and over.&lt;/p&gt;

&lt;h1&gt;Tracking&lt;/h1&gt;

&lt;p&gt;One thing to note is that the following is from experience that I have working at &lt;a href="http://company.thescore.com/"&gt;theScore&lt;/a&gt;, along with reading various sources online. Let us touch on what to track, where to track, and how to track.&lt;/p&gt;

&lt;h2&gt;What to Track?&lt;/h2&gt;

&lt;p&gt;The more information you have the better you&amp;rsquo;ll understand the disruption if you weren&amp;rsquo;t immediately involved in it. Additionally, in most cases, multiple people are involved and so not everyone had the same exposure to the entire event. The following is a list and description of what we track at theScore for disruptions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Service(s)&lt;/strong&gt;: name of service(s) that were interrupted.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disruption Meta-Information&lt;/strong&gt;: at-a-glance information about the disruption.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: what type of disruption (i.e., Infrastructure, Critical Bug, Data Provider, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start Time&lt;/strong&gt;: when the disruption started (not necessarily when it was discovered).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detection Time&lt;/strong&gt;: when the disruption was detected by users/support/team.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;End Time&lt;/strong&gt;: when the disruption was resolved (action items may extend past this time).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Length&lt;/strong&gt;: the total time the disruption was active (based on start/end times).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time to Detection&lt;/strong&gt;: time to detect the disruption (based on start/detection times).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;People Involved&lt;/strong&gt;: list of individuals involved in handling the disruption.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: a high-level summary of the disruption (root cause and impact).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt;: a table of events which constructs the timeline of the disruption.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Timestamp&lt;/strong&gt;: approximate time of this event.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Party Involved&lt;/strong&gt;: who/what was involved with this event (i.e., servers, people, services).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: what happened at this event.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Retrospective&lt;/strong&gt;: a reflection of the disruption used for learnings.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Good&lt;/strong&gt;: what went well (i.e., process, safeguards, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bad&lt;/strong&gt;: what went poorly (i.e., process, cascading failures, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lessons&lt;/strong&gt;: what was learned (i.e., flaws in the process, missing monitoring, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action Items&lt;/strong&gt;: assigned items to be completed in a timely fashion related to the disruption.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supporting Documentation&lt;/strong&gt;: additional information (i.e., Slack Logs, Bug Reports, Screenshots, etc&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Where to Track?&lt;/h2&gt;

&lt;p&gt;To be honest, the none of this matters matter if you aren&amp;rsquo;t tracking disruptions to any capacity, just do it! Even if you have all your disruptions in a single text file, it&amp;rsquo;s better than nothing. Let&amp;rsquo;s get realistic though, we can do much better. For starters, you could opt for a spreadsheet or a basic database, maybe even a heavier integrated service like &lt;a href="https://victorops.com/"&gt;VictorOps&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;At theScore, we use a GitHub repository where each &lt;em&gt;issue&lt;/em&gt; is a disruption report. We record the aforementioned data points in each issue&amp;rsquo;s description. We decided to use GitHub as it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Has great markdown support to provide rich information (i.e., font-styles, links, images, tables).&lt;/li&gt;
&lt;li&gt;Gives us closer integration with our code if we want to link to resources in other repositories.&lt;/li&gt;
&lt;li&gt;Has built-in support for comments on an issue to better facilitate discussions.&lt;/li&gt;
&lt;li&gt;Has labels and open/close states for issues, which layers in additional categorization and grouping.&lt;/li&gt;
&lt;li&gt;Has an API to interface with (for automation and analysis).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For us, our action items become &lt;a href="https://help.github.com/articles/about-task-lists/"&gt;GitHub tasks&lt;/a&gt; with a mentioned individual or team. Issues are to be closed when all action items are resolved, and after sufficient discussion/retrospection has been carried out.&lt;/p&gt;

&lt;h2&gt;How to Track?&lt;/h2&gt;

&lt;p&gt;After a disruption, within a few days, it should be tracked. Waiting too long to track a disruption will result in fuzzy/shallow details. There much special in building up the report, although from personal experience it is good for people to jot notes down immediately after a disruption. I also find it effective to create a specific channel or chatroom in your team&amp;rsquo;s messaging application when dealing with disruptions as all the communication is located in one area.&lt;/p&gt;

&lt;p&gt;PagerDuty has some fantastic material on a &lt;a href="https://response.pagerduty.com/after/post_mortem_process/"&gt;post-mortem process&lt;/a&gt; and even a &lt;a href="https://response.pagerduty.com/after/post_mortem_template/"&gt;post-mortem template&lt;/a&gt;. They also document &lt;a href="https://response.pagerduty.com/before/different_roles/"&gt;defined roles during a disruption&lt;/a&gt;, in which the &lt;em&gt;Scribe&lt;/em&gt; is a critical role for tracking purposes.&lt;/p&gt;

&lt;p&gt;A disruption report can be a single person&amp;rsquo;s responsibility, although it usually helps to reach out to the people involved for clarifying details.&lt;/p&gt;

&lt;h1&gt;Making Sense of the Data&lt;/h1&gt;

&lt;p&gt;With all these disruptions tracked, what can we do with them? Hopefully, all the action items and retrospection have led to large gains. Additionally, there is a lot of value in the data itself, it is simply a matter of finding the signals you want to pay attention too. For example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The frequency of disruptions (per service).

&lt;ul&gt;
&lt;li&gt;What services to focus on improving resilience.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Distribution of when disruptions happen.

&lt;ul&gt;
&lt;li&gt;When to be prepared (i.e., weekend/evenings) for possible on-call resolution.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Time to detection over time.

&lt;ul&gt;
&lt;li&gt;Are the improvements being made to monitoring helping out?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;etc&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Find aspects that your organization cares about and measure them.&lt;/p&gt;

&lt;h1&gt;Improving the Process&lt;/h1&gt;

&lt;p&gt;Never stop and periodically revisit the process to make adjustments. What works for one team, might not work for others. Even though tracking a disruption can be seen as &lt;em&gt;additional&lt;/em&gt; work, it will pay itself off in time.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Automating Slack Statuses for Meetings and Focus Time</title>
    <link rel="alternate" href="https://kevinjalbert.com/automating-slack-statuses-for-meetings-and-focus-times/"/>
    <id>https://kevinjalbert.com/automating-slack-statuses-for-meetings-and-focus-times/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-10-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Slack statuses can be a powerful communication tool for setting up expectations on response times. Using Zapier we look at how we can automate Slack statuses for meetings and focus times.</description>
    <content type="html">&lt;p&gt;I use Slack statuses to communicate my &lt;em&gt;availability to respond&lt;/em&gt; to messages and to set up &lt;em&gt;expectations of my focus for a conversation&lt;/em&gt;. In an office setting, colleagues are able to see whether I&amp;rsquo;m at my desk or not, and that conveys to a certain degree how responsive I might be to messages. I work remotely a few times each week, and on those days my colleagues have even less visibility on whether I would be available or in a meeting.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve come up with a solution for two places where I can automate my Slack status to better communicate expectations and context. Hopefully, these changes will lead to fewer distractions and less ticked off colleagues.&lt;/p&gt;

&lt;h1&gt;Automating Slack Status for Meetings&lt;/h1&gt;

&lt;p&gt;I want to increase transparency in my response times (and set expectations for my colleagues) by updating my Slack status if I&amp;rsquo;m in a meeting. With Slack&amp;rsquo;s recent feature to &lt;a href="https://www.theverge.com/2018/8/30/17802308/slack-auto-expiring-status-updates-feature-change"&gt;auto-expire statuses&lt;/a&gt;, a clean solution using &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt; was possible.&lt;/p&gt;

&lt;p&gt;The following three steps will outline the &lt;em&gt;Zap&lt;/em&gt; I use to automatically update my Slack status with a meeting status.&lt;/p&gt;

&lt;h2&gt;Google Calendar - Event Start Trigger&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-google-calendar-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I use the &lt;em&gt;Google Calendar Event Start&lt;/em&gt; as our trigger, specifying the calendar where all my meetings are set within. I also set the &lt;em&gt;Time Before&lt;/em&gt; value to 16 minutes as I&amp;rsquo;m not subscribed to a high premium plan.&lt;/p&gt;

&lt;h2&gt;Zapier - Delay Until Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-delay-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I want to delay the next step (setting the status) until the actual event starts. This is needed due to how the previous step works, as it might trigger up to 16 minutes earlier than the meeting start time.&lt;/p&gt;

&lt;h2&gt;Slack - Set Status Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-slack-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I update the Slack status with information on when I will be done my meeting, as well as provide a clear status emoji. With the expiration time field, the status is cleared after the meeting is completed.&lt;/p&gt;

&lt;h2&gt;Possible Issue Due to Multi-Step Zap&lt;/h2&gt;

&lt;p&gt;I have been a user of Zapier for a while, and somehow I have the ability to make &lt;em&gt;3-step Zaps&lt;/em&gt; with the free plan. It is possible to cut the &lt;em&gt;Delay Until&lt;/em&gt; step, but there is a possibility of the &lt;em&gt;Set Status&lt;/em&gt; step running a maximum of 16 minutes earlier than the event&amp;rsquo;s start time.&lt;/p&gt;

&lt;p&gt;You could possibly mitigate this with some clever status text (i.e., &amp;ldquo;Meeting from 3:15 to 3:45&amp;rdquo;). At worse you have a meeting status &lt;em&gt;slightly&lt;/em&gt; before your meeting, which might not be a bad idea as you might be busy preparing or in-transit to a meeting room.&lt;/p&gt;

&lt;h1&gt;Automating Slack Status For Focus Time&lt;/h1&gt;

&lt;p&gt;Another place I automate Slack statuses is for focus time. While at work, there are times I need a deep focus time (i.e., being in the &lt;em&gt;zone&lt;/em&gt;). I use &lt;a href="https://pomodoneapp.com/"&gt;PomoDoneApp&lt;/a&gt; as my &lt;a href="https://francescocirillo.com/pages/pomodoro-technique"&gt;Pomodoro&lt;/a&gt; application of choice. Fortunately for me, it also interfaces with Zapier.&lt;/p&gt;

&lt;p&gt;The goal here is for colleagues to know that I&amp;rsquo;m busy and might not get back to their messages until I have a break from my deep work.&lt;/p&gt;

&lt;h2&gt;PomoDoneApp - New Timer Started Trigger&lt;/h2&gt;

&lt;p&gt;With PomoDoneApp, Zapier will trigger whenever a timer begins. There is nothing to configure here, so the setup is straight forward for this step.&lt;/p&gt;

&lt;h2&gt;Slack - Set Status Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/pomodone-slack-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;At this step, I&amp;rsquo;m just setting the appropriate status (i.e., focusing) to indicate that I&amp;rsquo;m in deep work. As per the Pomodoro technique, after the timer is up I&amp;rsquo;m free for a small break. The status expiration helps accommodate this workflow easily.&lt;/p&gt;

&lt;h1&gt;Slack Statuses While Working Remotely&lt;/h1&gt;

&lt;p&gt;So, as I mentioned earlier, I occasionally work remotely. This presents an interesting problem of conveying two statuses simultaneously. My workaround isn&amp;rsquo;t pretty but it works&amp;hellip; I simply change my Slack name to &amp;ldquo;Kevin Jalbert (WFH)&amp;rdquo; to indicate that I&amp;rsquo;m working from home that day. This move frees up my actual Slack status to be automated throughout the day.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Todoist with Keyboard Navigation via Nativefier</title>
    <link rel="alternate" href="https://kevinjalbert.com/todoist-with-keyboard-navigation-via-nativefier/"/>
    <id>https://kevinjalbert.com/todoist-with-keyboard-navigation-via-nativefier/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-09-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Todoist does not have strong keyboard navigation and shortcuts. Fortunately, there is a browser extension that augments the web client to support better keyboard navigation. This article outlines how to gain this functionality in a desktop version of Todoist using 'nativefier'.</description>
    <content type="html">&lt;p&gt;&lt;a href="https://todoist.com"&gt;Todoist&lt;/a&gt; is a powerful task manager. It offers a &lt;a href="https://itunes.apple.com/ca/app/todoist-organize-your-life/id585829637"&gt;MacOS Application&lt;/a&gt; that provides a desktop experience and a dedicated &lt;em&gt;quick task adding&lt;/em&gt; feature. I am a poweruser of the keyboard (i.e., I use &lt;a href="https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en"&gt;Vimium&lt;/a&gt; in Chrome), and my big issue is that Todoist doesn&amp;rsquo;t offer strong keyboard navigation. Fortunately, &lt;a href="https://github.com/mgsloan/todoist-shortcuts"&gt;todoist-shortcuts&lt;/a&gt; adds much-needed keyboard navigation to the web client as a browser extension.&lt;/p&gt;

&lt;p&gt;I enjoy having &lt;em&gt;dedicated tools/applications&lt;/em&gt; for tasks and tend to keep my browser for ephemeral tasks. Therefore I wanted to keep Todoist as a desktop application but with the keyboard navigation extension.&lt;/p&gt;

&lt;h2&gt;Web Application -&amp;gt; Desktop Application&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve used &lt;a href="https://github.com/jiahaog/nativefier"&gt;nativefier&lt;/a&gt; in the past to create a desktop version of various web applications. Quick searching showed the following &lt;a href="https://github.com/jiahaog/nativefier/issues/207"&gt;issue&lt;/a&gt; mentioning that adding a Chrome extention isn&amp;rsquo;t supported, although it is possible to &lt;em&gt;inject&lt;/em&gt; custom JavaScript to be executed within the newly created application.&lt;/p&gt;

&lt;p&gt;The following command will build the application while injecting &lt;a href="https://github.com/mgsloan/todoist-shortcuts/blob/v22/src/todoist-shortcuts.js"&gt;&lt;code&gt;src/todoist-shortcuts.js&lt;/code&gt;&lt;/a&gt; in it. The injected file contains all of the keyboard navigation of &lt;code&gt;todoist-shortcuts&lt;/code&gt;. In addition, other options were provided to &lt;code&gt;nativefier&lt;/code&gt; so that we have support for badge counts and bouncing the dock icon on changes when out of focus (MacOS).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight shell"&gt;&lt;code&gt;nativefier &lt;span class="s1"&gt;'https://todoist.com/'&lt;/span&gt; &lt;span class="nt"&gt;--name&lt;/span&gt; &lt;span class="s1"&gt;'Todoist'&lt;/span&gt; &lt;span class="nt"&gt;--icon&lt;/span&gt; ./todoist-icon.png &lt;span class="nt"&gt;--inject&lt;/span&gt; ./todoist-shortcuts-22/src/todoist-shortcuts.js &lt;span class="nt"&gt;--counter&lt;/span&gt; &lt;span class="nt"&gt;--bounce&lt;/span&gt; &lt;span class="nt"&gt;--single-instance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The produced application works as expected. Keyboard navigation exists within the &lt;code&gt;nativefier&lt;/code&gt; created application. Unfortunately, the badge count aspect did not&amp;hellip;&lt;/p&gt;

&lt;h3&gt;Supporting Badge Count&lt;/h3&gt;

&lt;p&gt;The reason the badge count didn&amp;rsquo;t work is because &lt;code&gt;nativefier&lt;/code&gt; is looking in the title of the window/application for the number (using a regular expression). To solve this, we will need some additional JavaScript that will propagate the number of tasks in &lt;em&gt;Today&lt;/em&gt; into the title (while handling edge cases). It isn&amp;rsquo;t the prettiest, but the following &lt;code&gt;counter.js&lt;/code&gt; snippet does the trick:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// Returns the count for the 'Today' list (defaults to 0)&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;currentCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#top_filters &amp;gt; li:nth-child(2) &amp;gt; span.item_content &amp;gt; small'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;innerText&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Returns the title without any annotated count&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;titleWithoutCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" ("&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Returns the existing count from the title (defaults to 0)&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;existingCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" ("&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Update badge count based on the number in Today&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;currentCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;titleWithoutCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;===&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;!==&lt;/span&gt; &lt;span class="nx"&gt;existingCount&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;`&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; (&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;)`&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;!==&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Update the badge every 5 seconds&lt;/span&gt;
&lt;span class="nx"&gt;setInterval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;// Update the badge when the title changes&lt;/span&gt;
&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;MutationObserver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mutations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="nx"&gt;observe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="na"&gt;subtree&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;characterData&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;childList&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unfortunately, &lt;code&gt;nativefier&lt;/code&gt; has an issue with &lt;a href="https://github.com/jiahaog/nativefier/issues/458"&gt;injecting multiple JavaScript files&lt;/a&gt;. As a workaround, we concatenate the JavaScript into one file before &lt;em&gt;injecting it&lt;/em&gt; (which fortunately works with the JavaScript we have).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nb"&gt;cat&lt;/span&gt; ./counter.js &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; todoist.js&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;cat&lt;/span&gt; ./todoist-shortcuts-22/src/todoist-shortcuts.js &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; todoist.js
nativefier &lt;span class="s1"&gt;'https://todoist.com/'&lt;/span&gt; &lt;span class="nt"&gt;--name&lt;/span&gt; &lt;span class="s1"&gt;'Todoist'&lt;/span&gt; &lt;span class="nt"&gt;--icon&lt;/span&gt; ./todoist-icon.png &lt;span class="nt"&gt;--inject&lt;/span&gt; ./todoist.js &lt;span class="nt"&gt;--counter&lt;/span&gt; &lt;span class="nt"&gt;--bounce&lt;/span&gt; &lt;span class="nt"&gt;--single-instance&lt;/span&gt; &lt;span class="nt"&gt;--overwrite&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Desktop Todoist with Keyboard Navigation&lt;/h2&gt;

&lt;p&gt;At this point, we&amp;rsquo;ve successfully wrapped the web client of Todoist for Desktop while injecting &lt;code&gt;todoist-shortcuts&lt;/code&gt;. Badge support is preserved and notifications continue to function.&lt;/p&gt;

&lt;p&gt;I still like the &lt;em&gt;quick task adding&lt;/em&gt; feature of the original Todoist application on the desktop, but unfortunately, that was outside the scope of what I could do with &lt;code&gt;nativefier&lt;/code&gt;. As a workaround, I&amp;rsquo;ve renamed the original application to &lt;code&gt;Todoist-store&lt;/code&gt; and moved the new application over with no naming conflicts. I run both applications so that I can continue to use the &lt;em&gt;quick task adding&lt;/em&gt; feature, although I hide &lt;code&gt;Todist-store&lt;/code&gt;in the tray and prevent any notifications from appearing.&lt;/p&gt;

&lt;p&gt;To simplify the process of extending/modifying/building this solution, I&amp;rsquo;ve put together the following &lt;a href="https://github.com/kevinjalbert/todoist-shortcuts-nativefier"&gt;repository on GitHub&lt;/a&gt;. I hope that Todoist simply adds better keyboard navigation in their client by default&amp;hellip; but until then, I&amp;rsquo;ll be using this solution.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Video Clubs: A Way to Keep Up</title>
    <link rel="alternate" href="https://kevinjalbert.com/video-clubs-a-way-to-keep-up/"/>
    <id>https://kevinjalbert.com/video-clubs-a-way-to-keep-up/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-08-28T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Keeping up in your industry can be hard. Conferences offer industry-leading information and the direction of the community. Attending conferences is expensive in both cost and time. Learn how to start a video club to better consume conference videos in your workplace at a sustainable pace.</description>
    <content type="html">&lt;p&gt;As a knowledge worker, a lot of our time is spent thinking about problems and solutions. We rely on pattern matching and experience while working to make the best progress we can. Is there a way to accelerate our learning and keep a pulse on new, upcoming, and innovative solutions? I will be approaching this question from a developer&amp;rsquo;s perspective, although the ideas presented here can be applied to other domains.&lt;/p&gt;

&lt;p&gt;Being aware of best practices, new techniques, alternative frameworks, and really anything in general for your domain is good. I would attribute some of my successes to &lt;em&gt;surface knowledge&lt;/em&gt; (i.e., having a high-level understanding), as it allows you to know of alternatives and possible solutions. Obviously, you would dive deeper into the area if you are going to invest more effort into it. In a way, this promotes a &lt;em&gt;just-in-time learning&lt;/em&gt; philosophy, to focus on areas as needed. Again, the key is that you &lt;em&gt;know&lt;/em&gt; of these areas.&lt;/p&gt;

&lt;h1&gt;Keeping up as Developers&lt;/h1&gt;

&lt;p&gt;I encourage developers to do the following, although from my experiences it&amp;rsquo;s common for developers to be doing at least some of these activities already:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read blog posts: low friction and easily discoverable source of information, it normally comes naturally while developing.&lt;/li&gt;
&lt;li&gt;Listen to podcasts: commuter friendly, topical and timely due to the &lt;em&gt;real-time&lt;/em&gt; nature, interviews with high-calibre people can be insightful.&lt;/li&gt;
&lt;li&gt;Read Books: a wealth of knowledge but require more time investment.&lt;/li&gt;
&lt;li&gt;Attend meetups: allows for networking with like-minded individuals, local groups, talks or workshops, typically free to attend.&lt;/li&gt;
&lt;li&gt;Attend conferences: like meetups but normally of a higher calibre and immersive, costs a lot of money to attend.&lt;/li&gt;
&lt;li&gt;Watch conference videos: talks of a conference, without the cost and networking aspects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I want to focus on the last point &amp;ndash; watching conference videos. To me, this activity presents an affordable solution to attending conferences (from a time/money perspective). Additionally, conferences sometimes have multiple tracks and so, even as an attendee, it is not possible to see all the talks. The videos from a conference are usually available a few weeks after the conference. To me, conference talks represent distilled knowledge condensed into 30-60 minutes.&lt;/p&gt;

&lt;p&gt;I would argue that it is a developer&amp;rsquo;s job to keep up with the community and to &lt;em&gt;learn&lt;/em&gt; from industry-leaders. It can be hard to find the time to watch these videos on your own (i.e., evenings or weekends). Not only is the time a constraint, but also if you are consuming a conference video by yourself you are missing out on valuable discussions with peers immediately after the talk. So in an effort to better facilitate the time for learning, I am proposing the following: to start a &lt;em&gt;video club at your workplace&lt;/em&gt;!&lt;/p&gt;

&lt;h1&gt;The Workings of a Video Club&lt;/h1&gt;

&lt;p&gt;At theScore, the way we&amp;rsquo;ve handled our video club has evolved over the years. Initially, the flow worked like so:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;See an interesting video to watch.&lt;/li&gt;
&lt;li&gt;Add video URL to video club page in wiki (&lt;a href="https://www.atlassian.com/software/confluence"&gt;Confluence&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Once a week people would gather at lunch for the video club.&lt;/li&gt;
&lt;li&gt;Watch the next video or one which the audience really wants to see.&lt;/li&gt;
&lt;li&gt;Discuss (maybe?).&lt;/li&gt;
&lt;li&gt;Continue on with the day.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This flow worked and to be honest was fine. The main issue we wanted to fix was more transparency and organization around the videos. By addressing these concerns, the idea is that we&amp;rsquo;d be able to surface the most desired videos to be watched, as well as better facilitating discussion and recording findings.&lt;/p&gt;

&lt;p&gt;The next section outlines how we&amp;rsquo;ve changed our video club to better work for developers, mainly taking advantage of GitHub and Slack. These changes have been well received, and it seems to better encourage the functioning aspects of the video club. I do want to mention that this next section is going to be highly tailored to developers.&lt;/p&gt;

&lt;h1&gt;Video Club on GitHub&lt;/h1&gt;

&lt;p&gt;We decided to move away from the wiki version of the video club to GitHub. The main reasons were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Better structure (i.e., issues, labels, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;Familiar to developers.&lt;/li&gt;
&lt;li&gt;Voting via &lt;em&gt;reactions&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Slack + GitHub integration for visibility.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Setup Repository&lt;/h2&gt;

&lt;p&gt;The first thing we need is a repository &lt;code&gt;video-club&lt;/code&gt; (or any other name you like). We only need two files in our repository:&lt;/p&gt;

&lt;p&gt;The following is the content of the &lt;code&gt;README.md&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# The Video Club
* Video club for weekly educational videos
* Place for tracking/voting/discussion
* Slack Channel #video-club

## Would like to group watch a video?
* Create an issue
* Throw some labels on it
* Get people to vote on it with the :thumbsup: reactions

## Each week the highest voted video is watched
* Discussion happens immediately afterwards
* Issue could be updated with large takeaway points
* Close the issue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following is the content of the &lt;code&gt;ISSUE_TEMPLATE.md&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;## [Video Title -- Also should be issue title](video.url)

### Description
&amp;lt;!-- Talk's description --&amp;gt;

### Time Length
&amp;lt;!-- Length of the video (i.e., 16m, 1h10m) --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Videos as Issues&lt;/h2&gt;

&lt;p&gt;&lt;img width="1001" height="692" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/issues.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;As you can see in the above image, each &lt;em&gt;GitHub Issue&lt;/em&gt; represents a video within our repository. As we have an &lt;code&gt;ISSUE_TEMPLATE.md&lt;/code&gt; each issue then follows a consistent format containing context and information about the video. Ideally, we want the inputting process for a video to be as low-friction as possible. Right now it is pretty quick to create a new issue for a video, although &lt;strong&gt;one thing I would like to do is create a bookmarklet or browser extension to pre-fill an issue based on the video URL&lt;/strong&gt;. The following image illustrates an example video in our issue format.&lt;/p&gt;

&lt;p&gt;&lt;img width="1022" height="521" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/video-issue.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;You can see that we take advantage of &lt;em&gt;Issue Labels&lt;/em&gt; as well to further categorize the videos. We&amp;rsquo;re pretty loose with their usage, but it does provide additional context and filtering capabilities. One other aspect to notice is that we use &lt;em&gt;Issue Reactions&lt;/em&gt; to &lt;em&gt;vote&lt;/em&gt; on videos that a participant would like to watch at some point. These votes are then used to help &lt;em&gt;pick the next video&lt;/em&gt;, as we will see in the next section.&lt;/p&gt;

&lt;h2&gt;Picking the Next Video&lt;/h2&gt;

&lt;p&gt;One of the main draws to using GitHub Issues is that we can vote using the reactions and then and sort the issues by &lt;em&gt;votes&lt;/em&gt; (i.e., thumbsup reactions on the issue). This approach allows the participants to weigh in on what they would like to see. The end goal is that the most highly desired videos will be watched. By sorting the open issues by votes, the process of picking the next video is pretty straightforward.&lt;/p&gt;

&lt;p&gt;&lt;img width="999" height="506" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/next-video-sorting.jpg" /&gt;&lt;/p&gt;

&lt;h2&gt;Discussion and Context&lt;/h2&gt;

&lt;p&gt;The fact that we have GitHub Issues gives us a space for discussion using &lt;em&gt;GitHub Comments&lt;/em&gt;. After the video has been watched, we carry out a 5~ minute discussion and record the high-level takeaways. Our video club accommodates remote attendees (coordination is done via Slack), and in those situations, we use video conferencing to facilitate the discussion process.&lt;/p&gt;

&lt;p&gt;Ideally, additional discussion can be carried out via more comments (even later after the video has been watched). We use GitHub for our projects, and having the videos as issues allows us to link to videos if we want to use them as references or talking points in other issues or pull requests. Finally, a video issue is closed after the initial discussion is written up for it. The following image demonstrates the aforementioned concepts.&lt;/p&gt;

&lt;p&gt;&lt;img width="782" height="630" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/completed-video.jpg" /&gt;&lt;/p&gt;

&lt;h2&gt;Slack Integration&lt;/h2&gt;

&lt;p&gt;To increase transparency and engagement, we are using the &lt;a href="https://slack.github.com/"&gt;GitHub + Slack integration&lt;/a&gt;. This allows us to have events in our &lt;code&gt;video-club&lt;/code&gt; repository to be pushed to our &lt;code&gt;#video-club&lt;/code&gt; Slack channel.&lt;/p&gt;

&lt;p&gt;When someone adds a new video, the issue&amp;rsquo;s content (following the template) lets everyone know of a new video they could vote on:
&lt;img width="640" height="420" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-new-video.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;We use &lt;a href="/slack-reminding-users-and-channels/"&gt;Slack&amp;rsquo;s channel reminders&lt;/a&gt; to ping the room to ensuring that votes are cast prior to the time we&amp;rsquo;ll watch a video. In addition, we announce a bit before what video we will watch based on the sorting of votes:
&lt;img width="760" height="555" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-video-selected.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;Discussion notes and comments are pushed through the channel to help surface further comments:
&lt;img width="635" height="490" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-video-finished.jpg" /&gt;&lt;/p&gt;

&lt;h1&gt;Starting a Video Club&lt;/h1&gt;

&lt;p&gt;So, are you are psyched to start a video club in your workplace? Now, how do you sell the idea to your boss and peers? You are trying to take 60~ minutes every week or so to watch &lt;em&gt;videos&lt;/em&gt;&amp;hellip; it doesn&amp;rsquo;t sound like a good use of work time. Again, the whole point of this is to improve yourself and that these changes will be reflected in the work you do (i.e., knowing better practices and tools).&lt;/p&gt;

&lt;p&gt;There are different ways to go about starting a video club, and honestly, it could be as straightforward as asking your boss and peers. I personally think if you can &lt;em&gt;embody&lt;/em&gt; the change, it is an easier sell to the organization and your direct manager. First thing I would do is personally find a set of high-quality videos from a conference relevant to your domain (i.e., could even be old ones). Put these out in the open as great material that everyone &lt;em&gt;should&lt;/em&gt; watch at some point (which shouldn&amp;rsquo;t be a stretch from the truth). Suggest a brown bag lunch event, everyone brings their lunch (or buys it) and watches the video during their lunch. Encourage discussion and see if there are any takeaways that might be directly related to the work at hand. Then, eventually, you start to transition to an organizational model (i.e., GitHub) and getting participation from your peers by suggesting videos.&lt;/p&gt;

&lt;p&gt;This is a cultural shift you are trying to create, therefore it could be slow. I believe the end goal is to move away from the brown bag lunch and instead to a dedicated &lt;em&gt;meeting time&lt;/em&gt; so that the video club isn&amp;rsquo;t taking up everyone&amp;rsquo;s personal time at lunch. I&amp;rsquo;ve seen various attendees drop off due to external lunch plans. Hopefully, a higher attendance can be achieved if it&amp;rsquo;s a normal meeting time. Overall, I would say either you&amp;rsquo;ll get your manager/organization to buy into the idea, or you will be stuck doing brown bag lunches. &lt;strong&gt;In either case, &lt;em&gt;you&lt;/em&gt; will be improving and investing in yourself.&lt;/strong&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 4]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-4/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-4/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-07-18T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the last of four parts on GraphQL Persisted Queries with HTTP Caching. We end by adding HTTP caching to our Express, Rails and React applications.</description>
    <content type="html">&lt;p&gt;This is the last part of a four-part series on GraphQL Persisted Queries with HTTP Caching. As a recap of &lt;a href="/graphql-persisted-queries-with-http-caching-part-3/"&gt;part three&lt;/a&gt;, we created a Rails application capable of handling persisted queries.&lt;/p&gt;

&lt;p&gt;In part four we will cover the following topics:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add HTTP Caching to React Application&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Express Server&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Rails Server&lt;/li&gt;
&lt;li&gt;Alternative Caching with Gateways&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Caching with GraphQL&lt;/h1&gt;

&lt;p&gt;There are different ways to &lt;em&gt;cache&lt;/em&gt; with GraphQL:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.apollographql.com/docs/react/advanced/caching.html"&gt;Caching on the Apollo client&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mgiroux.me/2016/graphql-query-caching-with-rails/"&gt;Caching the parsed and validated GraphQL query&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chatterbugapp/cacheql"&gt;Caching field and response resolutions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Amongst other mechanisms and techniques.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our situation, we&amp;rsquo;re interested in HTTP caching, and the way to achieve this is to make our GraphQL network requests use &lt;code&gt;GET&lt;/code&gt; instead of &lt;code&gt;POST&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The main benefit for HTTP caching is that it allows CDNs and reverse proxy&amp;rsquo;s (i.e., &lt;a href="https://varnish-cache.org/"&gt;Varnish&lt;/a&gt;) to cache intermediate responses based on the response&amp;rsquo;s headers (i.e., &lt;code&gt;Cache-Control&lt;/code&gt;). This results in fewer requests hitting your server as the results might be cached, perfect for scaling your API. Even a short cache (i,e., &amp;lt; 10 seconds) could be extremely valuable as this cache could be shared across all consumers of the API.&lt;/p&gt;

&lt;p&gt;I want to bring up an article by &lt;a href="https://twitter.com/_CoreyClark"&gt;Corey Clark&lt;/a&gt; which tackles a very similar problem on how to use &lt;a href="https://medium.com/@coreyclark/graphql-persisted-queries-using-get-requests-8a6704aba9eb"&gt;&lt;code&gt;GET&lt;/code&gt; requests with GraphQL Persisted Queries&lt;/a&gt;. Both the current post and Corey&amp;rsquo;s article reach a similar state in achieving HTTP cacheability using &lt;code&gt;GET&lt;/code&gt; requests.&lt;/p&gt;

&lt;p&gt;In the following sections, we will augment our Express and Rails servers as well as our React application to use &lt;code&gt;GET&lt;/code&gt; requests. To simplify things, we&amp;rsquo;re going to apply a simple 10-second cache on all our responses (ideally you could tailor this to the individual query). In addition, we&amp;rsquo;re going to make an assumption that we don&amp;rsquo;t have any personalized data in our query responses.&lt;/p&gt;

&lt;h2&gt;Add HTTP Caching to React Application&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/5cbb630c4780d20bc2747b0b62035a3702e87a3b"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fortunately, the &lt;code&gt;apollo-link-persisted-queries&lt;/code&gt; link has a simple option (&lt;code&gt;useGETForHashedQueries&lt;/code&gt;) to enable &lt;code&gt;GET&lt;/code&gt; requests for queries (but not mutations):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;ApolloClient&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
  &lt;span class="na"&gt;link&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;createPersistedQueryLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;useGETForHashedQueries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt; &lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="nx"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nx"&gt;createHttpLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'http://localhost:5000/graphql'&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="na"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;InMemoryCache&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now the outbound requests look like the following (a bit messy, but gets the job done):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;http://localhost:5000/graphql?operationName=ConsolesByYear&amp;amp;variables=%7B%22afterYear%22%3A1990%2C%22beforeYear%22%3A2000%7D&amp;amp;extensions=%7B%22persistedQuery%22%3A%7B%22version%22%3A1%2C%22sha256Hash%22%3A%22a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80%22%7D%7D
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To better see the requests being cached on the HTTP layer, we&amp;rsquo;re going to modify the &lt;code&gt;Query&lt;/code&gt; in our &lt;code&gt;ConsoleContainer&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;Query&lt;/span&gt; &lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;QUERY&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nx"&gt;variables&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;afterYear&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;beforeYear&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt; &lt;span class="nx"&gt;fetchPolicy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'network-only'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By adding &lt;code&gt;fetchPolicy&lt;/code&gt; of &lt;code&gt;network-only&lt;/code&gt; the &lt;code&gt;apollo-client&lt;/code&gt; will not cache responses, and thus each query will be sent to the GraphQL API.&lt;/p&gt;

&lt;h2&gt;Add HTTP Caching to Express Server&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/0bf8d6bccc5649b00dda77b4dfdce523c22b4796"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We have to do a couple things to get our Express server in shape to serve &lt;code&gt;GET&lt;/code&gt; requests. First thing is to remove the &lt;code&gt;bodyParser&lt;/code&gt; middleware as we aren&amp;rsquo;t parsing a &lt;code&gt;POST&lt;/code&gt; anymore. We will also adjust our &lt;code&gt;GraphQLServer&lt;/code&gt; options to toggle the &lt;code&gt;getEndpoint&lt;/code&gt;, which adds a &lt;code&gt;GET&lt;/code&gt; endpoint using our defined GraphQL route. Finally, we have to modify our &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; to be on the &lt;code&gt;GET&lt;/code&gt; route for &lt;code&gt;/graphql&lt;/code&gt;. Those changes looks like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// server.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'graphql-yoga'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/typeDefs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/resolvers'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./persistedQueriesMiddleware'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;getEndpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;endpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;playground&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/playground'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;`Server started, listening on port &lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; for incoming requests.`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We also have to modify our &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; itself to parse the &lt;code&gt;GET&lt;/code&gt; query parameters and specify the response&amp;rsquo;s &lt;code&gt;Cache-Control&lt;/code&gt; header for a &lt;code&gt;max-age&lt;/code&gt; of 10 seconds:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// persistedQueriesMiddleware.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'lodash'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./extracted_queries.json'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Handling request to: '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Cache-Control'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'public, max-age=10'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;extensions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;querySignature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sha256Hash&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;querySignature&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt;
  &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exports&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Add HTTP Caching to Rails Server&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/c3bcc3588012a9b4b22bd582c80de3e0dd208078"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For our Rails server, we have a few small changes to make to allow for &lt;code&gt;GET&lt;/code&gt; requests. First, we&amp;rsquo;ll add a new route to allow for &lt;code&gt;GET&lt;/code&gt; requests, under the same URL and controller action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="c1"&gt;# .. other routes&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
  &lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Like before, we handle the persisted queries within the &lt;code&gt;GraphqlController&lt;/code&gt;. We need to tweak the controller to conform to the new query parameters structure of the React application&amp;rsquo;s requests. We will also add an &lt;code&gt;expires_in&lt;/code&gt; to add in the 10-seconds of &lt;code&gt;max-age&lt;/code&gt; for the response&amp;rsquo;s &lt;code&gt;Cache-Control&lt;/code&gt; header:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;expires_in&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;public: &lt;/span&gt;&lt;span class="kp"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;extensions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:extensions&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
      &lt;span class="n"&gt;signature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"persistedQuery"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"sha256Hash"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find_by!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;signature&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;

    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Alternative Caching with Gateways&lt;/h2&gt;

&lt;p&gt;I didn&amp;rsquo;t mention &lt;a href="https://www.apollographql.com/engine"&gt;Apollo Engine&lt;/a&gt;, but this is a recent development in the GraphQL caching space. It provides a layer which sits in front of your GraphQL server and handles caching, query execution tracing, and error tracking. It is a paid solution if you need to handle more than 1 million requests per month.&lt;/p&gt;

&lt;p&gt;Part of the secret sauce for caching with Apollo Engine is that it introduced the &lt;a href="https://github.com/apollographql/apollo-cache-control"&gt;Apollo Cache Control&lt;/a&gt; GraphQL extension. This allows the GraphQL API to return cache hints on a per field-level. Effectively, this allows the caching to be smarter than simply a blanket solution.&lt;/p&gt;

&lt;p&gt;For additional reading on these technologies and techniques, I recommend the following article on &lt;a href="https://dev-blog.apollodata.com/caching-graphql-results-in-your-cdn-54299832b8e2"&gt;Caching GraphQL Results in your CDN&lt;/a&gt; as it uses Automatic Persisted Queries, Apollo Cache Control, and Apollo Engine.&lt;/p&gt;

&lt;p&gt;Another paid solution (if you exceed 5,000 requests per months) is &lt;a href="https://fastql.io/"&gt;FastQL&lt;/a&gt;. This is a new gateway solution which acts as its own CDN, handling caching and expiration of fields. You are able to manually invalidate field-level caches through an API, or automatically invalidate by sending mutations through their CDN (which expires fields related to the mutation object type).&lt;/p&gt;

&lt;h1&gt;Reflection&lt;/h1&gt;

&lt;p&gt;There are a lot of options available for caching with GraphQL. It is possible to do so at different layers of the flow using different techniques and technologies. In this last post of the series we mainly took a look at HTTP caching. By enabling &lt;code&gt;GET&lt;/code&gt; requests we were half-way there &amp;ndash; the last bit remaining is attaching the appropriate &lt;code&gt;Cache-Control&lt;/code&gt; headers. Admittedly, we took an easy approach of blanketing all responses with a 10 second &lt;code&gt;max-age&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Depending on your situation, you might need to further explore the field-level caching options like Apollo Cache Control, or even using a Gateway to help out, like FastQL. Even though being aware of the data within your queries is important, is it all cacheable? If you have personalized data you have to approach this in a different way. There might not be value in caching if every response is personalized to a user, or maybe you have to split your queries into two queries (i.e., personalized, non-personalized). The cache configuration (i.e., CDN and/or a reverse proxy) is a huge piece we skipped over, but it likely will need some tweaking for your specific use cases (i.e., split caching based on the header).&lt;/p&gt;

&lt;p&gt;Overall, I am pleased with the solutions we arrived too. We built a simple GraphQL API in Express and Rails. Both of these can communicate with a React application using persisted queries. Our Express server used a JSON file for its data and persisted queries, while for our Rails server we had everything in a database. We overcame the issues with the existing tooling for determining a signature for each query, and created the ability to synchronize persisted queries via HTTP &lt;code&gt;POST&lt;/code&gt; requests. We were able to implement &lt;code&gt;GET&lt;/code&gt; requests and apply a 10-second cache for intermediate CDN and reverse proxies.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 3]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-3/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-3/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-07-17T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the third of four parts on GraphQL Persisted Queries with HTTP Caching. We continue our journey with creating a Rails GraphQL API, synchronizing queries to it, and adapting it to use persisted queries.</description>
    <content type="html">&lt;p&gt;This is the third part of a four-part series on GraphQL Pesisted Queries with HTTP Caching. As a recap of &lt;a href="/graphql-persisted-queries-with-http-caching-part-2/"&gt;part two&lt;/a&gt;, we created an Express server and React application, both using persisted queries.&lt;/p&gt;

&lt;p&gt;In part three we will cover the following topics:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setup Rails Server&lt;/li&gt;
&lt;li&gt;Synchronize GraphQL Queries to Rails Server&lt;/li&gt;
&lt;li&gt;Refactor Rails Server to use Persisted Queries&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Setup Rails Server&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/5f78ac6dd2840a8690d82e4b50a752471332c8c2"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We&amp;rsquo;ll create a basic Rails server that uses &lt;a href="https://github.com/rmosolgo/graphql-ruby"&gt;&lt;code&gt;graphql-ruby&lt;/code&gt;&lt;/a&gt;. We will gloss over the busy work of setting up the models, database, and GraphQL types. First, we have our route defined that will accept &lt;code&gt;POST&lt;/code&gt; requests to &lt;code&gt;/graphql&lt;/code&gt; and passes them to our controller.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# config/routes.rb&lt;/span&gt;
&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The controller then extracts the variables, query, and operation name from the request&amp;rsquo;s parameters. All this information is then executed against the GraphQL schema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="kp"&gt;private&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ambiguous_param&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# ... Generated code provided by graphql-ruby's graphql:install&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Synchronize GraphQL Queries to Rails Server&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/9f72e132f88e6f551e07700fd35539890d9e2a44"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To accommodate persisted queries, we will have to &lt;em&gt;synchronize&lt;/em&gt; the queries from our React application to our Rails server. Fortunately, &lt;code&gt;persistgraphql-signature-sync&lt;/code&gt; (our script from earlier to extract queries) does this already.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is possible to sync the persisted queries to a specified endpoint. The endpoint needs to accept a POST request with body parameters of query and signature.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will need to do a few things to support this new synchronization endpoint.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create a new &lt;code&gt;PersistedQuery&lt;/code&gt; model and migration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/models/persisted_query.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PersistedQuery&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationRecord&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# db/migrate/20180617011135_create_persisted_queries.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CreatePersistedQueries&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ActiveRecord&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Migration&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;5.2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;change&lt;/span&gt;
    &lt;span class="n"&gt;create_table&lt;/span&gt; &lt;span class="ss"&gt;:persisted_queries&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;string&lt;/span&gt; &lt;span class="ss"&gt;:signature&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;index: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;unique: &lt;/span&gt;&lt;span class="kp"&gt;true&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;string&lt;/span&gt; &lt;span class="ss"&gt;:query&lt;/span&gt;

      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;timestamps&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We will store the persisted queries in this newly created table &amp;ndash; notice that we have a unique index on the signature. Now let&amp;rsquo;s add the required route and controller that will accept the synchronization request.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# config/routes.rb&lt;/span&gt;
&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="c1"&gt;# ... existing routes&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql_persist"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql_persist#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_persist_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlPersistController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;document&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;valid_query?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:signature&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="ss"&gt;query: &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;

      &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;attributes&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="vi"&gt;@errors&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="ss"&gt;status: &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="ss"&gt;status: &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="kp"&gt;private&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;valid_query?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;document: &lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;validator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;StaticValidation&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Validator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;schema: &lt;/span&gt;&lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;validator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;validate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:errors&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="vi"&gt;@errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="ss"&gt;:message&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="vi"&gt;@errors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;empty?&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this controller, we are parsing out the &lt;em&gt;query&lt;/em&gt; and validating it against our schema. If the query is okay from a schema perspective, then we create a new &lt;code&gt;PersistedQuery&lt;/code&gt; database record with the &lt;code&gt;query&lt;/code&gt; and the &lt;code&gt;signature&lt;/code&gt;. When we get to using the persisted queries, we can do a quick look up and pull the query to be used.&lt;/p&gt;

&lt;p&gt;We can now run the &lt;code&gt;persistgraphql-signature-sync&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;node index.js --input-path=../react-graphql/src --sync-endpoint=http://localhost:3000/graphql_persist
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will attempt to synchronize each query to the server. It is not the prettiest, but the command will print out the server&amp;rsquo;s response for each query.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Synching persisted query a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80
{ id: 1,
  signature: 'a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80',
  query: 'query ConsolesByYear($afterYear: Int, $beforeYear: Int) {\n  consoles(afterYear: $afterYear, beforeYear: $beforeYear) {\n    ...ConsoleFieldsFragment\n    company {\n      name\n      __typename\n    }\n    __typename\n  }\n}\n\nfragment ConsoleFieldsFragment on Console {\n  name\n  releaseYear\n  __typename\n}\n',
  created_at: '2018-07-03T19:52:54.717Z',
  updated_at: '2018-07-03T19:52:54.717Z' }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Refactor Rails Server to use Persisted Queries&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/802dcc0d9aef28b117f926d7638a4a2115d304e1"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The finish line is near! Our Rails server has the queries persisted in the database. Now we just have to adjust our &lt;code&gt;GraphqlController&lt;/code&gt; to pull the appropriate query when receiving the persisted query request from our React application.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;signature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:extensions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;:persistedQuery&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;:sha256Hash&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find_by!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;signature&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;

    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="c1"&gt;# ... rest of class&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our controller&amp;rsquo;s action now handles the situation when we don&amp;rsquo;t have a query present, which is the case when we&amp;rsquo;re using persisted queries. In this situation, we pull out the &lt;code&gt;sha256Hash&lt;/code&gt; value from the parameters and look up the persisted query. We then execute the persisted query&amp;rsquo;s query against the schema.&lt;/p&gt;

&lt;p&gt;In the event that we want to &lt;em&gt;lock down&lt;/em&gt; the API to only use persisted queries, we can use a conditional like &lt;code&gt;Rails.env.production?&lt;/code&gt; to gate the flow, allowing only the persisted queries through.&lt;/p&gt;

&lt;h1&gt;Reflection&lt;/h1&gt;

&lt;p&gt;In this post, we created a Rails server that exposes a GraphQL API. We used &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/tree/master/persistgraphql-signature-sync"&gt;&lt;code&gt;persistgraphql-signature-sync&lt;/code&gt;&lt;/a&gt; to assist in synchronizing the queries from the React application (that we built in &lt;a href="/graphql-persisted-queries-with-http-caching-part-2/"&gt;part two&lt;/a&gt;) to our Rails server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; there does exist a paid pro version of &lt;code&gt;graphql-ruby&lt;/code&gt; called &lt;a href="http://graphql.pro/"&gt;GraphQL::Pro&lt;/a&gt;, which has its own support for &lt;a href="http://graphql-ruby.org/operation_store/overview"&gt;persisted queries&lt;/a&gt;. It is a great solution as it covers synchronization of queries, admin dashboard, and connection to clients (Apollo/Relay). If you can afford the cost and want an &lt;em&gt;off the shelf&lt;/em&gt; solution, it is something you could consider. For the purpose of this article, however, we will skip out on it.&lt;/p&gt;

&lt;p&gt;In the next and last part of this series, we will look at the final goal of adding HTTP caching to our GraphQL API servers. With HTTP caching we can lessen the load on our servers and offer faster response times to the consumers of the API.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 2]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-2/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-2/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-07-16T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the second of four parts on GraphQL Persisted Queries with HTTP Caching. We'll setup a React application and Express server, both using GraphQL. We will refactor these applications to support persisted queries.</description>
    <content type="html">&lt;p&gt;This is the second part of a four part series on GraphQL Persisted Queries with HTTP Caching. As a recap of &lt;a href="/graphql-persisted-queries-with-http-caching-part-1/"&gt;part one&lt;/a&gt;, we described some issues with GraphQL and how persisted queries can be a solution for them. We also covered what persisted queries were from a high-level.&lt;/p&gt;

&lt;p&gt;In part two we will cover the following topics:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setup Express Server&lt;/li&gt;
&lt;li&gt;Setup React Application&lt;/li&gt;
&lt;li&gt;Refactor React Application to use Persisted Queries&lt;/li&gt;
&lt;li&gt;Extract GraphQL Queries from Client&lt;/li&gt;
&lt;li&gt;Refactor Express Server to use Persisted Queries&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Setup Express Server&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/5ac1a2a8dcc1757d145503ca0d209bcccca0ed97"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To begin, we&amp;rsquo;re going to setup up a very simple Express server that&amp;rsquo;ll serve up a GraphQL API. Let&amp;rsquo;s break down the following file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// server.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'graphql-yoga'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/typeDefs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/resolvers'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;endpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;playground&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/playground'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;`Server started, listening on port &lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; for incoming requests.`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have our GraphQL types and resolvers defined under the &lt;code&gt;./graphql&lt;/code&gt; directory. The resolvers are pulling data from &lt;code&gt;data.json&lt;/code&gt;, which is just an easier way to get this API started. In our example, we&amp;rsquo;re serving up data on video game consoles, so the data doesn&amp;rsquo;t change that often.&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;graphql-yoga&lt;/code&gt; we can create a &lt;code&gt;GraphQLServer&lt;/code&gt;, supply it with the type definitions and resolvers. We set a couple of &lt;em&gt;options&lt;/em&gt; then we start the server.&lt;/p&gt;

&lt;h1&gt;Setup React Application&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/c992730643a39f72bd5f5b6e335eb103b3646949"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To take advantage of our Express Server that is exposing a GraphQL API, we&amp;rsquo;re going to create a simple React application to use it. We&amp;rsquo;ll use &lt;code&gt;create-react-app&lt;/code&gt; for our foundation, and add in &lt;code&gt;react-apollo&lt;/code&gt; and &lt;code&gt;apollo-boost&lt;/code&gt; to bootstrap the GraphQL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; we need to use the &lt;a href="https://github.com/facebook/create-react-app/pull/3909"&gt;&lt;em&gt;next&lt;/em&gt; version (2.x) of &lt;code&gt;react-scripts&lt;/code&gt; so that we can take advantage of a &lt;code&gt;graphql-tag/loader&lt;/code&gt;&lt;/a&gt; to load up &lt;a href="https://dev-blog.apollodata.com/5-benefits-of-static-graphql-queries-b7fa90b0b69a"&gt;static &lt;code&gt;.graphql&lt;/code&gt; files&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll first initialize our Apollo client and render our &lt;code&gt;App&lt;/code&gt; to the DOM. In addition, we need to set up the Apollo Client and point it to our GraphQL API. The following &lt;code&gt;index.js&lt;/code&gt; file accomplishes all this setup:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="c1"&gt;// index.js&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;React&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'react'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;ReactDOM&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'react-dom'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;registerServiceWorker&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'./registerServiceWorker'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;ApolloClient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;InMemoryCache&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'apollo-boost'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;ApolloProvider&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'react-apollo'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;createHttpLink&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'apollo-link-http'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;App&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'./components/App'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="s1"&gt;'./index.css'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;ApolloClient&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
  &lt;span class="na"&gt;link&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;createHttpLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'http://localhost:5000/graphql'&lt;/span&gt; &lt;span class="p"&gt;}),&lt;/span&gt;
  &lt;span class="na"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;InMemoryCache&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;AppWithProvider&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;ApolloProvider&lt;/span&gt; &lt;span class="na"&gt;client=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;client&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;App&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nc"&gt;ApolloProvider&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nx"&gt;ReactDOM&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;AppWithProvider&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;,&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'root'&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nx"&gt;registerServiceWorker&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Nothing special is happening in our &lt;code&gt;App&lt;/code&gt; component, as we&amp;rsquo;re just creating some input controls and passing the data to our &lt;code&gt;ConsoleContainer&lt;/code&gt; component. All our GraphQL data loading and usage is handled within the &lt;code&gt;ConsoleContainer&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="c1"&gt;// components/ConsoleContainer.js&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;React&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'react'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;PropTypes&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'prop-types'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;Query&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'react-apollo'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;QUERY&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'../graphql/ConsolesByYear.graphql'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;ConsolesAndCompany&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;afterYear&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;beforeYear&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;Query&lt;/span&gt; &lt;span class="na"&gt;query=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;QUERY&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="na"&gt;variables=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;afterYear&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;beforeYear&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="na"&gt;fetchPolicy=&lt;/span&gt;&lt;span class="s1"&gt;'network-only'&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;loading&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'Error!'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;loading&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'Loading'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

      &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;React&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Fragment&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
          &lt;span class="si"&gt;{&lt;/span&gt;
            &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;consoles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;console&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
              &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;key=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Release Year: &lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;releaseYear&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Company: &lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;company&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h4&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;br&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
              &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nc"&gt;React&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Fragment&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nc"&gt;Query&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nx"&gt;ConsolesAndCompany&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;propTypes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="na"&gt;afterYear&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;PropTypes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="na"&gt;beforeYear&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;PropTypes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;number&lt;/span&gt; &lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="k"&gt;default&lt;/span&gt; &lt;span class="nx"&gt;ConsolesAndCompany&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that we&amp;rsquo;re loading the &lt;code&gt;QUERY&lt;/code&gt; from a static file. The &lt;code&gt;Query&lt;/code&gt; component then allows the Apollo client to handle the networking, storage, and retrieval of the query. Our component finally renders new &lt;code&gt;React.Fragments&lt;/code&gt; to the DOM with the resolved data.&lt;/p&gt;

&lt;h1&gt;Refactor React Application to use Persisted Queries&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/f8b91be248c3b5c41813fc01dd99f05e3f62bf69"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the last two sections we created a simple React application using Apollo client that uses a GraphQL API being served on Express. With a small change on our React application we can make it &lt;em&gt;persisted query&lt;/em&gt; enabled.&lt;/p&gt;

&lt;p&gt;We take advantage of the &lt;a href="https://github.com/apollographql/apollo-link-persisted-queries"&gt;&lt;code&gt;apollo-link-persisted-queries&lt;/code&gt;&lt;/a&gt; (an &lt;em&gt;Apollo Link&lt;/em&gt;) to modify the Apollo client. While it isn&amp;rsquo;t &lt;em&gt;too difficult&lt;/em&gt; to roll our own implementation, it is best to lean on community supported projects. Using this package will help us narrow down what our future implementation needs to conform to on the server-side. In addition, it provides some &lt;em&gt;portability/compatibility&lt;/em&gt; with different projects due to being a community solution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// index.js&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;createPersistedQueryLink&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="s1"&gt;'apollo-link-persisted-queries'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;// ... rest of file&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;ApolloClient&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
  &lt;span class="na"&gt;link&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;createPersistedQueryLink&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nx"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nx"&gt;createHttpLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'http://localhost:5000/graphql'&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="na"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;InMemoryCache&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;

&lt;span class="c1"&gt;// ... rest of file&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point our React application will be sending outbound &lt;code&gt;POST&lt;/code&gt; requests with the following body:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
  extensions: {
    persistedQuery: {
      version: 1,
      sha256Hash: "a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80"
    }
  },
  operationName: "ConsolesByYear",
  variables: {
    afterYear: 1990,
    beforeYear: 1999
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have our &lt;code&gt;operationName&lt;/code&gt;, &lt;code&gt;variables&lt;/code&gt; and the &lt;code&gt;extensions&lt;/code&gt; properties present. Within the &lt;code&gt;extensions&lt;/code&gt; property, we really only care about the &lt;code&gt;persistedQuery.sha256Hash&lt;/code&gt; value. The &lt;code&gt;sha256Hash&lt;/code&gt; value is automatically computed on-the-fly based on the outgoing query (it is worth noting you can &lt;a href="https://github.com/apollographql/apollo-link-persisted-queries#build-time-generation"&gt;calculate the hashes at build-time&lt;/a&gt;). Thus, we now need a way to identify the queries by this signature on the server.&lt;/p&gt;

&lt;h1&gt;Extract GraphQL Queries from React Application&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/078b3d2784add9b54b831b7e0b662ebea2bd9d4e"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can use the &lt;a href="https://github.com/apollographql/persistgraphql"&gt;persistgraphql&lt;/a&gt; tool from Apollo to help extract queries from the client application. This tool recursively scans a directory and looks for GraphQL queries (i.e., &lt;code&gt;.graphql&lt;/code&gt; files), then it generates a JSON file of &lt;code&gt;query_string&lt;/code&gt; keys mapped to &lt;code&gt;id&lt;/code&gt; values. Unfortunately, this tool&amp;rsquo;s major flaw is that the &lt;code&gt;id&lt;/code&gt; ends up being an auto-incremented number:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight json"&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"&amp;lt;query_string_1&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"&amp;lt;query_string_2&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"&amp;lt;query_string_3&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Auto-incrementing ids aren&amp;rsquo;t going to uniquely identify the query string, thus causing long-term concerns when you need to extract the queries multiple times or from multiple clients. Ideally, you could use some cryptographic hash function to come up with the unique ids, which effectively becomes the query&amp;rsquo;s signature). Currently, there are GitHub issues discussing these concerns (&lt;a href="https://github.com/apollographql/persistgraphql/pull/35"&gt;pull request #35&lt;/a&gt; and &lt;a href="https://github.com/apollographql/persistgraphql/issues/34"&gt;issue #34&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;There are general questions and concerns with the tool&amp;rsquo;s operation and how to use the output:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How do you sync them to the server (&lt;a href="https://github.com/apollographql/persistgraphql/issues/52"&gt;issue #52&lt;/a&gt;)?&lt;/li&gt;
&lt;li&gt;How do you use them in the client (&lt;a href="https://github.com/apollographql/persistgraphql/issues/42"&gt;issue #42&lt;/a&gt;)?&lt;/li&gt;
&lt;li&gt;How can you retain previous queries for a build process (&lt;a href="https://github.com/apollographql/persistgraphql/issues/17"&gt;issue #17&lt;/a&gt;)?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apollo has another tool, &lt;a href="https://github.com/apollographql/apollo-codegen"&gt;apollo-codegen&lt;/a&gt;, that handles extracting queries for the purpose of generating code for other languages and types (i.e., Swift, Scala, Flow, etc&amp;hellip;). It has been brought up in &lt;a href="https://github.com/apollographql/apollo-codegen/issues/314"&gt;issue #314&lt;/a&gt; that a unification of &lt;code&gt;persistgraphql&lt;/code&gt; and &lt;code&gt;apollo-codegen&lt;/code&gt; would be ideal. In an article titled &lt;a href="https://leoasis.github.io/posts/2018/04/27/graphql-persisted-documents/"&gt;GraphQL Persisted Documents&lt;/a&gt; (by &lt;a href="https://twitter.com/leogcrespo"&gt;Leonardo Garcia Crespo&lt;/a&gt;), the landscape for extracting and using persisted queries can be confusing.&lt;/p&gt;

&lt;p&gt;For the purpose of what we want to do, we will reuse the existing logic that &lt;code&gt;persistgraphql&lt;/code&gt; has to extract the queries and add in a post-process that will determine a unique signature for each query to match what we need. I created a script, &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/tree/master/persistgraphql-signature-sync"&gt;&lt;code&gt;persistgraphql-signature-sync&lt;/code&gt;&lt;/a&gt;, to extract the queries from the client and augmented the &lt;code&gt;id&lt;/code&gt;s to be a hash of the query acting as the unique signature. A SHA 256 hashing algorithm is used so that the generated hash value is the same as the ones generated by &lt;code&gt;apollo-link-persisted-queries&lt;/code&gt;. It also handles synchronization of queries to an endpoint, which we will explore in a later section.&lt;/p&gt;

&lt;p&gt;The following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;node index.js --input-path=../react-graphql/src --output-file=./extracted_queries.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;produces a JSON file holding the query strings and their signatures:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight json"&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"query ConsolesByYear($afterYear: Int, $beforeYear: Int) {&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;  consoles(afterYear: $afterYear, beforeYear: $beforeYear) {&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;    ...ConsoleFieldsFragment&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;    company {&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;      name&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;      __typename&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;    }&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;    __typename&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;  }&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;fragment ConsoleFieldsFragment on Console {&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;  name&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;  releaseYear&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;  __typename&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80"&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Refactor Express Server to use Persisted Queries&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/a386f13fdc4e97ff0ceb4f159038eb924ced8386"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We now have our &lt;code&gt;extracted_queries.json&lt;/code&gt; file containing our mapping of queries to signatures. We can go back and refactor our express server to use the output file containing the mapping to support persisted queries.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'graphql-yoga'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;bodyParser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'body-parser'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/typeDefs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/resolvers'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./persistedQueriesMiddleware'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;endpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;playground&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/playground'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;bodyParser&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;`Server started, listening on port &lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; for incoming requests.`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have added two things here:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We use the &lt;code&gt;bodyParser&lt;/code&gt; middleware that will allow us to access the &lt;code&gt;body&lt;/code&gt; parameters on &lt;code&gt;POST&lt;/code&gt; requests.&lt;/li&gt;
&lt;li&gt;We have a new &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; that attaches onto the &lt;code&gt;/graphql&lt;/code&gt; &lt;code&gt;POST&lt;/code&gt; route.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We add the first middleware so that we can access the &lt;code&gt;req.body&lt;/code&gt; in our custom &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; middleware.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// persistedQueriesMiddleware.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'lodash'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./extracted_queries.json'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Handling request to: "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;querySignature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sha256Hash&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;querySignature&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt;
  &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exports&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Recall the persisted query request body from our React application. We need to pull out the &lt;code&gt;sha256Hash&lt;/code&gt; value as our signature and do a lookup in our &lt;code&gt;extracted_queries.json&lt;/code&gt; file for the matching query. If we find a match, then we can set the &lt;em&gt;query&lt;/em&gt; to the actual query string and pass the request through to the underlying server to be resolved.&lt;/p&gt;

&lt;h1&gt;Reflection&lt;/h1&gt;

&lt;p&gt;At this point we&amp;rsquo;ve built:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An Express server that exposes a GraphQL API.&lt;/li&gt;
&lt;li&gt;A React application that uses Apollo to communicate with our GraphQL API.&lt;/li&gt;
&lt;li&gt;A script to help to with extracting persisted queries from our React application.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our Express server is using a static file, &lt;code&gt;extracted_queries.json&lt;/code&gt;, to do the mapping of the query to the signature. While this approach gets the job done, you might want to take it to the next level where this information is stored in a database (or similar storage). This adaptation comes with the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If we&amp;rsquo;re using a database, it becomes possible to create more analytics and administration around persisted queries.&lt;/li&gt;
&lt;li&gt;If you have multiple clients, they would all produce their own JSON file of persisted queries. You will then have to track/manage/merge these and possible commit them to your server code.&lt;/li&gt;
&lt;li&gt;Each time you update your persisted queries you will require a restart or redeployment of the server. With a database synchronization approach, you can send the queries to be persisted while the server is running.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will take a look at the next iteration of our persisted queries implementation, one that&amp;rsquo;ll use synchronization &amp;ndash; using a Rails server backed by a database. We will cover this in the third part of our series.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 1]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-1/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-1/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-07-15T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the first of four parts on GraphQL Persisted Queries with HTTP Caching. We start by describing some problems with GraphQL due to its flexibility, and how we can solve the issues with persisted queries.</description>
    <content type="html">&lt;p&gt;GraphQL is a fast growing API specification, with aims of replacing REST APIs. A GraphQL server describes the data capabilities through the use of a type system and resolvers. A client is able to send a descriptive GraphQL query of what they want. The structure of the response then matches the query, providing a predictable result. There are many benefits to GraphQL servers and clients, to which I am not going to cover here as there is plenty of material on the Internet talking about those.&lt;/p&gt;

&lt;p&gt;This four-part blog post series is specifically covering the topic of &lt;em&gt;GraphQL Persisted Queries&lt;/em&gt;. A persisted query is a slight modification to the GraphQL specification that allows for better performance and security, at the cost of less flexibility. I will cover a bit of history regarding persisted GraphQL queries, along with the problems it solves. We will look at how to implement persisted queries in Rails and Express. As an extension to persisted queries, we will look at how to adapt them to take advantage of HTTP caching.&lt;/p&gt;

&lt;h1&gt;Problems with GraphQL&lt;/h1&gt;

&lt;p&gt;GraphQL presents a flexible endpoint to which clients can send queries, however, this flexibility comes at a cost. The following three concerns are specifically targeting performance and security:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Queries could be large (i.e., data being sent) when compared to a standard REST endpoint&lt;/li&gt;
&lt;li&gt;Queries could be inefficiently constructed (i.e., resource expensive)&lt;/li&gt;
&lt;li&gt;Queries could be maliciously constructed (i.e., circular in nature)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a consumer of a GraphQL API, it possible to construct &lt;em&gt;any query&lt;/em&gt; for the server to process. You can hope that the consumers are doing their best to create good queries, but in a public API that might not be the case. You might have ill-informed users creating very expensive queries, or even a bad actor trying to timeout or cripple your server by sending deeply cyclical queries.&lt;/p&gt;

&lt;p&gt;There are several ways to mitigate these issues, as further outlined by &lt;a href="https://twitter.com/mxstbr"&gt;Max Stoiber&amp;rsquo;s&lt;/a&gt; article on &lt;a href="https://dev-blog.apollodata.com/securing-your-graphql-api-from-malicious-queries-16130a324a6b"&gt;&lt;em&gt;Securing Your GraphQL API from Malicious Queries&lt;/em&gt;&lt;/a&gt;. In particular:
 - &lt;em&gt;Depth Limiting&lt;/em&gt;: Rejecting queries which are too deeply nested
 - &lt;em&gt;Amount Limiting&lt;/em&gt;: Rejecting queries which ask for too much information (i.e., via pagination arguments)
 - &lt;em&gt;Query Cost Analysis&lt;/em&gt;: Rejecting queries which are too expensive (by assigning complexity values to fields)
 - &lt;em&gt;Query Whitelisting&lt;/em&gt;: Rejecting queries that are not whitelisted&lt;/p&gt;

&lt;p&gt;I would like to also add &lt;em&gt;Time Limiting&lt;/em&gt;, which would reject queries that take too long to resolve.  &lt;em&gt;Query Whitelisting&lt;/em&gt; is only applicable for private APIs, but otherwise, these are all good approaches for preventing malicious or expensive queries from hitting your API. As per the topic we are covering, we&amp;rsquo;ll focus on Query Whitelisting (otherwise known as Persisted Queries).&lt;/p&gt;

&lt;h1&gt;Persisted Queries&lt;/h1&gt;

&lt;p&gt;&lt;a href="https://twitter.com/leeb/status/829434814402945026"&gt;Facebook has been using persisted queries since 2013&lt;/a&gt;, and comes highly recommended for production usage from them. The essence of a persisted query is that the query is &lt;em&gt;persisted&lt;/em&gt; on the server&amp;rsquo;s side and that a client can &lt;em&gt;reference&lt;/em&gt; it using some unique identifier. A great primer on persisted queries can be found on &lt;a href="https://dev-blog.apollodata.com/persisted-graphql-queries-with-apollo-client-119fd7e6bba5"&gt;Apollo&amp;rsquo;s blog article for this topic&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For the sake of completeness, I want to demonstrate a scenario where persisted queries shine.&lt;/p&gt;

&lt;p&gt;A client sends the following query to the server:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight graphql"&gt;&lt;code&gt;&lt;span class="k"&gt;query&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="n"&gt;company&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;consoles&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="n"&gt;releaseYear&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;No problems so far! Now a bad actor sends the following query:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight graphql"&gt;&lt;code&gt;&lt;span class="k"&gt;query&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="n"&gt;company&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;consoles&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="n"&gt;company&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;consoles&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
          &lt;/span&gt;&lt;span class="n"&gt;company&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
            &lt;/span&gt;&lt;span class="n"&gt;consoles&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
              &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="w"&gt;
              &lt;/span&gt;&lt;span class="c"&gt;# ... continues nesting till happy with the damage&lt;/span&gt;&lt;span class="w"&gt;
            &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
          &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The server evaluating this query can experience performance or stability issues due to the deep nesting and complex nature of the query. Going forward, we will make some assumptions about our API:
 - We control both the server and the clients (i.e., web/mobile clients)
 - We don&amp;rsquo;t expose a public API (it is accessible, but it isn&amp;rsquo;t promoted for external usage)
 - The data being returned from the queries is not personalized&lt;/p&gt;

&lt;p&gt;In our specific case, we can use persisted queries to remedy the issue of malicious users sending bad queries to our API. In addition, we will also gain some performance benefits (i.e., reducing the request&amp;rsquo;s network size).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Persist the query on the server and make note of the signature of the query (i.e., a hash of the query)&lt;/li&gt;
&lt;li&gt;The client sends the query signature to the server, along with any query variables&lt;/li&gt;
&lt;li&gt;Using the signature, the server looks up the matching query from a set of persisted queries&lt;/li&gt;
&lt;li&gt;The server executes the query and returns the data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That sounds great, but how can we go about implementing this? As previously mentioned, persisted queries are not part of the official specification. There are many implementations that exist, as well as some tooling for supporting persisted queries. In my experience at the time of writing this, there wasn&amp;rsquo;t a standard way to implement persisted queries.&lt;/p&gt;

&lt;p&gt;I want to stress the following: &lt;strong&gt;Persisted Queries only work if you control the server and the client&lt;/strong&gt;. In theory, you could use persisted queries on public APIs, although the &lt;em&gt;security&lt;/em&gt; gains are not present. I do want to mention that &lt;a href="https://dev-blog.apollodata.com/improve-graphql-performance-with-automatic-persisted-queries-c31d27b8e6ea"&gt;Automatic Persisted Queries&lt;/a&gt; is one way which uses the concept of persisted queries solely for performance gains.&lt;/p&gt;

&lt;h1&gt;Implementing GraphQL Persisted Queries with HTTP Caching&lt;/h1&gt;

&lt;p&gt;For the sake of brevity and focus, this series will focus on the following platforms:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/facebook/react/"&gt;React&lt;/a&gt; with &lt;a href="https://github.com/apollographql/apollo-client"&gt;Apollo Client&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/expressjs/express"&gt;Express&lt;/a&gt; with &lt;a href="https://github.com/prismagraphql/graphql-yoga"&gt;GraphQL Yoga&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rails/rails"&gt;Rails&lt;/a&gt; with &lt;a href="https://github.com/rmosolgo/graphql-ruby"&gt;GraphQL Ruby&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="/graphql-persisted-queries-with-http-caching-part-2/"&gt;Part two&lt;/a&gt; will cover the following sections:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setup Express Server&lt;/li&gt;
&lt;li&gt;Setup React Application&lt;/li&gt;
&lt;li&gt;Refactor React Application to use Persisted Queries&lt;/li&gt;
&lt;li&gt;Extract GraphQL Queries from Client&lt;/li&gt;
&lt;li&gt;Refactor Express Server to use Persisted Queries&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href="/graphql-persisted-queries-with-http-caching-part-3/"&gt;Part three&lt;/a&gt; will cover the following sections:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setup Rails Server&lt;/li&gt;
&lt;li&gt;Synchronize GraphQL Queries to Rails Server&lt;/li&gt;
&lt;li&gt;Refactor Rails Server to use Persisted Queries&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href="/graphql-persisted-queries-with-http-caching-part-4/"&gt;Part four&lt;/a&gt; will cover the following sections:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add HTTP Caching to React Application&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Express Server&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Rails Server&lt;/li&gt;
&lt;li&gt;Alternative Caching with Gateways&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <title>Migrating PostgreSQL to Aurora with near Zero-Downtime</title>
    <link rel="alternate" href="https://kevinjalbert.com/migrate-postgresql-to-aurora-with-near-zero-downtime/"/>
    <id>https://kevinjalbert.com/migrate-postgresql-to-aurora-with-near-zero-downtime/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-06-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">The goal here is to migrate an Amazon Web Services Relational Database Service PostgreSQL Database to Aurora with as little downtime as possible. The following documents the initial strategy that was considered using read replica promotion, followed by the end result using AWS's Database Migration Service.</description>
    <content type="html">&lt;p&gt;The goal here is to migrate an Amazon Web Services (AWS) Relational Database Service (RDS) PostgreSQL Database to Aurora with as little downtime as possible. The following documents the initial strategy that was considered using read replica promotion, followed by the end result using AWS&amp;rsquo;s Database Migration Service (DMS).&lt;/p&gt;

&lt;h1&gt;Why Aurora&lt;/h1&gt;

&lt;p&gt;From the &lt;a href="https://aws.amazon.com/rds/aurora/details/"&gt;Aurora Details Page&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Amazon Aurora is designed to offer greater than 99.99% availability, increasing MySQL and PostgreSQL performance and availability by tightly integrating the database engine with an SSD-backed virtualized storage layer purpose-built for database workloads. Amazon Aurora&amp;rsquo;s storage is fault-tolerant and self-healing and disk failures are repaired in the background without loss of database availability. Amazon Aurora is designed to automatically detect database crashes and restart without the need for crash recovery or to rebuild the database cache. If the entire instance fails, Amazon Aurora will automatically fail over to one of up to 15 read replicas.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Essentially, better performance, reliability, and the ability to scale.&lt;/p&gt;

&lt;p&gt;Our configuration changes become easier. Aurora acts as a cluster, so we have two endpoints to deal with, and the replicas underneath will adjust dynamically. We use &lt;a href="https://github.com/taskrabbit/makara"&gt;Makara&lt;/a&gt; to spread our database queries between our master and slaves. With RDS PostgreSQL we would have to enumerate all our slave databases so we could take advantage of the replicas. If we added a new replica, we would have to adjust our configuration to take advantage of it. With Aurora, we have two endpoints to deal with now (primary/writer and a read-only URL). These endpoints will dynamically rotate between the available instances that fall under that cluster URL. This is great as it handles a failover to a different primary database, or changing the number of replicas. Effectively, we end up with less configuration, but we still need Makara to direct our write and read queries to the two cluster URLs.&lt;/p&gt;

&lt;h1&gt;Migration Approaches&lt;/h1&gt;

&lt;p&gt;As mentioned earlier, there are two approaches to doing this migration. First, we&amp;rsquo;ll cover the &lt;em&gt;recommended&lt;/em&gt; approach that AWS suggested as we&amp;rsquo;re on the RDS platform. As we&amp;rsquo;ll cover, it is easy and quick but it does incur downtime during the migration. The second approach uses DMS and was brought up to us after opening a support ticket with AWS on how to do our migration with zero downtime.&lt;/p&gt;

&lt;h2&gt;Read Replica Promotion&lt;/h2&gt;

&lt;p&gt;This is the &lt;em&gt;recommended&lt;/em&gt; approach for migrating from PostgreSQL to Aurora. It is easy and has a little risk (during the migration), although it has unavoidable downtime.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create an Aurora read replica off of your master database.&lt;/li&gt;
&lt;li&gt;Pause the master PostgreSQL database.

&lt;ul&gt;
&lt;li&gt;This is done so that the no additional write changes are occurring (as it won&amp;rsquo;t be replicated to the Aurora read replica during the promotion process).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Promote the Aurora read replica.

&lt;ul&gt;
&lt;li&gt;This takes about 10-20 minutes (at least in our experience).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deploy app configuration changes to use new Aurora cluster for write/reads.&lt;/li&gt;
&lt;li&gt;Immediately start building additional read replicas to match existing number.

&lt;ul&gt;
&lt;li&gt;Each one takes about 5-10 minutes to create (at least in our experience).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;When happy with the new setup, remove/delete the old databases.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is &lt;em&gt;recommended&lt;/em&gt; to do a dry run of the promotion (and just throw it away afterwards) to gauge how long that process takes.&lt;/p&gt;

&lt;p&gt;The issue here is that you have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Downtime due to the promotion process. You need to prevent writes from happening on the master. Replication between the PostgreSQL master and the Aurora read replica breaks when the promotion process starts.&lt;/li&gt;
&lt;li&gt;Immediately after you have your new Aurora master, you need to start building read replicas up.

&lt;ul&gt;
&lt;li&gt;In our case, we would want to match our existing number of replicas. So this would take additional time. Otherwise, you possibly run the risk of overwhelming the Database without those read replicas up.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One good thing is that even with the downtime the old read replicas will continue to serve up &lt;code&gt;GET&lt;/code&gt; requests. In addition, any CDN/&lt;a href="https://varnish-cache.org/"&gt;Varnish&lt;/a&gt; caching will also help serve stale data during the downtime.&lt;/p&gt;

&lt;h2&gt;Full Load and Ongoing Replication with DMS&lt;/h2&gt;

&lt;p&gt;This approach is much more involved and finicky, but it does offer a &lt;em&gt;near&lt;/em&gt; zero-downtime migration strategy. The general process here is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create an Aurora read replica (this is so we can keep the DB schema)&lt;/li&gt;
&lt;li&gt;Promote Aurora read replica so it is on its own&lt;/li&gt;
&lt;li&gt;Tweak settings on PostgreSQL DB&lt;/li&gt;
&lt;li&gt;Setup DMS Endpoints for the original PostgreSQL and Aurora databases&lt;/li&gt;
&lt;li&gt;Setup DMS Replication Instance to assist in the migration&lt;/li&gt;
&lt;li&gt;Setup DMS Task to use the endpoints and the replication instance&lt;/li&gt;
&lt;li&gt;Truncate Aurora data (we want to wipe the data, but we keep the schema)&lt;/li&gt;
&lt;li&gt;Initiate the migration

&lt;ul&gt;
&lt;li&gt;The first phase is a &lt;em&gt;full load&lt;/em&gt; of the tables from the source to the target&lt;/li&gt;
&lt;li&gt;The second phase is an &lt;em&gt;on-going replication&lt;/em&gt; of changes from the source to the target&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Both DBs are in-sync now&lt;/li&gt;
&lt;li&gt;Create read replicas off of the Aurora master&lt;/li&gt;
&lt;li&gt;Change app configuration to point to Aurora cluster&lt;/li&gt;
&lt;li&gt;Delete old DBs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a multi-part process, so the following sections will walk through each part.&lt;/p&gt;

&lt;h3&gt;Setting up Aurora Read Replica&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Create an Aurora read replica of the PostgreSQL database

&lt;ul&gt;
&lt;li&gt;Name it something like &lt;code&gt;&amp;lt;service&amp;gt;—&amp;lt;environment&amp;gt;-aurora&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;By creating an Aurora instance, we also get an Aurora cluster (i.e., &lt;code&gt;&amp;lt;service&amp;gt;—&amp;lt;environment&amp;gt;-aurora-cluster&lt;/code&gt;)

&lt;ul&gt;
&lt;li&gt;Ensure the subnet group and the security groups are set to the same values as defined for the PostgreSQL DB.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t need to have multi-AZ here, Aurora will handle fast failover if we have a replica&lt;/li&gt;
&lt;li&gt;Additional read replicas can then be added later using &lt;code&gt;&amp;lt;service&amp;gt;—&amp;lt;environment&amp;gt;-aurora-&amp;lt;##&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At this point, we will have an Aurora read replica that is receiving replicated data changes off the master.&lt;/p&gt;

&lt;h3&gt;Aurora Read Replica Promotion&lt;/h3&gt;

&lt;p&gt;To isolate our newly created Aurora read replica so it can be its own master, we&amp;rsquo;re going to promote the replica. This process allows the instance to receive writes, and be the master for other replicas. We need to do this as otherwise we are limited to only one Aurora read replica off of a PostgreSQL master database. By starting the promotion process the on-going replication is broken between the PostgreSQL and Aurora databases.&lt;/p&gt;

&lt;h3&gt;Tweak the Database Parameters&lt;/h3&gt;

&lt;p&gt;To enable the ability for PostgreSQL to replicate to Aurora we need to make sure we have certain database parameters set.&lt;/p&gt;

&lt;h4&gt;Configure PostgreSQL for Replication&lt;/h4&gt;

&lt;p&gt;The first thing you need to do is change the &lt;code&gt;rds.logical_replication&lt;/code&gt; parameter to 1. As described in &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.RDSPostgreSQL"&gt;the documentation&lt;/a&gt; this parameter actually configures additional related parameters that allow the replication to process:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As part of applying this parameter, AWS DMS sets the &lt;code&gt;wal_level&lt;/code&gt;, &lt;code&gt;max_wal_senders&lt;/code&gt;, &lt;code&gt;max_replication_slots&lt;/code&gt;, and &lt;code&gt;max_connections&lt;/code&gt; parameters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another parameter configuration that &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.Prerequisites"&gt;Amazon recommends&lt;/a&gt; is to set &lt;code&gt;wal_sender_timeout&lt;/code&gt; to 0.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The &lt;code&gt;wal_sender_timeout&lt;/code&gt; parameter terminates replication connections that are inactive longer than the specified number of milliseconds. Although the default is 60 seconds, we recommend that you set this parameter to zero, which disables the timeout mechanism.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Without setting the timeout parameter, the streaming of Write-Ahead Logging (WAL) files can be terminated if the sender is under load and does not send a WAL file within the timeout period. To prevent any risk of this it is best to disable it during the on-going replication phase of the migration process.&lt;/p&gt;

&lt;p&gt;There are additional &lt;code&gt;wal&lt;/code&gt; settings available, but we &lt;em&gt;shouldn&amp;rsquo;t&lt;/em&gt; need to configure them.&lt;/p&gt;

&lt;h4&gt;Configure Aurora for Replication&lt;/h4&gt;

&lt;p&gt;On the Aurora instance, we want to limit any foreign key constraints from triggering as the full loads for tables are occurring. Fortunately, if we change the &lt;code&gt;session_replication_role&lt;/code&gt; parameter to &lt;code&gt;replica&lt;/code&gt;, it only keeps &lt;em&gt;replica&lt;/em&gt; related constraint triggers active. This effectively disables foreign key constraints for us.&lt;/p&gt;

&lt;h3&gt;Create Replication Instance&lt;/h3&gt;

&lt;p&gt;DMS uses a dedicated &lt;em&gt;replication instance&lt;/em&gt; to help facilitate the migration process. In a PostgreSQL to Aurora migration, this machine is responsible for connecting to both the source and target databases and transforming and transferring the data.&lt;/p&gt;

&lt;p&gt;The following steps expand on what is needed to set up a replication instance for the migration.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create a replication instance under DMS

&lt;ul&gt;
&lt;li&gt;Name it as specific as possible for its purpose (i.e., production-api-replication-instance)&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;Instance Size&lt;/em&gt; might need to be tweaked based on various factors (&lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.html#CHAP_ReplicationInstance.InDepth"&gt;documentation on instance sizes&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;For example, in our staging we used &lt;code&gt;dms.t2.large&lt;/code&gt;, while for production we used &lt;code&gt;dms.c4.large&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set the &lt;em&gt;VPC&lt;/em&gt; to the same as the source and target databases&lt;/li&gt;
&lt;li&gt;Enable &lt;em&gt;Multi-AZ&lt;/em&gt; as it is needed for on-going replication&lt;/li&gt;
&lt;li&gt;The instance doesn’t need to be &lt;em&gt;Publicly Accessible&lt;/em&gt; (as the internal connections are done within the VPC)&lt;/li&gt;
&lt;li&gt;Ensure the &lt;em&gt;VPC Security Group&lt;/em&gt; under &lt;em&gt;Advance&lt;/em&gt; is set to &lt;code&gt;default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This allows for connections between the databases and the replication instance&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Create Source and Target Endpoints&lt;/h3&gt;

&lt;p&gt;We need to define the &lt;em&gt;endpoints&lt;/em&gt; of our databases in DMS. One to represent the source database (PostgreSQL) and another to represent the target database (Aurora). The following steps are to be applied to each endpoint.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;Server Name&lt;/em&gt; is the DB’s endpoint (i.e., the connection URL)

&lt;ul&gt;
&lt;li&gt;You cannot use a read replica as your source (it does not support on-going replication)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;User&lt;/em&gt; and &lt;em&gt;Password&lt;/em&gt; are for the master user account of the database

&lt;ul&gt;
&lt;li&gt;The account &lt;em&gt;needs&lt;/em&gt; to be the master account. Otherwise, you need to follow the additional instructions listed in the &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.RDSPostgreSQL"&gt;documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;Password&lt;/em&gt; cannot have certain characters (&lt;code&gt;: ; + %&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Test the endpoint

&lt;ul&gt;
&lt;li&gt;After a success ensure you refresh the schema&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Create Task&lt;/h3&gt;

&lt;p&gt;The DMS &lt;em&gt;task&lt;/em&gt; is where we actually configure and use the &lt;em&gt;endpoints&lt;/em&gt; and &lt;em&gt;replication instance&lt;/em&gt; to accomplish the migration. There are a couple of options and considerations to be made while creating a task. The following steps outline how to create a task, and the settings to configure:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;em&gt;source and target endpoints&lt;/em&gt; along with the &lt;em&gt;replica instance&lt;/em&gt; that was created for this migration task&lt;/li&gt;
&lt;li&gt;Set the &lt;em&gt;Migration type&lt;/em&gt; to &lt;code&gt;Migrate existing data and replicate ongoing changes&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;This ensures that we are doing the 2 phase approach:&lt;/li&gt;
&lt;li&gt;Doing a full-load of the table&amp;rsquo;s data&lt;/li&gt;
&lt;li&gt;Doing on-going replication of changes on the source database&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Target table preparation mode&lt;/em&gt; should be &lt;code&gt;Do nothing&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;The reason here is that we want to preserve the table&amp;rsquo;s metadata (i.e., indexes, defaults, constraints)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Truncate&lt;/code&gt; could work, but is likely to fail due to constraints in the database&lt;/li&gt;
&lt;li&gt;Remember that by using &lt;code&gt;Do nothing&lt;/code&gt; the target database needs to be truncated manually prior to running the task&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Stop task after full load completes&lt;/em&gt; should be set to &lt;code&gt;Don&amp;#39;t stop&lt;/code&gt;.

&lt;ul&gt;
&lt;li&gt;This ensures the on-going replication process starts immediately when a table is fully loaded&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;For the table mappings, we want to migrate all tables (i.e., &lt;code&gt;where schema name is like &amp;#39;public&amp;#39; and table name is like &amp;#39;%&amp;#39;, include&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;It is useful to enable the &lt;em&gt;validation&lt;/em&gt; and &lt;em&gt;logging&lt;/em&gt; to see how things are progressing during the migration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Include LOB columns in replication&lt;/em&gt; is an interesting setting, LOBs are &lt;em&gt;Large Objects&lt;/em&gt; that exist during the migration. As DMS is possibly migrating to a different database type a transformation of data types occurs. To understand what we&amp;rsquo;re dealing with you need to look up the source database&amp;rsquo;s supported types in the documentation. For example, using the DMS documentation you can see what &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html#CHAP_Source.PostgreSQL.DataTypes"&gt;PostgreSQL data types&lt;/a&gt; end up being LOBs.&lt;/p&gt;

&lt;p&gt;The following section will dig a little deeper into LOBs and the considerations that need to be considered.&lt;/p&gt;

&lt;h4&gt;Full or Limited LOB Mode&lt;/h4&gt;

&lt;p&gt;There are two options for handling LOBs during the migration: &lt;em&gt;Full&lt;/em&gt; or &lt;em&gt;Limited&lt;/em&gt; LOB Mode. LOBs are potentially massive objects that reside in the database, and they normally don&amp;rsquo;t have a fixed size in the column. The following &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.LOBSupport.html"&gt;documentation&lt;/a&gt; describes the two options:&lt;/p&gt;

&lt;p&gt;DMS provides you with the &lt;em&gt;Full LOB Mode&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In full LOB mode, AWS DMS migrates all LOBs from source to target regardless of size. In this configuration, AWS DMS has no information about the maximum size of LOBs to expect. Thus, LOBs are migrated one at a time, piece by piece. Full LOB mode can be quite slow.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;DMS also provides the &lt;em&gt;Limited LOB Mode&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In limited LOB mode, you set a maximum size LOB that AWS DMS should accept. Doing so allows AWS DMS to pre-allocate memory and load the LOB data in bulk. LOBs that exceed the maximum LOB size are truncated and a warning is issued to the log file. In limited LOB mode, you get significant performance gains over full LOB mode. We recommend that you use limited LOB mode whenever possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Initially, it makes sense to just use &lt;em&gt;Full LOB Mode&lt;/em&gt; as it&amp;rsquo;ll preserve data by migrating LOBs regardless of size. The big issue with this choice is &lt;em&gt;speed&lt;/em&gt;. In our migration, we achieve full migration in 2 hours using &lt;em&gt;Limited LOB Mode&lt;/em&gt; and we estimated about 90 hours using &lt;em&gt;Full LOB Mode&lt;/em&gt;. The issue with using &lt;em&gt;Limited LOB Mode&lt;/em&gt; is that you can essentially lose data if the LOB&amp;rsquo;s size is less than the &lt;code&gt;Max LOB Size&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;To work around this concern, the plan is to determine the max LOB size in the database and set the &lt;code&gt;Max LOB Size&lt;/code&gt; to slightly bigger than that value (i.e., multiply it by 2). By using a larger &lt;code&gt;Max LOB Size&lt;/code&gt; than the largest LOB we have in the database, we are ensured to have the full data migrated without any data loss.&lt;/p&gt;

&lt;p&gt;A manual way to check for the size of a LOB column is to use the following query: &lt;code&gt;SELECT max(pg_column_size(column_name)) FROM table_name;&lt;/code&gt;. This will return the max number of bytes used in that column. This is the value you&amp;rsquo;ll want to be larger than. The following is a Rails rake task that walks through every table&amp;rsquo;s column and identifies the max sizes for any LOB column (for PostgreSQL):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;namespace&lt;/span&gt; &lt;span class="ss"&gt;:scripts&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="s1"&gt;'Print out the max size of LOBs in the database. Usage: bin/rake scripts:max_lob_size'&lt;/span&gt;
  &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="ss"&gt;max_lob_size: :environment&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="no"&gt;LOB_TYPES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sx"&gt;%w(
      hstore
      composite
      array
      jsonb
      json
      polygon
      path
      xml
      tsquery
      tsvector
      bytea
      text
    )&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;freeze&lt;/span&gt;

    &lt;span class="no"&gt;ActiveRecord&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;connection&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;tables&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;each&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
      &lt;span class="k"&gt;next&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;table_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'schema_migrations'&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;starts_with?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'awsdms_'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

      &lt;span class="n"&gt;columns_sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;~&lt;/span&gt;&lt;span class="no"&gt;HEREDOC&lt;/span&gt;&lt;span class="sh"&gt;
        SELECT *
        FROM information_schema.columns
        WHERE table_schema = 'public'
          AND table_name   = '&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="sh"&gt;'
&lt;/span&gt;&lt;span class="no"&gt;      HEREDOC&lt;/span&gt;

      &lt;span class="n"&gt;columns_results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;ActiveRecord&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;connection&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns_sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

      &lt;span class="n"&gt;columns_results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;each&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
        &lt;span class="n"&gt;column_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'column_name'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;column_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'data_type'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="no"&gt;LOB_TYPES&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;include?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;column_type&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="n"&gt;size_sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;~&lt;/span&gt;&lt;span class="no"&gt;HEREDOC&lt;/span&gt;&lt;span class="sh"&gt;
            SELECT max(pg_column_size(&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;column_name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="sh"&gt;)) FROM &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="sh"&gt;;
&lt;/span&gt;&lt;span class="no"&gt;          HEREDOC&lt;/span&gt;
          &lt;span class="n"&gt;size_results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;ActiveRecord&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;connection&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size_sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

          &lt;span class="n"&gt;table_hash&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;to_sym&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
          &lt;span class="n"&gt;column_hash&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table_hash&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;to_sym&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

          &lt;span class="n"&gt;column_hash&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:column_type&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;column_type&lt;/span&gt;
          &lt;span class="n"&gt;column_hash&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:max_bytes_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;size_results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'max'&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="nf"&gt;to_i&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;

        &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'.'&lt;/span&gt;
      &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;

    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Raw Dump"&lt;/span&gt;
    &lt;span class="n"&gt;pp&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

    &lt;span class="n"&gt;max_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;values&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;values&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;first&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:max_bytes_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}.&lt;/span&gt;&lt;span class="nf"&gt;compact&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;max&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;"Max bytes found in a LOB column is &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;max_bytes&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;LOB Nullability Constraints&lt;/h4&gt;

&lt;p&gt;There are some concerns with &lt;code&gt;NOT NULL&lt;/code&gt; database constraints on columns that become LOBs during the migration. DMS has a certain process for dealing with tables with LOBs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The data for each column in a row is added, except for LOB columns&lt;/li&gt;
&lt;li&gt;LOB columns are left with a &lt;code&gt;null&lt;/code&gt; placeholder&lt;/li&gt;
&lt;li&gt;Afterwards, LOB data replaces the &lt;code&gt;null&lt;/code&gt; placeholders&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This two-step process of dealing with LOB data types is where we have to be concerned with &lt;code&gt;NOT NULL&lt;/code&gt; constraints. The migration will fail if any LOB columns have a &lt;code&gt;NOT NULL&lt;/code&gt; constraint. In PostgreSQL, a common case of LOBs is &lt;code&gt;jsonb&lt;/code&gt; and &lt;code&gt;array&lt;/code&gt; columns. So we have to &lt;em&gt;remove&lt;/em&gt; these constraints on the target database just until the full table load phase is done. For example, the following statement would do the trick, &lt;code&gt;ALTER TABLE my_table ALTER COLUMN lob_column DROP NOT NULL;&lt;/code&gt;. Do not forget to add the &lt;code&gt;NOT NULL&lt;/code&gt; constraints back after the full table load phase is done.&lt;/p&gt;

&lt;h3&gt;Migration Time&lt;/h3&gt;

&lt;p&gt;At this point, the migration process is pretty much ready! Let&amp;rsquo;s break the process up into before/during/after migration.&lt;/p&gt;

&lt;h4&gt;Before Migration&lt;/h4&gt;

&lt;p&gt;Make sure that the:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The DMS endpoints, task and replication instance are present and configured&lt;/li&gt;
&lt;li&gt;The Aurora instance is ready:

&lt;ul&gt;
&lt;li&gt;Truncated data&lt;/li&gt;
&lt;li&gt;Disabled LOB nullability constraints&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One thing that is suggested is to run &lt;code&gt;Assess&lt;/code&gt; on the task so you can get a report of potential issues. In our case, there were a couple of &lt;em&gt;Partially supported datatypes : float8&lt;/em&gt; on a few columns. This ended up changing the rounding of floats (i.e., 1.4999999998 &amp;ndash;&amp;gt; 1.5). It is worth noting that these differences occur after the migration process is completed and changes are being done on the new database type.&lt;/p&gt;

&lt;p&gt;For the migration, ideally, it is done during a &lt;em&gt;low&lt;/em&gt; activity period. In addition, if possible stop any background jobs just before the migration, and wait for the current jobs to finish. The jobs can resume processing after the migration, this is to reduce risk.&lt;/p&gt;

&lt;h4&gt;During Migration&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Keep an eye on the source database&amp;rsquo;s health

&lt;ul&gt;
&lt;li&gt;There will be additional load placed on it during the migration&lt;/li&gt;
&lt;li&gt;If needed you could always lower the number of tables loaded in parallel during the &lt;em&gt;full load&lt;/em&gt; phase (under the advanced settings in the &lt;em&gt;Task&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Monitor the task&amp;rsquo;s &lt;em&gt;Table Statistics&lt;/em&gt; tab to make sure tables are progressing well&lt;/li&gt;
&lt;li&gt;Monitor the task&amp;rsquo;s &lt;em&gt;Task Monitoring&lt;/em&gt; tab to make sure the on-going replication is keeping up

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;CDCIncomingChanges&lt;/code&gt; should be as close to 0 as possible&lt;/li&gt;
&lt;li&gt;During the &lt;em&gt;full load&lt;/em&gt; phase, the &lt;code&gt;CDCIncomingChanges&lt;/code&gt; will climb as the on-going replication changes are stored until the tables have fully loaded into the target database&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Monitor the replication instance&amp;rsquo;s &lt;em&gt;Monitoring&lt;/em&gt; tab to make sure the &lt;code&gt;FreeStorageSpace&lt;/code&gt; and &lt;code&gt;FreeableMemory&lt;/code&gt; are not dropping too low

&lt;ul&gt;
&lt;li&gt;If any of these are too low then the migration can fail&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first phase is &lt;em&gt;full table load&lt;/em&gt;, where all the source data is dumped into the target. Be aware that large tables can take some time. After a table has been fully loaded into the target, the on-going replication phase starts for that table.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;on-going replication&lt;/em&gt; phase is where &lt;em&gt;inserts/deletes/updates&lt;/em&gt; are replicated from the source to the target. After all the tables are in this phase (all tables in a &lt;em&gt;Table Completed&lt;/em&gt; state), it is now safe to re-enable the LOB nullability constraints that were disabled earlier.&lt;/p&gt;

&lt;h5&gt;Validations&lt;/h5&gt;

&lt;p&gt;If you have validations enabled for the &lt;em&gt;Task&lt;/em&gt; then the &lt;em&gt;validation&lt;/em&gt; columns in the &lt;em&gt;Table Statistics&lt;/em&gt; will update during the migration. These validations put additional load on the source and target database as the row data is compared after that row has been migrated. It is an on-going validation process.&lt;/p&gt;

&lt;p&gt;Personally, I found the validation to be very flaky. It is either &lt;em&gt;really slow&lt;/em&gt; and it also reports validation errors that are not actual errors. In our case, we didn&amp;rsquo;t pay much attention to the validation failures as spot checking proved that the data was &lt;em&gt;fine&lt;/em&gt;. There were &lt;em&gt;minor&lt;/em&gt; cases where time columns were &lt;em&gt;slightly off&lt;/em&gt;. I am unsure how the validation actually works (i.e., when it does the checks), as the on-going replication could be lagging behind. According to the &lt;a href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Validating.html#CHAP_Validating.Limitations"&gt;documentation&lt;/a&gt;, there are some limitations that might prevent it from being that useful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If one or more rows are being continuously modified during the validation, then AWS DMS can&amp;rsquo;t validate those rows. However, you can validate those &lt;em&gt;busy&lt;/em&gt; rows manually, after the task completes.&lt;/li&gt;
&lt;li&gt;If AWS DMS detects more than 10,000 failed or suspended records, it will stop the validation. Before you proceed further, resolve any underlying problems with the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In either case under the target&amp;rsquo;s database, there is a new table called &lt;code&gt;awsdms_validation_failures_v1&lt;/code&gt; that contains information on the failures. The &lt;code&gt;KEY&lt;/code&gt; and &lt;code&gt;TABLE_NAME&lt;/code&gt; columns can be used to identify the record in question. It is then possible to check the source and target record and see if there are any issues. One other problem we had with spot-checking validation is that our PostgreSQL database used &lt;code&gt;UUID&lt;/code&gt;s for primary keys, this resulted in the &lt;code&gt;KEY&lt;/code&gt; column having truncated data on the &lt;code&gt;UUID&lt;/code&gt;.&lt;/p&gt;

&lt;h4&gt;After Migration&lt;/h4&gt;

&lt;p&gt;Hopefully, the migration went successfully, and both the source and target database are in-sync. At this point, the zero-downtime migration can occur &amp;ndash; simply point the application at the new database. It is advisable to wait for any replication lag or queued up &lt;code&gt;CDCIncomingChanges&lt;/code&gt; to drain before proceeding. You might have to wait a little bit for the connections of your application to cycle over to the new database, but you can monitor this in CloudWatch, or force the cycle (i.e., restart Rails Unicorn servers). Don&amp;rsquo;t forget to resume any background queues. After sufficient time, you can decommission the old database resources.&lt;/p&gt;

&lt;p&gt;In the event that the migration doesn&amp;rsquo;t go as planned, it is possible to revert back to the old database. The only issue is that any write data that occurred during the migration process (i.e., only on the Aurora database) wouldn&amp;rsquo;t be present on the old database (i.e., PostgreSQL database). This is simply an issue that cannot be worked around, and hopefully, the low activity period reduces the amount of data loss.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>iTerm2 Mouseless Copy</title>
    <link rel="alternate" href="https://kevinjalbert.com/iterm2-mouseless-copy/"/>
    <id>https://kevinjalbert.com/iterm2-mouseless-copy/</id>
    <updated>2018-11-30T23:08:35-05:00</updated>
    <published>2018-05-06T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Learn how to keep your hands on the keyboard, and accomplish mouseless selection and copying in iTerm2. We explore the find and copy approach, along with iTerm2's copy mode.</description>
    <content type="html">&lt;p&gt;Where possible, I try to avoid using the mouse. I heavily use &lt;a href="https://www.vim.org/"&gt;Vim&lt;/a&gt; while editing which allows for keyboard navigation. I have taken such a liking to the Vim keyboard-bindings that I even use  &lt;a href="https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en"&gt;Vimium (a Google Chrome extension)&lt;/a&gt; for keyboard-driven navigation in my browser (for as much as I can). In addition, I use &lt;a href="https://itunes.apple.com/ca/app/bettersnaptool/id417375580"&gt;BetterSnapTool&lt;/a&gt; for MacOS, which allows me to move/resize windows around solely from my keyboard.&lt;/p&gt;

&lt;p&gt;One optimization within my terminal that I have been avoiding is &lt;a href="https://github.com/tmux/tmux"&gt;tmux&lt;/a&gt; &amp;ndash; it is unnecessarily complicated for what I need. For the most part, I am able to use &lt;a href="https://www.iterm2.com/"&gt;iTerm2&lt;/a&gt; to open tabs, split panes and navigate around. To be honest, I don&amp;rsquo;t really need the session keeping functionality that tmux or &lt;a href="http://www.gnu.org/software/screen/"&gt;screen&lt;/a&gt; provided. The big gain I was missing from tmux was the famed &lt;a href="https://minimul.com/increased-developer-productivity-with-tmux-part-8.html"&gt;copy mode&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A quick snippet from &lt;a href="https://www.iterm2.com/documentation-highlights.html"&gt;iTerm2&amp;rsquo;s documentation of highlights&lt;/a&gt; for text selection:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;You can use the mouse.&lt;/li&gt;
&lt;li&gt;You can use the find feature&amp;rsquo;s &amp;ldquo;mouseless copy&amp;rdquo; feature.&lt;/li&gt;
&lt;li&gt;You can use Copy Mode.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The first one we&amp;rsquo;re not interested in as it&amp;rsquo;s the &lt;em&gt;standard&lt;/em&gt; way to select and copy text. We will cover others two in the sections that follow.&lt;/p&gt;

&lt;h2&gt;Find and Copy&lt;/h2&gt;

&lt;p&gt;So one approach to copying anything within the iTerm2&amp;rsquo;s session is to use the default &lt;em&gt;search&lt;/em&gt;. It is an interesting approach, to say the least:&lt;/p&gt;

&lt;p&gt;&lt;img width="648" height="445" src="/images/2018-05-06-iterm2-mouseless-copy/search-copy.gif" /&gt;&lt;/p&gt;

&lt;p&gt;Essentially, you initiate the search with &lt;em&gt;cmd+f&lt;/em&gt; and you can use the &lt;em&gt;enter&lt;/em&gt; and &lt;em&gt;tab&lt;/em&gt; to move your selection around and to control how much of the text you want in your selection. It works in a pinch, but if you mess up the amount of text in your selection, you basically have to restart the process. In addition, I found the &lt;em&gt;shift+tab&lt;/em&gt; command cycled the selected search result, leading to some confusion.&lt;/p&gt;

&lt;p&gt;To be honest, I don&amp;rsquo;t use this search copying approach very often. I find it difficult to get right, as you cannot really afford any mistakes. The following is a summary of this approach:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Searching for some text using &lt;em&gt;cmd+f&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Use &lt;em&gt;enter&lt;/em&gt; to move to the next search result.&lt;/li&gt;
&lt;li&gt;Use &lt;em&gt;shift+enter&lt;/em&gt; to move to the previous search result.&lt;/li&gt;
&lt;li&gt;Navigate until you are on the desired location.&lt;/li&gt;
&lt;li&gt;Use &lt;em&gt;tab&lt;/em&gt; to expand your search to the next word.&lt;/li&gt;
&lt;li&gt;Use &lt;em&gt;shift+tab&lt;/em&gt; to expand your search to the previous word.

&lt;ul&gt;
&lt;li&gt;Although it moves to the previous search result if one exists.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;When your search term is selected, use &lt;em&gt;cmd+c&lt;/em&gt; to copy the selection.&lt;/li&gt;
&lt;li&gt;Use &lt;em&gt;esc&lt;/em&gt; to exit search, and now you have the selection in your clipboard.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Copy Mode&lt;/h2&gt;

&lt;p&gt;This iTerm2 mode attempts to emulate as much of the tmux copy mode as possible, allowing you to make text selections using the keyboard. It is a &lt;em&gt;mode&lt;/em&gt; very much like Vim&amp;rsquo;s &lt;em&gt;insert&lt;/em&gt; and &lt;em&gt;normal&lt;/em&gt; modes. It is important to note that the session within the pane will stop updating when you enter copy mode.&lt;/p&gt;

&lt;p&gt;&lt;img width="648" height="445" src="/images/2018-05-06-iterm2-mouseless-copy/copy-mode.gif" /&gt;&lt;/p&gt;

&lt;p&gt;I highly recommend reading the &lt;a href="https://www.iterm2.com/documentation-copymode.html"&gt;documentation on iTerm2&amp;rsquo;s copy mode&lt;/a&gt; as it completely covers the keyboard shortcuts and features. Copy mode, in my opinion, is the superior of the two approaches for mouseless copying. I highly recommend giving it a shot the next time you reach for your mouse. The following is a quick summary of copy mode:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Enter copy mode with &lt;em&gt;cmd+shift+c&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Basic Vim keybinding, many keystrokes can active different actions.

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;v&lt;/em&gt; to select by character.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;shift+v&lt;/em&gt; to select by line.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;ctrl+v&lt;/em&gt; for rectangular selection.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;ctrl+space&lt;/em&gt; to stop selecting.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;y&lt;/em&gt; to yank/copy the selection (also exits copy mode).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;q&lt;/em&gt; to exit copy mode.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Can chain off of iTerm2&amp;rsquo;s search feature.&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
</feed>
