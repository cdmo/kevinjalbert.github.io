<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kevin Jalbert</title>
  <link href="https://kevinjalbert.com"/>
  <updated>2019-04-30T19:53:20-04:00</updated>
  <author>
    <name>Kevin Jalbert</name>
  </author>
  <id>https://kevinjalbert.com</id>
  <entry>
    <title>Editing Commits in a Pull Request; Make it your Last Action</title>
    <link rel="alternate" href="https://kevinjalbert.com/editing-commits-in-a-pull-request-make-it-your-last-action/"/>
    <id>https://kevinjalbert.com/editing-commits-in-a-pull-request-make-it-your-last-action/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2019-04-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">If you are going to edit commits in a collapsing fashion (i.e., amend/squash) in a pull request, make it your last action before merging to avoid confusing code reviewers.</description>
    <content type="html">&lt;p&gt;&lt;em&gt;This post should be seen through the lens of working with a team using Git and GitHub during the collaboration of developing software. There is also the assumption that the reader has a firm understanding of Git.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Editing commits are more common than you might think. Anytime you &lt;em&gt;amend, rebase, or squash&lt;/em&gt; you are modifying commits, in which the affected commits&amp;rsquo; SHA changes.&lt;/p&gt;

&lt;p&gt;In a collaborative setting (i.e., a Pull Request in GitHub), we want to &lt;a href="https://git-scm.com/book/en/v1/Git-Branching-Rebasing#The-Perils-of-Rebasing"&gt;minimize editing commits&lt;/a&gt;. For many developers, it is worthwhile to keep the Git history as clean and linear as possible. The best way to achieve that simplicity is by reducing multiple commits or rebasing off of master to avoid a merge conflict/commit.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you are going to edit commits in a collapsing fashion (i.e., amend/squash) in a pull request, make it your last action before merging to avoid confusing code reviewers.&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Editing Commits&lt;/h1&gt;

&lt;p&gt;For brevity, the details of how to edit commits can be found at the following &lt;a href="https://thoughtbot.com/blog/git-interactive-rebase-squash-amend-rewriting-history"&gt;article by thoughtbot&lt;/a&gt;. As touched on in my &lt;a href="https://kevinjalbert.com/level-up-your-commit-messages/"&gt;previous post&lt;/a&gt;, you can &lt;em&gt;hide the &lt;a href="https://sethrobertson.github.io/GitBestPractices/#sausage"&gt;sausage making process&lt;/a&gt;&lt;/em&gt; by amending and squashing commits. There are two main benefits to consolidating commits:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The ability to &lt;code&gt;git bisect&lt;/code&gt;, &lt;code&gt;git revert&lt;/code&gt; and &lt;code&gt;git cherry-pick&lt;/code&gt; work without much issue.&lt;/li&gt;
&lt;li&gt;Commits are &lt;a href="https://www.freshconsulting.com/atomic-commits/"&gt;atomic&lt;/a&gt; and provide better archaeological information in &lt;code&gt;git log&lt;/code&gt; and &lt;code&gt;git blame&lt;/code&gt; scenarios.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Cautiously Edit a Pull Request&amp;rsquo;s Commits&lt;/h1&gt;

&lt;p&gt;As developers learn early on, when a branch is public you avoid carelessly rewriting the commit history. If you do need to get changes from another branch (i.e., master) into the feature branch, there are two options (&lt;a href="https://www.atlassian.com/git/tutorials/merging-vs-rebasing"&gt;both which Atlassian covers in great detail&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;safer&lt;/em&gt; way is merging master into the feature branch, which in my opinion makes things a bit messy.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;cleaner&lt;/em&gt; way is rebasing the feature branch onto master, which results in a more linear commit history.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From my experience, I&amp;rsquo;ve always gone with the rebase option as I value a simplified commit history. Incidentally, the two benefits mentioned in the previous section help with keeping the master branch simple and clean. In practice, this manifests as a final squashing effort before merging the pull request into master.&lt;/p&gt;

&lt;p&gt;Regardless, communication is key if you plan to edit the commits of a pull request. Collaborators need to know that they have to account for the rewritten history the next time they want to use or contribute to that branch.&lt;/p&gt;

&lt;h1&gt;Don&amp;rsquo;t Edit Commits During Code Reviews&lt;/h1&gt;

&lt;p&gt;Imagine the following scenario:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Bob is creating a new feature in his local branch.&lt;/li&gt;
&lt;li&gt;Bob pushes up the branch to GitHub and creates a pull request.&lt;/li&gt;
&lt;li&gt;Bob communicates that he wants feedback from Jane by requesting her as a reviewer.&lt;/li&gt;
&lt;li&gt;Jane makes some comments and good suggestions on the pull request.&lt;/li&gt;
&lt;li&gt;Bob makes changes to address the code review comments.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now here is where we can hit some diverging paths:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bob creates new commits based off the review comments.&lt;/li&gt;
&lt;li&gt;Bob amends the changes onto the last commit.&lt;/li&gt;
&lt;li&gt;Bob squashes the changes into other commits on the branch.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the three presented cases, Bob addressed the code review comments and the resulting code is identical &amp;ndash; only the commits are different. The issue arises when he re-requests Jane to perform a subsequent review. As Jane has already left comments, she instinctively looks to see the &lt;em&gt;new&lt;/em&gt; changes on the branch as these changes are more likely the ones that address the earlier code review comments. In the first case, these are represented as new commits, and it is easy enough to see the changes. In the second and third case, the changes are hidden inside previous commits. &lt;strong&gt;This makes it incredibly difficult to isolate the changes made since Jane last looked at the pull request.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img width="1454" height="392" src="/images/2019-04-30-editing-commits-in-a-pull-request-make-it-your-last-action/view-changes.png" /&gt;&lt;/p&gt;

&lt;p&gt;The take away here is that during the code review phase, we want to ensure that the commits are additive and tell a complete story. A reviewer can and should see how the pull request has changed at each step of the process. The back-and-forth of getting feedback and adding new commits to address them is the collaborative flow for which we should aim.&lt;/p&gt;

&lt;h1&gt;Squash Before You Merge&lt;/h1&gt;

&lt;p&gt;Ultimately, we still want that clean commit history when we finally merge, and so we have to squash commits down at some point. As previously mentioned, editing commits during the active code review cycle is detrimental, so you wait until the pull request is approved and ready to be merged.&lt;/p&gt;

&lt;p&gt;A final rebase onto master might be needed to resolve any conflicts between the feature branch and master. If we do need this, it&amp;rsquo;s sometimes useful to get a final check if you were not confident in the conflict resolution.&lt;/p&gt;

&lt;p&gt;Ideally, squashing commits results in no code changes from what was already reviewed. If, for whatever reason, there are some changes that need to be made, you&amp;rsquo;d want some final eyes to check it over. With respect to making the squashing task easier for yourself, I recommend taking a look over the &lt;a href="https://thoughtbot.com/blog/autosquashing-git-commits"&gt;auto-squashing feature built into Git&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth mentioning that GitHub also has a &lt;a href="https://help.github.com/en/articles/about-pull-request-merges#squash-and-merge-your-pull-request-commits"&gt;&lt;em&gt;Squash and Merge&lt;/em&gt; option&lt;/a&gt;, which does the squashing for you. This is a decent approach if your team is okay with all the changes being compressed down into one commit on master. I personally prefer having the finer grain control over how I structure my atomic commits.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Consuming Content and Managing the Flood</title>
    <link rel="alternate" href="https://kevinjalbert.com/consuming-content-and-managing-the-flood/"/>
    <id>https://kevinjalbert.com/consuming-content-and-managing-the-flood/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2019-03-31T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">In the software development world, there are always new articles and content to consume. Learn how I keep on top of it all and focus on keeping the flood of information to a sustainable level.</description>
    <content type="html">&lt;p&gt;For almost a decade, I&amp;rsquo;ve been immersed in the software development world. One single truth that has held on since the beginning is that there are always &lt;em&gt;things to keep up with.&lt;/em&gt; You know what I mean &amp;ndash; it seems like every day there are new frameworks, languages, techniques, and learnings to consume. I have always referred to this constant onslaught of information as &lt;em&gt;the Feed&lt;/em&gt;. This term comes from my original method of corralling the information &amp;ndash; via RSS feeds.&lt;/p&gt;

&lt;p&gt;Early in my journey, I was looking to get up to date on anything and everything. I was grasping for information to consume. As I found sources, I simply latched on to the pipe and drank it all. In most cases this was unsustainable. The classic and best example of this is &lt;a href="https://news.ycombinator.com/"&gt;HackerNews&lt;/a&gt;, which presents a barrage of items every day.&lt;/p&gt;

&lt;p&gt;I want to talk about the techniques I&amp;rsquo;ve adopted to better keep up to date in my field. The following are techniques I&amp;rsquo;ve found and solutions that work for me, but no guarantee they will work for you to the same capacity.&lt;/p&gt;

&lt;h1&gt;Don&amp;rsquo;t Consume Everything&lt;/h1&gt;

&lt;p&gt;Just don&amp;rsquo;t. It&amp;rsquo;s impossible to do so, you&amp;rsquo;ll only end up wasting your time and putting more pressure on yourself. I&amp;rsquo;ve been guilty of trying to stay on top of HackerNews and just drowned in it. It is a struggle if you try to consume everything. Even if you aren&amp;rsquo;t reading every article, you still have to spend the time and effort to determine if this is something you &lt;em&gt;want to read&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So you don&amp;rsquo;t want to read everything&amp;hellip; how do you determine what to read? I ask the following two questions when I see a headline:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Is this actionable and relevant to me &lt;em&gt;right now?&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Is this information that will stand the test of time (i.e., unchanging)?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These rules have some flexibility built-in and will vary by person and by time. If you do adhere to them, hopefully, you find a way to pass over media that you&amp;rsquo;ll get little benefit from. We want to maximize the return on investment when consuming information, everything takes time and effort.&lt;/p&gt;

&lt;h1&gt;Focus on High-Quality Sources&lt;/h1&gt;

&lt;p&gt;Going back to HackerNews, there are tens if not hundreds of links posted a day. Subreddits are another case where there is a large amount of content present daily. Unfortunately, not everything you see will be high-caliber.&lt;/p&gt;

&lt;p&gt;If we think of getting the best return on our investment, we&amp;rsquo;d naturally want to only consume the finest information. To me, this is stuff that other people have found useful, and therefore has been vetted by the community. It is also worth considering content that is &lt;em&gt;gated&lt;/em&gt; by some criteria as this enforces a minimum bar of quality.&lt;/p&gt;

&lt;h2&gt;Newsletters&lt;/h2&gt;

&lt;p&gt;I subscribe to several &lt;em&gt;weekly&lt;/em&gt; newsletters from various sources &amp;ndash; they are curated and present the highlights for that week. The following is a subset of newsletters that I consume weekly.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://softwareleadweekly.com/"&gt;Software Lead Weekly&lt;/a&gt; — People, culture, and leadership&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gitprime.com/engineering-impact/"&gt;Engineering Impact Newsletter&lt;/a&gt; — Engineering leadership, productivity, culture, and scaling development teams&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hackernewsletter.com/"&gt;Hacker NewsLetter&lt;/a&gt; — The best articles from HackerNews on startups, technology, programming and more&lt;/li&gt;
&lt;li&gt;&lt;a href="https://changelog.com/weekly"&gt;Changelog Weekly&lt;/a&gt; — Open source community and software development&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cooperpress.com/publications/"&gt;&lt;em&gt;&amp;lt;tech&amp;gt;&lt;/em&gt; Weekly&lt;/a&gt; — 12 weekly newsletters curated by CooperPress (i.e., Ruby Weekly, JavaScript Weekly, etc&amp;hellip;). Each one is a curated newsletter sharing news, articles, and tutorials in their respective spaces.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recalling our earlier focus on &lt;em&gt;Don&amp;rsquo;t Consume Everything&lt;/em&gt;, we need to be selective even on the curated selections. Newsletters can be a slippery slope as well, as it still depends on how you handle them. In addition, we don&amp;rsquo;t want to &lt;em&gt;subscribe&lt;/em&gt; to everything. Be focused on the relevant and the unchanging. For example, don&amp;rsquo;t subscribe to Mobile Dev newsletters if you aren&amp;rsquo;t actively working in that area &amp;ndash; with any luck, different topics will converge in other areas you are focused on.&lt;/p&gt;

&lt;h2&gt;Blogs&lt;/h2&gt;

&lt;p&gt;Ultimately, a good chunk of content is sourced from the blogs of individuals. In the past, I have subscribed to receive updates from individuals (i.e., via RSS or their own newsletters), although I have started to slowly move away from this approach. It&amp;rsquo;s not uncommon to frequently see articles from an individual appearing in curated newsletters. In rare situations does an individual produce consistent high-quality material that is on-point and unchanging in value.&lt;/p&gt;

&lt;h2&gt;Talks&lt;/h2&gt;

&lt;p&gt;Conference talks are also a great medium to consider as they carry with them a certain level of quality. The same rules as before apply with the selection process. I skim over the titles of a conference talk when it appears on their preferred video hosting platform (i.e., YouTube, or &lt;a href="https://confreaks.tv/"&gt;Confreaks&lt;/a&gt;). I also want to bring up that &lt;a href="https://www.ted.com/talks"&gt;TED Talks&lt;/a&gt; are also a fantastic source of knowledge.&lt;/p&gt;

&lt;h2&gt;Books&lt;/h2&gt;

&lt;p&gt;A tried and tested approach to knowledge transfer is books. Writing a book is a significant undertaking requiring plenty of research and editing, and are also difficult to update after they are published. Given the constraints of books, we are hopeful that they are written to stand the test of time (i.e., the content is unchanging). One other valuable aspect is that book authors often have a unique viewpoint, which led them to write a book. Overall, I think books are a great medium of high-quality content, and there are many great books out there that are recommended.&lt;/p&gt;

&lt;h2&gt;Podcasts&lt;/h2&gt;

&lt;p&gt;The podcasts I listen to traditionally follow the format of a host interviewing a person of interest within the topic&amp;rsquo;s community of the podcast. Podcasts are interesting as their content can vary episode to episode, and can be heavily dependent on the people present. Sometimes there are musings on recent news, sometimes it is dissecting the success of an individual or project. I follow podcasts that are specific to my professional focus, although I&amp;rsquo;ll admit even those offer highly entertaining facets due to the light-hearted nature of interviewing styles.&lt;/p&gt;

&lt;h2&gt;Twitter&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve always found &lt;a href="https://twitter.com/"&gt;Twitter&lt;/a&gt; to be hit-or-miss with respect to content. It&amp;rsquo;s a lot more &lt;em&gt;raw&lt;/em&gt; in nature, and if you&amp;rsquo;re following the right people you do get a glimmer of insight closer to their thought processes. In my opinion, keep Twitter for entertainment, and as a means for social connections. Also from my experience, if a nugget of information is linked to on Twitter, it normally ends up in another medium.&lt;/p&gt;

&lt;h1&gt;Awareness of Emerging Trends&lt;/h1&gt;

&lt;p&gt;To summarize the above, &lt;em&gt;focus on the high-quality content that is deeply relevant and/or unchanging over time&lt;/em&gt;. This brings up an interesting conundrum &amp;ndash; &lt;em&gt;how do we expand our knowledge to new areas?&lt;/em&gt; As previously mentioned, different topics and trends will bleed into each other if they are tangentially related. We can rest assured that we won&amp;rsquo;t be blindsided from an emerging trend.&lt;/p&gt;

&lt;p&gt;I personally like to keep a pulse on emerging trends and technologies. I subscribe to the &lt;a href="https://www.thoughtworks.com/radar"&gt;Technology Radar by ThoughtWorks&lt;/a&gt;, an infrequent but detailed report with insights into the technology and trends shaping the future. To some degree, the trends mentioned in the report help shape new areas that I want to focus on in the near future.&lt;/p&gt;

&lt;h1&gt;Building the Dam&lt;/h1&gt;

&lt;p&gt;To tie everything together, I&amp;rsquo;m going to use the metaphor of a dam.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The flow of water is the content to be consumed.&lt;/li&gt;
&lt;li&gt;The dam is our process to stop the flood, and only allow high-quality content through at a sustainable rate.&lt;/li&gt;
&lt;li&gt;The reservoir is the holding area of content before we consume it.&lt;/li&gt;
&lt;li&gt;The spillway filters out the excess content produced by the flow as it arrives in the reservoir.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The selection process we&amp;rsquo;ve talked about is our dam &amp;ndash; it helps reduce the flow and keeps high-quality content in our reservoir. The flow is composed of content mostly arriving in my email&amp;rsquo;s inbox (via newsletters, and RSS-to-Email). My reservoir is a combination of tools and services: &lt;a href="https://www.instapaper.com"&gt;Instapaper&lt;/a&gt; for individual articles, &lt;a href="https://www.kobo.com/"&gt;Kobo&lt;/a&gt; for books, &lt;a href="https://www.pocketcasts.com/"&gt;Pocket Casts&lt;/a&gt; for podcasts, and a list in &lt;a href="https://www.notion.so/?r=6b8d609eb50943419db4d87c67fa558e"&gt;Notion [Referral]&lt;/a&gt; for video talks.&lt;/p&gt;

&lt;p&gt;One aspect to be aware of is when the reservoir overflows. It is possible that there is just too much material to cover. There are two ways to correct this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Be more aggressive with reducing the flow by removing certain sources that aren&amp;rsquo;t adding as much value as others or being stricter on the selection process of content.&lt;/li&gt;
&lt;li&gt;Actively use a spillway to drain the reservoir by sweeping through the content and discarding things which aren&amp;rsquo;t relevant anymore, or not as impactful.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I plan to post more detailed information regarding my dam, how I manage it, and reasonings for certain decisions. Our information flow/consumption should be as sustainable as a real dam.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Decompressing when Working Remotely</title>
    <link rel="alternate" href="https://kevinjalbert.com/decompressing-when-working-remotely/"/>
    <id>https://kevinjalbert.com/decompressing-when-working-remotely/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2019-02-28T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Working in an office comes with built-in stress relievers, namely social lunchtime with peers and the commute. When working remotely, it is important to ensure your day includes opportunities to decompress from the stresses of work. Learn about my process for decompressing at home.</description>
    <content type="html">&lt;p&gt;At the start of this year, I switched jobs. I intentionally aimed for a remote position so I could reclaim approximately 3 hours of my day from commuting. I have a toddler at home and being able to have more time with him is important to me. I have been in situations at my previous job where I would leave before he would wake up and be back home after he is sleeping. I now have the freedom and flexibility to be present for my son, as well as the opportunity to have lunch with my family.&lt;/p&gt;

&lt;p&gt;Early on, I noticed that I missed certain aspects of my old commute. I was able to decompress in the time between finishing work and being home with my family. I feel the effects of stress when rushed or pressed for time. Since it takes about 20 seconds to go from my office to the main living area, my mind might be still with work without the time to decompress &amp;ndash; this isn&amp;rsquo;t good for my family or myself.&lt;/p&gt;

&lt;h1&gt;Make Boundaries with Time Blocking&lt;/h1&gt;

&lt;p&gt;&lt;img width="1135" height="940" src="/images/2019-02-28-decompressing-when-working-remotely/time-blocking.png" /&gt;&lt;/p&gt;

&lt;p&gt;The above screenshot shows a typical afternoon for me. Let me break down the two important events we can see here.&lt;/p&gt;

&lt;h2&gt;Lunch&lt;/h2&gt;

&lt;p&gt;It can be easy to just eat at your desk quickly and keep on working. Working from home presents unique ways to handle your lunchtime. Offices have built-in mechanisms to relieve stress, like ranting to a colleague about the problem you&amp;rsquo;re hitting, socializing humor and antics, off-topic conversations, etc. For me, it&amp;rsquo;s about making the best use of my time as a dedicated break to relax the brain.&lt;/p&gt;

&lt;p&gt;I took an example from &lt;a href="https://twitter.com/mitchellh/status/1074709385266442246"&gt;Mitchell Hashimoto to block time for lunch&lt;/a&gt;. That time block can move, but I try to ensure that I take an actual lunch. This is time is where I can focus on my family without work distractions (i.e., email and slack) and be present mentally. In the event that I&amp;rsquo;m home alone, I&amp;rsquo;ll eat and read, I&amp;rsquo;ll do some chores or tidying on the main floor while listening to a podcast, and still take the full lunch hour.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m hoping to loop in some regular lunch outings with a remote friend in the neighbourhood who also works in the software domain. I suspect this will help us both get out of the house and provide a listening ear.&lt;/p&gt;

&lt;h2&gt;Decompress&lt;/h2&gt;

&lt;p&gt;At the end of my day, I slot in a 30-minute block of time to decompress. This to me is where I&amp;rsquo;ve reconstructed a &lt;em&gt;fake commute&lt;/em&gt; to detach from work thoughts. I&amp;rsquo;ve been experimenting and feel that these three steps work best for me:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Wrap up the current task. Ideally, this takes less than 10 minutes, as I&amp;rsquo;m simply getting to a checkpoint in my current task. There is a conscious effort to not dive deeper into things, so a natural endpoint will occur quickly.&lt;/li&gt;
&lt;li&gt;Leave a note on what to start with when I get back to work the next day. This should take less than 5 minutes, as I&amp;rsquo;m dumping context in my scratchpad (within &lt;a href="https://www.notion.so/?r=6b8d609eb50943419db4d87c67fa558e"&gt;Notion [Referral Link]&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Mindfulness exercise (i.e., I&amp;rsquo;m using &lt;a href="https://insighttimer.com/"&gt;Insight Timer&lt;/a&gt;) to clear the mind. This should occupy at least 10 minutes. I&amp;rsquo;m rather new to practicing mindfulness but it is something I am making a part of my day-to-day routine. Ending my work day with this helps me to be more present with my family.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Iterate and Improve&lt;/h1&gt;

&lt;p&gt;The above are techniques and strategies I&amp;rsquo;ve put in place to help decompress while working from home. I make it a habit to try and improve my processes, so the same applies here as well. I&amp;rsquo;ll continue to tweak and experiment with the way I handle decompression time when working from home. I highly encourage the same for you; as you never know what you might be missing if you don&amp;rsquo;t try.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Level Up Your Commit Messages</title>
    <link rel="alternate" href="https://kevinjalbert.com/level-up-your-commit-messages/"/>
    <id>https://kevinjalbert.com/level-up-your-commit-messages/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2019-01-30T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Version control is something that all developers have to work through. It is such an essential part of working in the software field, especially in teams. There are many tools, utilities, commands and scenarios to learn. One facet that sometimes is overlooked is the *commit message* itself.</description>
    <content type="html">&lt;p&gt;A well-crafted message is important for yourself and others — it helps frame the context of what changed and why. It is especially important when you have to look back at old commits to figure out why the code has a certain structure or behaviour.&lt;/p&gt;

&lt;p&gt;It is easy to make one-line commit messages that have little-to-no context in the description. There are a couple of reasons one might fall into this behaviour:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Doing exploratory work in which small changes are being made with little care&lt;/li&gt;
&lt;li&gt;Want to move faster (although you will pay for it later)&lt;/li&gt;
&lt;li&gt;Assuming that the &lt;em&gt;why&lt;/em&gt; and &lt;em&gt;what&lt;/em&gt; are obvious (which it might not be to others)&lt;/li&gt;
&lt;li&gt;Not knowing the value of good commit messages&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As the creator of a commit, it is likely you already have a firm grasp of the context surrounding the change. It is not a good assumption that everyone will have the same level of comprehension when they look at your changes. You may also find yourself confused when looking at a commit from several months back if the commit message is lacking context.&lt;/p&gt;

&lt;h1&gt;Foundation of a Good Commit Message&lt;/h1&gt;

&lt;p&gt;You cannot talk about how to make good commit messages without referencing these two fantastic posts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html"&gt;A Note About Git Commit Messages&lt;/a&gt; by Tim Pope&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit"&gt;How to Write a Git Commit Message&lt;/a&gt; by Chris Beams&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even though both are referencing Git, the conventions can be applied to any version control system. I highly encourage you to read the above posts (and then come back) to learn what constitutes a good commit message.&lt;/p&gt;

&lt;p&gt;As a TL;DR, Chris Beams outlines the &lt;a href="https://chris.beams.io/posts/git-commit/#seven-rules"&gt;seven rules of a great commit message&lt;/a&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#separate"&gt;Separate subject from body with a blank line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#limit-50"&gt;Limit the subject line to 50 characters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#capitalize"&gt;Capitalize the subject line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#end"&gt;Do not end the subject line with a period&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#imperative"&gt;Use the imperative mood in the subject line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#wrap-72"&gt;Wrap the body at 72 characters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chris.beams.io/posts/git-commit/#why-not-how"&gt;Use the body to explain &lt;em&gt;what&lt;/em&gt; and &lt;em&gt;why&lt;/em&gt; vs. &lt;em&gt;how&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Commit Early and Often&lt;/h1&gt;

&lt;p&gt;I learned about the &lt;em&gt;Commit Early and Often&lt;/em&gt; approach early in my journey. It is an easy concept to understand, although from experience it can be hard to consistently adhere too.  Seth Robertson&amp;rsquo;s &lt;a href="https://sethrobertson.github.io/GitBestPractices/#commit"&gt;Do commit early and often&lt;/a&gt; article explains the benefits:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Git only takes full responsibility for your data when you commit. If you fail to commit and then do something poorly thought out, you can run into trouble. Additionally, having periodic checkpoints means that you can understand how you broke something.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It depends on the person and project, but it is an easy trap to hold your changes and make large commits for the &lt;em&gt;completed&lt;/em&gt; piece of work. Seth Robertson raises these concerns but suggests you can &lt;em&gt;hide the sausage making process&lt;/em&gt; if you so desire.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;People resist this out of some sense that this is ugly, limits git-bisection functionality, is confusing to observers, and might lead to accusations of stupidity. Well, I’m here to tell you that resisting this is ignorant.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;Hiding the Sausage Making Process&lt;/h1&gt;

&lt;p&gt;As Seth Robertson mentions in his note &lt;a href="https://sethrobertson.github.io/GitBestPractices/#sausage"&gt;on sausage making&lt;/a&gt;, it is the process of doctoring &lt;em&gt;how your final&lt;/em&gt; commits look when completed. By committing early and often, the commits will likely expose your complete development process (i.e., fixing a bug you introduced earlier, adding tests after the fact, etc.).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some people like to hide the sausage making, or in other words pretend to the outside world that their commits sprung full-formed in utter perfection into their git repository. Certain large public projects demand this, others demand smushing all work into one large commit, and still others do not care.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With version control systems, it is possible to edit the commit history. Seth Robertson dives deeper into this in his article on &lt;a href="https://sethrobertson.github.io/GitPostProduction/gpp.html"&gt;Post-Production Editing using Git&lt;/a&gt;. There is another benefit other than the vanity aspect of making a set of commits &lt;em&gt;look&lt;/em&gt; good. By squashing bug fixes or even half-baked solutions into cohesive commits that compile and/or pass tests, you are able to &lt;code&gt;git bisect&lt;/code&gt;, &lt;code&gt;git revert&lt;/code&gt; and &lt;code&gt;git cherry-pick&lt;/code&gt; without much issue. In addition, you are able to squash several commits into logical &lt;a href="https://www.freshconsulting.com/atomic-commits/"&gt;atomic commits&lt;/a&gt; — then code review is straight-forward.&lt;/p&gt;

&lt;p&gt;Personally, I like to commit early and often, and only after the fact will I squash commits down into atomic commits. These commits ideally are valid from a testing/compiling perspective. The whole set of commits that I push up for code review tell the story of &lt;em&gt;what w&lt;/em&gt;as changed and &lt;em&gt;why&lt;/em&gt; it was done.&lt;/p&gt;

&lt;h1&gt;Semantic Commit Messages&lt;/h1&gt;

&lt;p&gt;As an experiment, I&amp;rsquo;m going to be trying out &lt;em&gt;&lt;a href="https://www.conventionalcommits.org"&gt;semantic commit messages (aka conventional commits)&lt;/a&gt;&lt;/em&gt;. The idea here is that commit messages are structured so that it is easy to understand the intention and impact of a commit. In addition, adhering to a consistent format gives commit messages a machine-readable meaning.&lt;/p&gt;

&lt;p&gt;The &lt;a href="https://seesparkbox.com/foundry/semantic_commit_messages"&gt;following snippet from Jeremy Mack&lt;/a&gt; best illustrates how semantic commits are formatted:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;feat: add hat wobble
^--^  ^------------^
|     |
|     +-&amp;gt; Summary in present tense.
|
+-------&amp;gt; Type: chore, docs, feat, fix, refactor, style, or test.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;An optional aspect you can add is a &lt;em&gt;scope&lt;/em&gt; after the &lt;em&gt;type&lt;/em&gt; to indicate the section of the codebase that the commit interacts with (i.e., &lt;code&gt;fix(linter): fix off by one in main loop&lt;/code&gt;). The following is an example of what a commit history with semantic commits might look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;* bc0ee40 - (2 days ago) chore: bump Rails version
* 52f87c0 - (3 days ago) docs: enhance README documentation
* 66fd6f7 - (4 days ago) feat(payment): add new payment option
* 3f0746c - (5 days ago) fix(admin): bug in dropdown selector
* 2b56812 - (6 days ago) refactor(jobs): background job logging
* da75ea2 - (7 days ago) style: remove extra whitespaces
* 3ade674 - (8 days ago) test(payment): add more tests around payment
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above history is easy to understand, and I believe it&amp;rsquo;ll help with creating those &lt;em&gt;atomic commits&lt;/em&gt;. As mentioned, the commit messages become machine-readable and this paves a way to use tools like &lt;a href="https://github.com/semantic-release/semantic-release"&gt;semantic-release&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;Putting It All Together&lt;/h1&gt;

&lt;p&gt;To better integrate semantic commit messages into my workflow, I have the following set as my &lt;code&gt;.gitmessage&lt;/code&gt; template (learn how to use this in &lt;a href="https://robots.thoughtbot.com/better-commit-messages-with-a-gitmessage-template"&gt;this article by Matt Sumner&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;

# &amp;lt;type&amp;gt;(&amp;lt;scope&amp;gt;): &amp;lt;subject&amp;gt;
#
# &amp;lt;type&amp;gt; - chore, docs, feat, fix, refactor, style or test
# (&amp;lt;scope&amp;gt;) - optional, section of codebase involved
# &amp;lt;subject&amp;gt; - present tense summary, whole line is 50 characters
#
# 72-character wrapped longer description. This should answer:
# * Why was this change necessary?
# * How does it address the problem?
# * Are there any side effects?
#
# Include a link to the ticket, if any.
#
# Add co-authors if you worked on this code with others:
# Co-authored-by: Full Name &amp;lt;email@example.com&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As always, keep on levelling up!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Archive Unused Repositories</title>
    <link rel="alternate" href="https://kevinjalbert.com/archive-unused-repositories/"/>
    <id>https://kevinjalbert.com/archive-unused-repositories/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-12-29T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Over time, an individual or organization will create a number of software projects. The purpose of these repositories is to facilitate libraries, micro-services, documentation, mono-repositories, etc. Every so often, the time comes when a repository is no longer used. This article will outline how to archive these repositories, and the benefits to be realized.</description>
    <content type="html">&lt;p&gt;At the time of writing this article, &lt;a href="http://company.thescore.com/"&gt;theScore&lt;/a&gt; has approximately 250 repositories hosted on &lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;. The majority of these are private, although some public ones do exist as well. I suspect that software companies of sufficient size eventually accumulate a large number of repositories due to new projects, libraries, experiments, etc. An employee being faced with these numbers can waste a lot of time searching through these repositories and determining whether a repository is actively used.&lt;/p&gt;

&lt;h1&gt;The Burden&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Note: We&amp;rsquo;ll be focused on GitHub as the platform of choice, although the same principals can be applied to other code hosting platforms.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Over time, a repository can fade in activity and end up in either a &lt;em&gt;finished and active&lt;/em&gt; or a &lt;em&gt;unused&lt;/em&gt; state. In the event that someone stumbles upon an unused repository, they can waste a lot of time if it&amp;rsquo;s not clear that the repository is in fact unused. These repositories faded over time and so it will still have a detailed README and possibly open issues and pull requests. In the worst case scenario, an individual might put time and effort into addressing these unresolved issues to no benefits.&lt;/p&gt;

&lt;p&gt;At theScore, we use &lt;a href="https://help.github.com/articles/about-teams/"&gt;GitHub Teams&lt;/a&gt; to help determine the ownership of repositories. As you can guess, when you have unused repositories, this leads to a cognitive burden on the team. Routine tasks might involve going over all the repositories that a team owns, which just eats up time if you are unsure a repository is used or not.&lt;/p&gt;

&lt;p&gt;In addition, theScore also uses services that periodically check for security violations or outdated dependencies. In a similar vein, these services are triggering for unused repositories, thus leading to more noise. In some instances, the services are priced by the number of repositories or invocations, and so unused repositories can lead to additional costs as well.&lt;/p&gt;

&lt;h1&gt;The Solution&lt;/h1&gt;

&lt;p&gt;So one option that might have crossed your mind is to just delete/remove the repository. While it does the job of reducing the burden of having unused repositories, I would argue that there is a wealth of knowledge in the history of the repository and the code hosting platform (i.e., GitHub via issues and pull requests). A perfect example of where archiving makes a lot of sense is in open source software (i.e., like in &lt;a href="https://github.com/rails/actioncable"&gt;rails/actioncable&lt;/a&gt;) &amp;ndash; you want to retain the open contributions and communications.&lt;/p&gt;

&lt;p&gt;To prevent future confusion and wasted effort/time/cost, we&amp;rsquo;ve made a conscious decision to &lt;em&gt;archive unused repositories&lt;/em&gt;. Fortunately, GitHub actually provides a mechanism for &lt;a href="https://help.github.com/articles/archiving-a-github-repository/"&gt;archiving repositories&lt;/a&gt;. I highly recommend giving &lt;a href="https://blog.github.com/2017-11-08-archiving-repositories/"&gt;GitHub&amp;rsquo;s blog post&lt;/a&gt; a read as it details how you use the feature and provides some recommendations for archiving.&lt;/p&gt;

&lt;p&gt;The main takeaways of archiving a repository on GitHub are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The repository becomes read-only to everyone.&lt;/li&gt;
&lt;li&gt;Forks can still happen in the event someone wants to take the repository in a new direction.&lt;/li&gt;
&lt;li&gt;Archived repositories have a different appearance and can be filtered in a search.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;The Final Change&lt;/h1&gt;

&lt;p&gt;The first thing we do is create our final pull request, which adds the following notice to the top of the README:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# This repository is ⚰️ ARCHIVED ⚰️

FancyProject as a product has been sunsetted and decommissioned as the adoption was not as great as we were hoping for. Resources and efforts were moved to other projects. The last day of operation was on September 18, 2018.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This pull request has at least 4 major tasks in it:&lt;/p&gt;

&lt;h3&gt;1. Close All Open Issues and Pull Requests&lt;/h3&gt;

&lt;p&gt;We close the issues with the following message so that people know the reason why it was closed:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Closing open issues and pull requests as the project is now archived (&amp;lt;pr_of_final_update&amp;gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A link to the pull request is also mentioned in the comment. We do this so the last pull request that GitHub includes all the issues and pull requests that were closed due to the archiving process. You can see an example of this in the image below:&lt;/p&gt;

&lt;p&gt;&lt;img alt="Closed issues and pull requests" width="708" height="612" src="/images/2018-12-29-archive-unused-repositories/closed-issues.jpg" /&gt;&lt;/p&gt;

&lt;h3&gt;2. Set &lt;em&gt;Contributors&lt;/em&gt; to All Developers&lt;/h3&gt;

&lt;p&gt;When a repository is archived you cannot change the contributors (i.e., adding/removing teams). In the event that a repository was only visible to a subset of developers (it sometimes happens), we ensure our &lt;em&gt;developers team&lt;/em&gt; is a contributor before archiving. This subtle change makes it so everyone in the organization can see the repository (in the event it was needed for something).&lt;/p&gt;

&lt;h3&gt;3. Delete Repository from External Services&lt;/h3&gt;

&lt;p&gt;As part of the archiving process, we want to disable/remove any external services that might be monitoring the repository. For example, &lt;a href="https://snyk.io/"&gt;Snyk&lt;/a&gt; checks for security vulnerabilities periodically, and would continue to do so unless disabled. As previously mentioned, some of these services are priced by invocations and/or the number of repositories, so it is important that this step is completed.&lt;/p&gt;

&lt;p&gt;In the event that the repository represents a deployable project, you want to make sure you&amp;rsquo;ve taken steps to &lt;em&gt;decommission&lt;/em&gt; all aspects. For example, there might be servers, databases, cloud storage, etc., that are linked to this repository and need to be taken care of.&lt;/p&gt;

&lt;h3&gt;4. Archive Repository&lt;/h3&gt;

&lt;p&gt;Finally, with everything resolved, we can archive the repository in GitHub. Enjoy the event, as it simplifies the surface area of repositories you have to maintain.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Tracking Production Disruptions</title>
    <link rel="alternate" href="https://kevinjalbert.com/tracking-production-disruptions/"/>
    <id>https://kevinjalbert.com/tracking-production-disruptions/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-11-30T18:53:20-05:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">When operating software in a production environment it is expected to have some unplanned disruptions over time. While the primary task is to resolve the disruption so that the impact is minimized, it is still very much important to track the disruption itself. Disruption reports provide transparency to others, accountability in the actionable tasks, a place for discussion, categorical data, and also a summary of the event.</description>
    <content type="html">&lt;p&gt;Let us first iron out what constitutes a &lt;em&gt;disruption&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Any unexpected degradation or interruption of a service that in any method affects users ability to the service.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When operating a production service, it is simply a matter of time till a disruptions &lt;em&gt;happens&lt;/em&gt;. No matter the safeguards you&amp;rsquo;ve put in place, there is always the expected scenarios. There are many ways to prepare and to ensure that your services are as robust as possible, but that is a task left to you the reader. In this post I&amp;rsquo;ll be talking about what to do &lt;em&gt;after&lt;/em&gt; you&amp;rsquo;ve handled a production disruption.&lt;/p&gt;

&lt;h1&gt;Why Track?&lt;/h1&gt;

&lt;p&gt;A disruption can be a chaotic event, lasting from a few minutes to multiple hours. The main purpose of tracking these disruptions is to have a better understanding of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;what led to the issue.&lt;/li&gt;
&lt;li&gt;what could have been done to prevent the issue from happening?&lt;/li&gt;
&lt;li&gt;flaws in monitoring in detecting when the issue started.&lt;/li&gt;
&lt;li&gt;learnings and processes when dealing with a similar issue in the future.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I highly encourage disseminating the learnings around all aspects of a disruption to the rest of the team and organization. A tracked disruption can be used in a post-mortem. The ultimate goal is by educating everyone it will lead to more resilient services and better processes during the inevitable future disruptions.&lt;/p&gt;

&lt;p&gt;In addition, with tracked disruptions, it becomes easy to perform basic analysis of the frequency and length of disruptions.&lt;/p&gt;

&lt;p&gt;Without any tracking, it becomes a huge failure if the same disruption happens again over and over.&lt;/p&gt;

&lt;h1&gt;Tracking&lt;/h1&gt;

&lt;p&gt;One thing to note is that the following is from experience that I have working at &lt;a href="http://company.thescore.com/"&gt;theScore&lt;/a&gt;, along with reading various sources online. Let us touch on what to track, where to track, and how to track.&lt;/p&gt;

&lt;h2&gt;What to Track?&lt;/h2&gt;

&lt;p&gt;The more information you have the better you&amp;rsquo;ll understand the disruption if you weren&amp;rsquo;t immediately involved in it. Additionally, in most cases, multiple people are involved and so not everyone had the same exposure to the entire event. The following is a list and description of what we track at theScore for disruptions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Service(s)&lt;/strong&gt;: name of service(s) that were interrupted.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disruption Meta-Information&lt;/strong&gt;: at-a-glance information about the disruption.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: what type of disruption (i.e., Infrastructure, Critical Bug, Data Provider, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start Time&lt;/strong&gt;: when the disruption started (not necessarily when it was discovered).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detection Time&lt;/strong&gt;: when the disruption was detected by users/support/team.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;End Time&lt;/strong&gt;: when the disruption was resolved (action items may extend past this time).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Length&lt;/strong&gt;: the total time the disruption was active (based on start/end times).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time to Detection&lt;/strong&gt;: time to detect the disruption (based on start/detection times).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;People Involved&lt;/strong&gt;: list of individuals involved in handling the disruption.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Summary&lt;/strong&gt;: a high-level summary of the disruption (root cause and impact).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt;: a table of events which constructs the timeline of the disruption.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Timestamp&lt;/strong&gt;: approximate time of this event.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Party Involved&lt;/strong&gt;: who/what was involved with this event (i.e., servers, people, services).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: what happened at this event.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Retrospective&lt;/strong&gt;: a reflection of the disruption used for learnings.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Good&lt;/strong&gt;: what went well (i.e., process, safeguards, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bad&lt;/strong&gt;: what went poorly (i.e., process, cascading failures, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lessons&lt;/strong&gt;: what was learned (i.e., flaws in the process, missing monitoring, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action Items&lt;/strong&gt;: assigned items to be completed in a timely fashion related to the disruption.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supporting Documentation&lt;/strong&gt;: additional information (i.e., Slack Logs, Bug Reports, Screenshots, etc&amp;hellip;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Where to Track?&lt;/h2&gt;

&lt;p&gt;To be honest, the none of this matters matter if you aren&amp;rsquo;t tracking disruptions to any capacity, just do it! Even if you have all your disruptions in a single text file, it&amp;rsquo;s better than nothing. Let&amp;rsquo;s get realistic though, we can do much better. For starters, you could opt for a spreadsheet or a basic database, maybe even a heavier integrated service like &lt;a href="https://victorops.com/"&gt;VictorOps&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;At theScore, we use a GitHub repository where each &lt;em&gt;issue&lt;/em&gt; is a disruption report. We record the aforementioned data points in each issue&amp;rsquo;s description. We decided to use GitHub as it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Has great markdown support to provide rich information (i.e., font-styles, links, images, tables).&lt;/li&gt;
&lt;li&gt;Gives us closer integration with our code if we want to link to resources in other repositories.&lt;/li&gt;
&lt;li&gt;Has built-in support for comments on an issue to better facilitate discussions.&lt;/li&gt;
&lt;li&gt;Has labels and open/close states for issues, which layers in additional categorization and grouping.&lt;/li&gt;
&lt;li&gt;Has an API to interface with (for automation and analysis).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For us, our action items become &lt;a href="https://help.github.com/articles/about-task-lists/"&gt;GitHub tasks&lt;/a&gt; with a mentioned individual or team. Issues are to be closed when all action items are resolved, and after sufficient discussion/retrospection has been carried out.&lt;/p&gt;

&lt;h2&gt;How to Track?&lt;/h2&gt;

&lt;p&gt;After a disruption, within a few days, it should be tracked. Waiting too long to track a disruption will result in fuzzy/shallow details. There much special in building up the report, although from personal experience it is good for people to jot notes down immediately after a disruption. I also find it effective to create a specific channel or chatroom in your team&amp;rsquo;s messaging application when dealing with disruptions as all the communication is located in one area.&lt;/p&gt;

&lt;p&gt;PagerDuty has some fantastic material on a &lt;a href="https://response.pagerduty.com/after/post_mortem_process/"&gt;post-mortem process&lt;/a&gt; and even a &lt;a href="https://response.pagerduty.com/after/post_mortem_template/"&gt;post-mortem template&lt;/a&gt;. They also document &lt;a href="https://response.pagerduty.com/before/different_roles/"&gt;defined roles during a disruption&lt;/a&gt;, in which the &lt;em&gt;Scribe&lt;/em&gt; is a critical role for tracking purposes.&lt;/p&gt;

&lt;p&gt;A disruption report can be a single person&amp;rsquo;s responsibility, although it usually helps to reach out to the people involved for clarifying details.&lt;/p&gt;

&lt;h1&gt;Making Sense of the Data&lt;/h1&gt;

&lt;p&gt;With all these disruptions tracked, what can we do with them? Hopefully, all the action items and retrospection have led to large gains. Additionally, there is a lot of value in the data itself, it is simply a matter of finding the signals you want to pay attention too. For example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The frequency of disruptions (per service).

&lt;ul&gt;
&lt;li&gt;What services to focus on improving resilience.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Distribution of when disruptions happen.

&lt;ul&gt;
&lt;li&gt;When to be prepared (i.e., weekend/evenings) for possible on-call resolution.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Time to detection over time.

&lt;ul&gt;
&lt;li&gt;Are the improvements being made to monitoring helping out?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;etc&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Find aspects that your organization cares about and measure them.&lt;/p&gt;

&lt;h1&gt;Improving the Process&lt;/h1&gt;

&lt;p&gt;Never stop and periodically revisit the process to make adjustments. What works for one team, might not work for others. Even though tracking a disruption can be seen as &lt;em&gt;additional&lt;/em&gt; work, it will pay itself off in time.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Automating Slack Statuses for Meetings and Focus Time</title>
    <link rel="alternate" href="https://kevinjalbert.com/automating-slack-statuses-for-meetings-and-focus-times/"/>
    <id>https://kevinjalbert.com/automating-slack-statuses-for-meetings-and-focus-times/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-10-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Slack statuses can be a powerful communication tool for setting up expectations on response times. Using Zapier we look at how we can automate Slack statuses for meetings and focus times.</description>
    <content type="html">&lt;p&gt;I use Slack statuses to communicate my &lt;em&gt;availability to respond&lt;/em&gt; to messages and to set up &lt;em&gt;expectations of my focus for a conversation&lt;/em&gt;. In an office setting, colleagues are able to see whether I&amp;rsquo;m at my desk or not, and that conveys to a certain degree how responsive I might be to messages. I work remotely a few times each week, and on those days my colleagues have even less visibility on whether I would be available or in a meeting.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve come up with a solution for two places where I can automate my Slack status to better communicate expectations and context. Hopefully, these changes will lead to fewer distractions and less ticked off colleagues.&lt;/p&gt;

&lt;h1&gt;Automating Slack Status for Meetings&lt;/h1&gt;

&lt;p&gt;I want to increase transparency in my response times (and set expectations for my colleagues) by updating my Slack status if I&amp;rsquo;m in a meeting. With Slack&amp;rsquo;s recent feature to &lt;a href="https://www.theverge.com/2018/8/30/17802308/slack-auto-expiring-status-updates-feature-change"&gt;auto-expire statuses&lt;/a&gt;, a clean solution using &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt; was possible.&lt;/p&gt;

&lt;p&gt;The following three steps will outline the &lt;em&gt;Zap&lt;/em&gt; I use to automatically update my Slack status with a meeting status.&lt;/p&gt;

&lt;h2&gt;Google Calendar - Event Start Trigger&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-google-calendar-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I use the &lt;em&gt;Google Calendar Event Start&lt;/em&gt; as our trigger, specifying the calendar where all my meetings are set within. I also set the &lt;em&gt;Time Before&lt;/em&gt; value to 16 minutes as I&amp;rsquo;m not subscribed to a high premium plan.&lt;/p&gt;

&lt;h2&gt;Zapier - Delay Until Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-delay-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I want to delay the next step (setting the status) until the actual event starts. This is needed due to how the previous step works, as it might trigger up to 16 minutes earlier than the meeting start time.&lt;/p&gt;

&lt;h2&gt;Slack - Set Status Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/meeting-slack-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I update the Slack status with information on when I will be done my meeting, as well as provide a clear status emoji. With the expiration time field, the status is cleared after the meeting is completed.&lt;/p&gt;

&lt;h2&gt;Possible Issue Due to Multi-Step Zap&lt;/h2&gt;

&lt;p&gt;I have been a user of Zapier for a while, and somehow I have the ability to make &lt;em&gt;3-step Zaps&lt;/em&gt; with the free plan. It is possible to cut the &lt;em&gt;Delay Until&lt;/em&gt; step, but there is a possibility of the &lt;em&gt;Set Status&lt;/em&gt; step running a maximum of 16 minutes earlier than the event&amp;rsquo;s start time.&lt;/p&gt;

&lt;p&gt;You could possibly mitigate this with some clever status text (i.e., &amp;ldquo;Meeting from 3:15 to 3:45&amp;rdquo;). At worse you have a meeting status &lt;em&gt;slightly&lt;/em&gt; before your meeting, which might not be a bad idea as you might be busy preparing or in-transit to a meeting room.&lt;/p&gt;

&lt;h1&gt;Automating Slack Status For Focus Time&lt;/h1&gt;

&lt;p&gt;Another place I automate Slack statuses is for focus time. While at work, there are times I need a deep focus time (i.e., being in the &lt;em&gt;zone&lt;/em&gt;). I use &lt;a href="https://pomodoneapp.com/"&gt;PomoDoneApp&lt;/a&gt; as my &lt;a href="https://francescocirillo.com/pages/pomodoro-technique"&gt;Pomodoro&lt;/a&gt; application of choice. Fortunately for me, it also interfaces with Zapier.&lt;/p&gt;

&lt;p&gt;The goal here is for colleagues to know that I&amp;rsquo;m busy and might not get back to their messages until I have a break from my deep work.&lt;/p&gt;

&lt;h2&gt;PomoDoneApp - New Timer Started Trigger&lt;/h2&gt;

&lt;p&gt;With PomoDoneApp, Zapier will trigger whenever a timer begins. There is nothing to configure here, so the setup is straight forward for this step.&lt;/p&gt;

&lt;h2&gt;Slack - Set Status Action&lt;/h2&gt;

&lt;p&gt;&lt;img width="1227" height="1062" src="/images/2018-10-30-automating-slack-statuses-for-meetings-and-focus-times/pomodone-slack-step.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;At this step, I&amp;rsquo;m just setting the appropriate status (i.e., focusing) to indicate that I&amp;rsquo;m in deep work. As per the Pomodoro technique, after the timer is up I&amp;rsquo;m free for a small break. The status expiration helps accommodate this workflow easily.&lt;/p&gt;

&lt;h1&gt;Slack Statuses While Working Remotely&lt;/h1&gt;

&lt;p&gt;So, as I mentioned earlier, I occasionally work remotely. This presents an interesting problem of conveying two statuses simultaneously. My workaround isn&amp;rsquo;t pretty but it works&amp;hellip; I simply change my Slack name to &amp;ldquo;Kevin Jalbert (WFH)&amp;rdquo; to indicate that I&amp;rsquo;m working from home that day. This move frees up my actual Slack status to be automated throughout the day.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Todoist with Keyboard Navigation via Nativefier</title>
    <link rel="alternate" href="https://kevinjalbert.com/todoist-with-keyboard-navigation-via-nativefier/"/>
    <id>https://kevinjalbert.com/todoist-with-keyboard-navigation-via-nativefier/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-09-30T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Todoist does not have strong keyboard navigation and shortcuts. Fortunately, there is a browser extension that augments the web client to support better keyboard navigation. This article outlines how to gain this functionality in a desktop version of Todoist using 'nativefier'.</description>
    <content type="html">&lt;p&gt;&lt;a href="https://todoist.com"&gt;Todoist&lt;/a&gt; is a powerful task manager. It offers a &lt;a href="https://itunes.apple.com/ca/app/todoist-organize-your-life/id585829637"&gt;MacOS Application&lt;/a&gt; that provides a desktop experience and a dedicated &lt;em&gt;quick task adding&lt;/em&gt; feature. I am a poweruser of the keyboard (i.e., I use &lt;a href="https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en"&gt;Vimium&lt;/a&gt; in Chrome), and my big issue is that Todoist doesn&amp;rsquo;t offer strong keyboard navigation. Fortunately, &lt;a href="https://github.com/mgsloan/todoist-shortcuts"&gt;todoist-shortcuts&lt;/a&gt; adds much-needed keyboard navigation to the web client as a browser extension.&lt;/p&gt;

&lt;p&gt;I enjoy having &lt;em&gt;dedicated tools/applications&lt;/em&gt; for tasks and tend to keep my browser for ephemeral tasks. Therefore I wanted to keep Todoist as a desktop application but with the keyboard navigation extension.&lt;/p&gt;

&lt;h2&gt;Web Application -&amp;gt; Desktop Application&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve used &lt;a href="https://github.com/jiahaog/nativefier"&gt;nativefier&lt;/a&gt; in the past to create a desktop version of various web applications. Quick searching showed the following &lt;a href="https://github.com/jiahaog/nativefier/issues/207"&gt;issue&lt;/a&gt; mentioning that adding a Chrome extention isn&amp;rsquo;t supported, although it is possible to &lt;em&gt;inject&lt;/em&gt; custom JavaScript to be executed within the newly created application.&lt;/p&gt;

&lt;p&gt;The following command will build the application while injecting &lt;a href="https://github.com/mgsloan/todoist-shortcuts/blob/v22/src/todoist-shortcuts.js"&gt;&lt;code&gt;src/todoist-shortcuts.js&lt;/code&gt;&lt;/a&gt; in it. The injected file contains all of the keyboard navigation of &lt;code&gt;todoist-shortcuts&lt;/code&gt;. In addition, other options were provided to &lt;code&gt;nativefier&lt;/code&gt; so that we have support for badge counts and bouncing the dock icon on changes when out of focus (MacOS).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight shell"&gt;&lt;code&gt;nativefier &lt;span class="s1"&gt;'https://todoist.com/'&lt;/span&gt; &lt;span class="nt"&gt;--name&lt;/span&gt; &lt;span class="s1"&gt;'Todoist'&lt;/span&gt; &lt;span class="nt"&gt;--icon&lt;/span&gt; ./todoist-icon.png &lt;span class="nt"&gt;--inject&lt;/span&gt; ./todoist-shortcuts-22/src/todoist-shortcuts.js &lt;span class="nt"&gt;--counter&lt;/span&gt; &lt;span class="nt"&gt;--bounce&lt;/span&gt; &lt;span class="nt"&gt;--single-instance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The produced application works as expected. Keyboard navigation exists within the &lt;code&gt;nativefier&lt;/code&gt; created application. Unfortunately, the badge count aspect did not&amp;hellip;&lt;/p&gt;

&lt;h3&gt;Supporting Badge Count&lt;/h3&gt;

&lt;p&gt;The reason the badge count didn&amp;rsquo;t work is because &lt;code&gt;nativefier&lt;/code&gt; is looking in the title of the window/application for the number (using a regular expression). To solve this, we will need some additional JavaScript that will propagate the number of tasks in &lt;em&gt;Today&lt;/em&gt; into the title (while handling edge cases). It isn&amp;rsquo;t the prettiest, but the following &lt;code&gt;counter.js&lt;/code&gt; snippet does the trick:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// Returns the count for the 'Today' list (defaults to 0)&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;currentCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#top_filters &amp;gt; li:nth-child(2) &amp;gt; span.item_content &amp;gt; small'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;innerText&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Returns the title without any annotated count&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;titleWithoutCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" ("&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Returns the existing count from the title (defaults to 0)&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;existingCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;indexOf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" ("&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;indexOfCount&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Update badge count based on the number in Today&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;currentCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;titleWithoutCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;===&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt; &lt;span class="o"&gt;!==&lt;/span&gt; &lt;span class="nx"&gt;existingCount&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;newTitle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;`&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; (&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;count&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;)`&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;!==&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;newTitle&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Update the badge every 5 seconds&lt;/span&gt;
&lt;span class="nx"&gt;setInterval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;// Update the badge when the title changes&lt;/span&gt;
&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;MutationObserver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;mutations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;updateBadgeCount&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="nx"&gt;observe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="na"&gt;subtree&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;characterData&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;childList&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unfortunately, &lt;code&gt;nativefier&lt;/code&gt; has an issue with &lt;a href="https://github.com/jiahaog/nativefier/issues/458"&gt;injecting multiple JavaScript files&lt;/a&gt;. As a workaround, we concatenate the JavaScript into one file before &lt;em&gt;injecting it&lt;/em&gt; (which fortunately works with the JavaScript we have).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nb"&gt;cat&lt;/span&gt; ./counter.js &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; todoist.js&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;cat&lt;/span&gt; ./todoist-shortcuts-22/src/todoist-shortcuts.js &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; todoist.js
nativefier &lt;span class="s1"&gt;'https://todoist.com/'&lt;/span&gt; &lt;span class="nt"&gt;--name&lt;/span&gt; &lt;span class="s1"&gt;'Todoist'&lt;/span&gt; &lt;span class="nt"&gt;--icon&lt;/span&gt; ./todoist-icon.png &lt;span class="nt"&gt;--inject&lt;/span&gt; ./todoist.js &lt;span class="nt"&gt;--counter&lt;/span&gt; &lt;span class="nt"&gt;--bounce&lt;/span&gt; &lt;span class="nt"&gt;--single-instance&lt;/span&gt; &lt;span class="nt"&gt;--overwrite&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Desktop Todoist with Keyboard Navigation&lt;/h2&gt;

&lt;p&gt;At this point, we&amp;rsquo;ve successfully wrapped the web client of Todoist for Desktop while injecting &lt;code&gt;todoist-shortcuts&lt;/code&gt;. Badge support is preserved and notifications continue to function.&lt;/p&gt;

&lt;p&gt;I still like the &lt;em&gt;quick task adding&lt;/em&gt; feature of the original Todoist application on the desktop, but unfortunately, that was outside the scope of what I could do with &lt;code&gt;nativefier&lt;/code&gt;. As a workaround, I&amp;rsquo;ve renamed the original application to &lt;code&gt;Todoist-store&lt;/code&gt; and moved the new application over with no naming conflicts. I run both applications so that I can continue to use the &lt;em&gt;quick task adding&lt;/em&gt; feature, although I hide &lt;code&gt;Todist-store&lt;/code&gt;in the tray and prevent any notifications from appearing.&lt;/p&gt;

&lt;p&gt;To simplify the process of extending/modifying/building this solution, I&amp;rsquo;ve put together the following &lt;a href="https://github.com/kevinjalbert/todoist-shortcuts-nativefier"&gt;repository on GitHub&lt;/a&gt;. I hope that Todoist simply adds better keyboard navigation in their client by default&amp;hellip; but until then, I&amp;rsquo;ll be using this solution.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Video Clubs: A Way to Keep Up</title>
    <link rel="alternate" href="https://kevinjalbert.com/video-clubs-a-way-to-keep-up/"/>
    <id>https://kevinjalbert.com/video-clubs-a-way-to-keep-up/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-08-28T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">Keeping up in your industry can be hard. Conferences offer industry-leading information and the direction of the community. Attending conferences is expensive in both cost and time. Learn how to start a video club to better consume conference videos in your workplace at a sustainable pace.</description>
    <content type="html">&lt;p&gt;As a knowledge worker, a lot of our time is spent thinking about problems and solutions. We rely on pattern matching and experience while working to make the best progress we can. Is there a way to accelerate our learning and keep a pulse on new, upcoming, and innovative solutions? I will be approaching this question from a developer&amp;rsquo;s perspective, although the ideas presented here can be applied to other domains.&lt;/p&gt;

&lt;p&gt;Being aware of best practices, new techniques, alternative frameworks, and really anything in general for your domain is good. I would attribute some of my successes to &lt;em&gt;surface knowledge&lt;/em&gt; (i.e., having a high-level understanding), as it allows you to know of alternatives and possible solutions. Obviously, you would dive deeper into the area if you are going to invest more effort into it. In a way, this promotes a &lt;em&gt;just-in-time learning&lt;/em&gt; philosophy, to focus on areas as needed. Again, the key is that you &lt;em&gt;know&lt;/em&gt; of these areas.&lt;/p&gt;

&lt;h1&gt;Keeping up as Developers&lt;/h1&gt;

&lt;p&gt;I encourage developers to do the following, although from my experiences it&amp;rsquo;s common for developers to be doing at least some of these activities already:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read blog posts: low friction and easily discoverable source of information, it normally comes naturally while developing.&lt;/li&gt;
&lt;li&gt;Listen to podcasts: commuter friendly, topical and timely due to the &lt;em&gt;real-time&lt;/em&gt; nature, interviews with high-calibre people can be insightful.&lt;/li&gt;
&lt;li&gt;Read Books: a wealth of knowledge but require more time investment.&lt;/li&gt;
&lt;li&gt;Attend meetups: allows for networking with like-minded individuals, local groups, talks or workshops, typically free to attend.&lt;/li&gt;
&lt;li&gt;Attend conferences: like meetups but normally of a higher calibre and immersive, costs a lot of money to attend.&lt;/li&gt;
&lt;li&gt;Watch conference videos: talks of a conference, without the cost and networking aspects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I want to focus on the last point &amp;ndash; watching conference videos. To me, this activity presents an affordable solution to attending conferences (from a time/money perspective). Additionally, conferences sometimes have multiple tracks and so, even as an attendee, it is not possible to see all the talks. The videos from a conference are usually available a few weeks after the conference. To me, conference talks represent distilled knowledge condensed into 30-60 minutes.&lt;/p&gt;

&lt;p&gt;I would argue that it is a developer&amp;rsquo;s job to keep up with the community and to &lt;em&gt;learn&lt;/em&gt; from industry-leaders. It can be hard to find the time to watch these videos on your own (i.e., evenings or weekends). Not only is the time a constraint, but also if you are consuming a conference video by yourself you are missing out on valuable discussions with peers immediately after the talk. So in an effort to better facilitate the time for learning, I am proposing the following: to start a &lt;em&gt;video club at your workplace&lt;/em&gt;!&lt;/p&gt;

&lt;h1&gt;The Workings of a Video Club&lt;/h1&gt;

&lt;p&gt;At theScore, the way we&amp;rsquo;ve handled our video club has evolved over the years. Initially, the flow worked like so:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;See an interesting video to watch.&lt;/li&gt;
&lt;li&gt;Add video URL to video club page in wiki (&lt;a href="https://www.atlassian.com/software/confluence"&gt;Confluence&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Once a week people would gather at lunch for the video club.&lt;/li&gt;
&lt;li&gt;Watch the next video or one which the audience really wants to see.&lt;/li&gt;
&lt;li&gt;Discuss (maybe?).&lt;/li&gt;
&lt;li&gt;Continue on with the day.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This flow worked and to be honest was fine. The main issue we wanted to fix was more transparency and organization around the videos. By addressing these concerns, the idea is that we&amp;rsquo;d be able to surface the most desired videos to be watched, as well as better facilitating discussion and recording findings.&lt;/p&gt;

&lt;p&gt;The next section outlines how we&amp;rsquo;ve changed our video club to better work for developers, mainly taking advantage of GitHub and Slack. These changes have been well received, and it seems to better encourage the functioning aspects of the video club. I do want to mention that this next section is going to be highly tailored to developers.&lt;/p&gt;

&lt;h1&gt;Video Club on GitHub&lt;/h1&gt;

&lt;p&gt;We decided to move away from the wiki version of the video club to GitHub. The main reasons were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Better structure (i.e., issues, labels, etc&amp;hellip;).&lt;/li&gt;
&lt;li&gt;Familiar to developers.&lt;/li&gt;
&lt;li&gt;Voting via &lt;em&gt;reactions&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Slack + GitHub integration for visibility.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Setup Repository&lt;/h2&gt;

&lt;p&gt;The first thing we need is a repository &lt;code&gt;video-club&lt;/code&gt; (or any other name you like). We only need two files in our repository:&lt;/p&gt;

&lt;p&gt;The following is the content of the &lt;code&gt;README.md&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# The Video Club
* Video club for weekly educational videos
* Place for tracking/voting/discussion
* Slack Channel #video-club

## Would like to group watch a video?
* Create an issue
* Throw some labels on it
* Get people to vote on it with the :thumbsup: reactions

## Each week the highest voted video is watched
* Discussion happens immediately afterwards
* Issue could be updated with large takeaway points
* Close the issue
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following is the content of the &lt;code&gt;ISSUE_TEMPLATE.md&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;## [Video Title -- Also should be issue title](video.url)

### Description
&amp;lt;!-- Talk's description --&amp;gt;

### Time Length
&amp;lt;!-- Length of the video (i.e., 16m, 1h10m) --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Videos as Issues&lt;/h2&gt;

&lt;p&gt;&lt;img width="1001" height="692" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/issues.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;As you can see in the above image, each &lt;em&gt;GitHub Issue&lt;/em&gt; represents a video within our repository. As we have an &lt;code&gt;ISSUE_TEMPLATE.md&lt;/code&gt; each issue then follows a consistent format containing context and information about the video. Ideally, we want the inputting process for a video to be as low-friction as possible. Right now it is pretty quick to create a new issue for a video, although &lt;strong&gt;one thing I would like to do is create a bookmarklet or browser extension to pre-fill an issue based on the video URL&lt;/strong&gt;. The following image illustrates an example video in our issue format.&lt;/p&gt;

&lt;p&gt;&lt;img width="1022" height="521" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/video-issue.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;You can see that we take advantage of &lt;em&gt;Issue Labels&lt;/em&gt; as well to further categorize the videos. We&amp;rsquo;re pretty loose with their usage, but it does provide additional context and filtering capabilities. One other aspect to notice is that we use &lt;em&gt;Issue Reactions&lt;/em&gt; to &lt;em&gt;vote&lt;/em&gt; on videos that a participant would like to watch at some point. These votes are then used to help &lt;em&gt;pick the next video&lt;/em&gt;, as we will see in the next section.&lt;/p&gt;

&lt;h2&gt;Picking the Next Video&lt;/h2&gt;

&lt;p&gt;One of the main draws to using GitHub Issues is that we can vote using the reactions and then and sort the issues by &lt;em&gt;votes&lt;/em&gt; (i.e., thumbsup reactions on the issue). This approach allows the participants to weigh in on what they would like to see. The end goal is that the most highly desired videos will be watched. By sorting the open issues by votes, the process of picking the next video is pretty straightforward.&lt;/p&gt;

&lt;p&gt;&lt;img width="999" height="506" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/next-video-sorting.jpg" /&gt;&lt;/p&gt;

&lt;h2&gt;Discussion and Context&lt;/h2&gt;

&lt;p&gt;The fact that we have GitHub Issues gives us a space for discussion using &lt;em&gt;GitHub Comments&lt;/em&gt;. After the video has been watched, we carry out a 5~ minute discussion and record the high-level takeaways. Our video club accommodates remote attendees (coordination is done via Slack), and in those situations, we use video conferencing to facilitate the discussion process.&lt;/p&gt;

&lt;p&gt;Ideally, additional discussion can be carried out via more comments (even later after the video has been watched). We use GitHub for our projects, and having the videos as issues allows us to link to videos if we want to use them as references or talking points in other issues or pull requests. Finally, a video issue is closed after the initial discussion is written up for it. The following image demonstrates the aforementioned concepts.&lt;/p&gt;

&lt;p&gt;&lt;img width="782" height="630" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/completed-video.jpg" /&gt;&lt;/p&gt;

&lt;h2&gt;Slack Integration&lt;/h2&gt;

&lt;p&gt;To increase transparency and engagement, we are using the &lt;a href="https://slack.github.com/"&gt;GitHub + Slack integration&lt;/a&gt;. This allows us to have events in our &lt;code&gt;video-club&lt;/code&gt; repository to be pushed to our &lt;code&gt;#video-club&lt;/code&gt; Slack channel.&lt;/p&gt;

&lt;p&gt;When someone adds a new video, the issue&amp;rsquo;s content (following the template) lets everyone know of a new video they could vote on:
&lt;img width="640" height="420" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-new-video.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;We use &lt;a href="/slack-reminding-users-and-channels/"&gt;Slack&amp;rsquo;s channel reminders&lt;/a&gt; to ping the room to ensuring that votes are cast prior to the time we&amp;rsquo;ll watch a video. In addition, we announce a bit before what video we will watch based on the sorting of votes:
&lt;img width="760" height="555" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-video-selected.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;Discussion notes and comments are pushed through the channel to help surface further comments:
&lt;img width="635" height="490" src="/images/2018-08-28-video-clubs-a-way-to-keep-up/slack-video-finished.jpg" /&gt;&lt;/p&gt;

&lt;h1&gt;Starting a Video Club&lt;/h1&gt;

&lt;p&gt;So, are you are psyched to start a video club in your workplace? Now, how do you sell the idea to your boss and peers? You are trying to take 60~ minutes every week or so to watch &lt;em&gt;videos&lt;/em&gt;&amp;hellip; it doesn&amp;rsquo;t sound like a good use of work time. Again, the whole point of this is to improve yourself and that these changes will be reflected in the work you do (i.e., knowing better practices and tools).&lt;/p&gt;

&lt;p&gt;There are different ways to go about starting a video club, and honestly, it could be as straightforward as asking your boss and peers. I personally think if you can &lt;em&gt;embody&lt;/em&gt; the change, it is an easier sell to the organization and your direct manager. First thing I would do is personally find a set of high-quality videos from a conference relevant to your domain (i.e., could even be old ones). Put these out in the open as great material that everyone &lt;em&gt;should&lt;/em&gt; watch at some point (which shouldn&amp;rsquo;t be a stretch from the truth). Suggest a brown bag lunch event, everyone brings their lunch (or buys it) and watches the video during their lunch. Encourage discussion and see if there are any takeaways that might be directly related to the work at hand. Then, eventually, you start to transition to an organizational model (i.e., GitHub) and getting participation from your peers by suggesting videos.&lt;/p&gt;

&lt;p&gt;This is a cultural shift you are trying to create, therefore it could be slow. I believe the end goal is to move away from the brown bag lunch and instead to a dedicated &lt;em&gt;meeting time&lt;/em&gt; so that the video club isn&amp;rsquo;t taking up everyone&amp;rsquo;s personal time at lunch. I&amp;rsquo;ve seen various attendees drop off due to external lunch plans. Hopefully, a higher attendance can be achieved if it&amp;rsquo;s a normal meeting time. Overall, I would say either you&amp;rsquo;ll get your manager/organization to buy into the idea, or you will be stuck doing brown bag lunches. &lt;strong&gt;In either case, &lt;em&gt;you&lt;/em&gt; will be improving and investing in yourself.&lt;/strong&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 4]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-4/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-4/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-07-18T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the last of four parts on GraphQL Persisted Queries with HTTP Caching. We end by adding HTTP caching to our Express, Rails and React applications.</description>
    <content type="html">&lt;p&gt;This is the last part of a four-part series on GraphQL Persisted Queries with HTTP Caching. As a recap of &lt;a href="/graphql-persisted-queries-with-http-caching-part-3/"&gt;part three&lt;/a&gt;, we created a Rails application capable of handling persisted queries.&lt;/p&gt;

&lt;p&gt;In part four we will cover the following topics:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add HTTP Caching to React Application&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Express Server&lt;/li&gt;
&lt;li&gt;Add HTTP Caching to Rails Server&lt;/li&gt;
&lt;li&gt;Alternative Caching with Gateways&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Caching with GraphQL&lt;/h1&gt;

&lt;p&gt;There are different ways to &lt;em&gt;cache&lt;/em&gt; with GraphQL:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.apollographql.com/docs/react/advanced/caching.html"&gt;Caching on the Apollo client&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mgiroux.me/2016/graphql-query-caching-with-rails/"&gt;Caching the parsed and validated GraphQL query&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chatterbugapp/cacheql"&gt;Caching field and response resolutions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Amongst other mechanisms and techniques.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our situation, we&amp;rsquo;re interested in HTTP caching, and the way to achieve this is to make our GraphQL network requests use &lt;code&gt;GET&lt;/code&gt; instead of &lt;code&gt;POST&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The main benefit for HTTP caching is that it allows CDNs and reverse proxy&amp;rsquo;s (i.e., &lt;a href="https://varnish-cache.org/"&gt;Varnish&lt;/a&gt;) to cache intermediate responses based on the response&amp;rsquo;s headers (i.e., &lt;code&gt;Cache-Control&lt;/code&gt;). This results in fewer requests hitting your server as the results might be cached, perfect for scaling your API. Even a short cache (i,e., &amp;lt; 10 seconds) could be extremely valuable as this cache could be shared across all consumers of the API.&lt;/p&gt;

&lt;p&gt;I want to bring up an article by &lt;a href="https://twitter.com/_CoreyClark"&gt;Corey Clark&lt;/a&gt; which tackles a very similar problem on how to use &lt;a href="https://medium.com/@coreyclark/graphql-persisted-queries-using-get-requests-8a6704aba9eb"&gt;&lt;code&gt;GET&lt;/code&gt; requests with GraphQL Persisted Queries&lt;/a&gt;. Both the current post and Corey&amp;rsquo;s article reach a similar state in achieving HTTP cacheability using &lt;code&gt;GET&lt;/code&gt; requests.&lt;/p&gt;

&lt;p&gt;In the following sections, we will augment our Express and Rails servers as well as our React application to use &lt;code&gt;GET&lt;/code&gt; requests. To simplify things, we&amp;rsquo;re going to apply a simple 10-second cache on all our responses (ideally you could tailor this to the individual query). In addition, we&amp;rsquo;re going to make an assumption that we don&amp;rsquo;t have any personalized data in our query responses.&lt;/p&gt;

&lt;h2&gt;Add HTTP Caching to React Application&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/5cbb630c4780d20bc2747b0b62035a3702e87a3b"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fortunately, the &lt;code&gt;apollo-link-persisted-queries&lt;/code&gt; link has a simple option (&lt;code&gt;useGETForHashedQueries&lt;/code&gt;) to enable &lt;code&gt;GET&lt;/code&gt; requests for queries (but not mutations):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;ApolloClient&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
  &lt;span class="na"&gt;link&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;createPersistedQueryLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;useGETForHashedQueries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt; &lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="nx"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nx"&gt;createHttpLink&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'http://localhost:5000/graphql'&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="na"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;InMemoryCache&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now the outbound requests look like the following (a bit messy, but gets the job done):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;http://localhost:5000/graphql?operationName=ConsolesByYear&amp;amp;variables=%7B%22afterYear%22%3A1990%2C%22beforeYear%22%3A2000%7D&amp;amp;extensions=%7B%22persistedQuery%22%3A%7B%22version%22%3A1%2C%22sha256Hash%22%3A%22a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80%22%7D%7D
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To better see the requests being cached on the HTTP layer, we&amp;rsquo;re going to modify the &lt;code&gt;Query&lt;/code&gt; in our &lt;code&gt;ConsoleContainer&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;Query&lt;/span&gt; &lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;QUERY&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nx"&gt;variables&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;afterYear&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;beforeYear&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt; &lt;span class="nx"&gt;fetchPolicy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'network-only'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By adding &lt;code&gt;fetchPolicy&lt;/code&gt; of &lt;code&gt;network-only&lt;/code&gt; the &lt;code&gt;apollo-client&lt;/code&gt; will not cache responses, and thus each query will be sent to the GraphQL API.&lt;/p&gt;

&lt;h2&gt;Add HTTP Caching to Express Server&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/0bf8d6bccc5649b00dda77b4dfdce523c22b4796"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We have to do a couple things to get our Express server in shape to serve &lt;code&gt;GET&lt;/code&gt; requests. First thing is to remove the &lt;code&gt;bodyParser&lt;/code&gt; middleware as we aren&amp;rsquo;t parsing a &lt;code&gt;POST&lt;/code&gt; anymore. We will also adjust our &lt;code&gt;GraphQLServer&lt;/code&gt; options to toggle the &lt;code&gt;getEndpoint&lt;/code&gt;, which adds a &lt;code&gt;GET&lt;/code&gt; endpoint using our defined GraphQL route. Finally, we have to modify our &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; to be on the &lt;code&gt;GET&lt;/code&gt; route for &lt;code&gt;/graphql&lt;/code&gt;. Those changes looks like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// server.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'graphql-yoga'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/typeDefs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./graphql/resolvers'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./persistedQueriesMiddleware'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;GraphQLServer&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;typeDefs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;resolvers&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;getEndpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;endpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;playground&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'/playground'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/graphql'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;start&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;`Server started, listening on port &lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; for incoming requests.`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We also have to modify our &lt;code&gt;persistedQueriesMiddleware&lt;/code&gt; itself to parse the &lt;code&gt;GET&lt;/code&gt; query parameters and specify the response&amp;rsquo;s &lt;code&gt;Cache-Control&lt;/code&gt; header for a &lt;code&gt;max-age&lt;/code&gt; of 10 seconds:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// persistedQueriesMiddleware.js&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'lodash'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;invert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'./extracted_queries.json'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Handling request to: '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Cache-Control'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'public, max-age=10'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;extensions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;querySignature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sha256Hash&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;extractedQueries&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;querySignature&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;persistedQuery&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Invalid querySignature'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;persistedQuery&lt;/span&gt;
  &lt;span class="nx"&gt;next&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;exports&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;persistedQueriesMiddleware&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Add HTTP Caching to Rails Server&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/c3bcc3588012a9b4b22bd582c80de3e0dd208078"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For our Rails server, we have a few small changes to make to allow for &lt;code&gt;GET&lt;/code&gt; requests. First, we&amp;rsquo;ll add a new route to allow for &lt;code&gt;GET&lt;/code&gt; requests, under the same URL and controller action:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="c1"&gt;# .. other routes&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
  &lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Like before, we handle the persisted queries within the &lt;code&gt;GraphqlController&lt;/code&gt;. We need to tweak the controller to conform to the new query parameters structure of the React application&amp;rsquo;s requests. We will also add an &lt;code&gt;expires_in&lt;/code&gt; to add in the 10-seconds of &lt;code&gt;max-age&lt;/code&gt; for the response&amp;rsquo;s &lt;code&gt;Cache-Control&lt;/code&gt; header:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;expires_in&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;public: &lt;/span&gt;&lt;span class="kp"&gt;true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;extensions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:extensions&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
      &lt;span class="n"&gt;signature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"persistedQuery"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"sha256Hash"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find_by!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;signature&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;

    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Alternative Caching with Gateways&lt;/h2&gt;

&lt;p&gt;I didn&amp;rsquo;t mention &lt;a href="https://www.apollographql.com/engine"&gt;Apollo Engine&lt;/a&gt;, but this is a recent development in the GraphQL caching space. It provides a layer which sits in front of your GraphQL server and handles caching, query execution tracing, and error tracking. It is a paid solution if you need to handle more than 1 million requests per month.&lt;/p&gt;

&lt;p&gt;Part of the secret sauce for caching with Apollo Engine is that it introduced the &lt;a href="https://github.com/apollographql/apollo-cache-control"&gt;Apollo Cache Control&lt;/a&gt; GraphQL extension. This allows the GraphQL API to return cache hints on a per field-level. Effectively, this allows the caching to be smarter than simply a blanket solution.&lt;/p&gt;

&lt;p&gt;For additional reading on these technologies and techniques, I recommend the following article on &lt;a href="https://dev-blog.apollodata.com/caching-graphql-results-in-your-cdn-54299832b8e2"&gt;Caching GraphQL Results in your CDN&lt;/a&gt; as it uses Automatic Persisted Queries, Apollo Cache Control, and Apollo Engine.&lt;/p&gt;

&lt;p&gt;Another paid solution (if you exceed 5,000 requests per months) is &lt;a href="https://fastql.io/"&gt;FastQL&lt;/a&gt;. This is a new gateway solution which acts as its own CDN, handling caching and expiration of fields. You are able to manually invalidate field-level caches through an API, or automatically invalidate by sending mutations through their CDN (which expires fields related to the mutation object type).&lt;/p&gt;

&lt;h1&gt;Reflection&lt;/h1&gt;

&lt;p&gt;There are a lot of options available for caching with GraphQL. It is possible to do so at different layers of the flow using different techniques and technologies. In this last post of the series we mainly took a look at HTTP caching. By enabling &lt;code&gt;GET&lt;/code&gt; requests we were half-way there &amp;ndash; the last bit remaining is attaching the appropriate &lt;code&gt;Cache-Control&lt;/code&gt; headers. Admittedly, we took an easy approach of blanketing all responses with a 10 second &lt;code&gt;max-age&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Depending on your situation, you might need to further explore the field-level caching options like Apollo Cache Control, or even using a Gateway to help out, like FastQL. Even though being aware of the data within your queries is important, is it all cacheable? If you have personalized data you have to approach this in a different way. There might not be value in caching if every response is personalized to a user, or maybe you have to split your queries into two queries (i.e., personalized, non-personalized). The cache configuration (i.e., CDN and/or a reverse proxy) is a huge piece we skipped over, but it likely will need some tweaking for your specific use cases (i.e., split caching based on the header).&lt;/p&gt;

&lt;p&gt;Overall, I am pleased with the solutions we arrived too. We built a simple GraphQL API in Express and Rails. Both of these can communicate with a React application using persisted queries. Our Express server used a JSON file for its data and persisted queries, while for our Rails server we had everything in a database. We overcame the issues with the existing tooling for determining a signature for each query, and created the ability to synchronize persisted queries via HTTP &lt;code&gt;POST&lt;/code&gt; requests. We were able to implement &lt;code&gt;GET&lt;/code&gt; requests and apply a 10-second cache for intermediate CDN and reverse proxies.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <title>GraphQL Persisted Queries with HTTP Caching [Part 3]</title>
    <link rel="alternate" href="https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-3/"/>
    <id>https://kevinjalbert.com/graphql-persisted-queries-with-http-caching-part-3/</id>
    <updated>2019-04-30T21:31:27-04:00</updated>
    <published>2018-07-17T19:53:20-04:00</published>
    <author>
      <name>Kevin Jalbert</name>
    </author>
    <description type="html">This is the third of four parts on GraphQL Persisted Queries with HTTP Caching. We continue our journey with creating a Rails GraphQL API, synchronizing queries to it, and adapting it to use persisted queries.</description>
    <content type="html">&lt;p&gt;This is the third part of a four-part series on GraphQL Pesisted Queries with HTTP Caching. As a recap of &lt;a href="/graphql-persisted-queries-with-http-caching-part-2/"&gt;part two&lt;/a&gt;, we created an Express server and React application, both using persisted queries.&lt;/p&gt;

&lt;p&gt;In part three we will cover the following topics:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setup Rails Server&lt;/li&gt;
&lt;li&gt;Synchronize GraphQL Queries to Rails Server&lt;/li&gt;
&lt;li&gt;Refactor Rails Server to use Persisted Queries&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;Setup Rails Server&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/5f78ac6dd2840a8690d82e4b50a752471332c8c2"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We&amp;rsquo;ll create a basic Rails server that uses &lt;a href="https://github.com/rmosolgo/graphql-ruby"&gt;&lt;code&gt;graphql-ruby&lt;/code&gt;&lt;/a&gt;. We will gloss over the busy work of setting up the models, database, and GraphQL types. First, we have our route defined that will accept &lt;code&gt;POST&lt;/code&gt; requests to &lt;code&gt;/graphql&lt;/code&gt; and passes them to our controller.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# config/routes.rb&lt;/span&gt;
&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The controller then extracts the variables, query, and operation name from the request&amp;rsquo;s parameters. All this information is then executed against the GraphQL schema.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="kp"&gt;private&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ambiguous_param&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# ... Generated code provided by graphql-ruby's graphql:install&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Synchronize GraphQL Queries to Rails Server&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/9f72e132f88e6f551e07700fd35539890d9e2a44"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To accommodate persisted queries, we will have to &lt;em&gt;synchronize&lt;/em&gt; the queries from our React application to our Rails server. Fortunately, &lt;code&gt;persistgraphql-signature-sync&lt;/code&gt; (our script from earlier to extract queries) does this already.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is possible to sync the persisted queries to a specified endpoint. The endpoint needs to accept a POST request with body parameters of query and signature.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will need to do a few things to support this new synchronization endpoint.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create a new &lt;code&gt;PersistedQuery&lt;/code&gt; model and migration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/models/persisted_query.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PersistedQuery&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationRecord&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# db/migrate/20180617011135_create_persisted_queries.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CreatePersistedQueries&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ActiveRecord&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Migration&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;5.2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;change&lt;/span&gt;
    &lt;span class="n"&gt;create_table&lt;/span&gt; &lt;span class="ss"&gt;:persisted_queries&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;string&lt;/span&gt; &lt;span class="ss"&gt;:signature&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;index: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;unique: &lt;/span&gt;&lt;span class="kp"&gt;true&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;string&lt;/span&gt; &lt;span class="ss"&gt;:query&lt;/span&gt;

      &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;timestamps&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We will store the persisted queries in this newly created table &amp;ndash; notice that we have a unique index on the signature. Now let&amp;rsquo;s add the required route and controller that will accept the synchronization request.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# config/routes.rb&lt;/span&gt;
&lt;span class="no"&gt;Rails&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;application&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;routes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="c1"&gt;# ... existing routes&lt;/span&gt;
  &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="s2"&gt;"/graphql_persist"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;to: &lt;/span&gt;&lt;span class="s2"&gt;"graphql_persist#execute"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_persist_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlPersistController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;document&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;valid_query?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:signature&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="ss"&gt;query: &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;

      &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;attributes&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="vi"&gt;@errors&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="ss"&gt;status: &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="ss"&gt;status: &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="kp"&gt;private&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;valid_query?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;document: &lt;/span&gt;&lt;span class="n"&gt;document&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;validator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;GraphQL&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;StaticValidation&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Validator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;schema: &lt;/span&gt;&lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;validator&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;validate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:errors&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="vi"&gt;@errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="ss"&gt;:message&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="vi"&gt;@errors&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;empty?&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this controller, we are parsing out the &lt;em&gt;query&lt;/em&gt; and validating it against our schema. If the query is okay from a schema perspective, then we create a new &lt;code&gt;PersistedQuery&lt;/code&gt; database record with the &lt;code&gt;query&lt;/code&gt; and the &lt;code&gt;signature&lt;/code&gt;. When we get to using the persisted queries, we can do a quick look up and pull the query to be used.&lt;/p&gt;

&lt;p&gt;We can now run the &lt;code&gt;persistgraphql-signature-sync&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;node index.js --input-path=../react-graphql/src --sync-endpoint=http://localhost:3000/graphql_persist
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will attempt to synchronize each query to the server. It is not the prettiest, but the command will print out the server&amp;rsquo;s response for each query.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Synching persisted query a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80
{ id: 1,
  signature: 'a38e6d5349901b395334b5fd3b14e84a7ca7c4fc060a4089f2c23b5cf76f0f80',
  query: 'query ConsolesByYear($afterYear: Int, $beforeYear: Int) {\n  consoles(afterYear: $afterYear, beforeYear: $beforeYear) {\n    ...ConsoleFieldsFragment\n    company {\n      name\n      __typename\n    }\n    __typename\n  }\n}\n\nfragment ConsoleFieldsFragment on Console {\n  name\n  releaseYear\n  __typename\n}\n',
  created_at: '2018-07-03T19:52:54.717Z',
  updated_at: '2018-07-03T19:52:54.717Z' }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Refactor Rails Server to use Persisted Queries&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Follow along with the complete code changes on &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/commit/802dcc0d9aef28b117f926d7638a4a2115d304e1"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The finish line is near! Our Rails server has the queries persisted in the database. Now we just have to adjust our &lt;code&gt;GraphqlController&lt;/code&gt; to pull the appropriate query when receiving the persisted query request from our React application.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# app/controllers/graphql_controller.rb&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;GraphqlController&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="no"&gt;ApplicationController&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;execute&lt;/span&gt;
    &lt;span class="n"&gt;variables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ensure_hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:variables&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:query&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;operation_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:operationName&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
      &lt;span class="n"&gt;signature&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;dig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:extensions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;:persistedQuery&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;:sha256Hash&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;persisted_query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;PersistedQuery&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find_by!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;signature: &lt;/span&gt;&lt;span class="n"&gt;signature&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;RailsGraphqlSchema&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;persisted_query&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;variables: &lt;/span&gt;&lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;operation_name: &lt;/span&gt;&lt;span class="n"&gt;operation_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;

    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;
  &lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;StandardError&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
    &lt;span class="n"&gt;render&lt;/span&gt; &lt;span class="ss"&gt;json: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;errors: &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;message&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="c1"&gt;# ... rest of class&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our controller&amp;rsquo;s action now handles the situation when we don&amp;rsquo;t have a query present, which is the case when we&amp;rsquo;re using persisted queries. In this situation, we pull out the &lt;code&gt;sha256Hash&lt;/code&gt; value from the parameters and look up the persisted query. We then execute the persisted query&amp;rsquo;s query against the schema.&lt;/p&gt;

&lt;p&gt;In the event that we want to &lt;em&gt;lock down&lt;/em&gt; the API to only use persisted queries, we can use a conditional like &lt;code&gt;Rails.env.production?&lt;/code&gt; to gate the flow, allowing only the persisted queries through.&lt;/p&gt;

&lt;h1&gt;Reflection&lt;/h1&gt;

&lt;p&gt;In this post, we created a Rails server that exposes a GraphQL API. We used &lt;a href="https://github.com/kevinjalbert/graphql-persisted-queries/tree/master/persistgraphql-signature-sync"&gt;&lt;code&gt;persistgraphql-signature-sync&lt;/code&gt;&lt;/a&gt; to assist in synchronizing the queries from the React application (that we built in &lt;a href="/graphql-persisted-queries-with-http-caching-part-2/"&gt;part two&lt;/a&gt;) to our Rails server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; there does exist a paid pro version of &lt;code&gt;graphql-ruby&lt;/code&gt; called &lt;a href="http://graphql.pro/"&gt;GraphQL::Pro&lt;/a&gt;, which has its own support for &lt;a href="http://graphql-ruby.org/operation_store/overview"&gt;persisted queries&lt;/a&gt;. It is a great solution as it covers synchronization of queries, admin dashboard, and connection to clients (Apollo/Relay). If you can afford the cost and want an &lt;em&gt;off the shelf&lt;/em&gt; solution, it is something you could consider. For the purpose of this article, however, we will skip out on it.&lt;/p&gt;

&lt;p&gt;In the next and last part of this series, we will look at the final goal of adding HTTP caching to our GraphQL API servers. With HTTP caching we can lessen the load on our servers and offer faster response times to the consumers of the API.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This topic was presented at &lt;a href="https://www.meetup.com/GraphQL-Toronto/events/251760335/"&gt;GraphQL Toronto July 2018&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ocX_jf81LwE"&gt;Watch the talk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/kevinjalbert/graphql-persisted-queries-with-http-caching"&gt;Read the slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
  </entry>
</feed>
